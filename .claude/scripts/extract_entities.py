#!/usr/bin/env python3
"""
XML æ ‡ç­¾æå–ä¸åŒæ­¥è„šæœ¬ (v4.0)

> **v5.0 è¯´æ˜**: æ­¤è„šæœ¬ç”¨äº**æ‰‹åŠ¨æ ‡æ³¨åœºæ™¯**ï¼ˆå¯é€‰ï¼‰ã€‚
> v5.0 ä¸»æµç¨‹ä½¿ç”¨ Data Agent ä»çº¯æ­£æ–‡è¿›è¡Œ AI è¯­ä¹‰æå–ï¼Œä¸å†ä¾èµ– XML æ ‡ç­¾ã€‚
> å¦‚æœç« èŠ‚ä¸­åŒ…å« XML æ ‡ç­¾ï¼Œæ­¤è„šæœ¬ä»å¯ç”¨äºè§£æå’ŒåŒæ­¥ã€‚

åŠŸèƒ½ï¼š
1. æ‰«ææŒ‡å®šç« èŠ‚æ­£æ–‡ï¼Œæå–æ‰€æœ‰ XML æ ¼å¼æ ‡ç­¾
2. æ”¯æŒæ ‡ç­¾ç±»å‹ï¼š
   - <entity>: å®ä½“ï¼ˆè§’è‰²/åœ°ç‚¹/ç‰©å“/åŠ¿åŠ›/æ‹›å¼ï¼‰
   - <entity-alias>: å®ä½“åˆ«åæ³¨å†Œ
   - <entity-update>: å®ä½“å±æ€§æ›´æ–°ï¼ˆæ”¯æŒ set/unset/add/remove/incï¼‰
   - <skill>: é‡‘æ‰‹æŒ‡æŠ€èƒ½
   - <foreshadow>: ä¼ç¬”æ ‡ç­¾
   - <deviation>: å¤§çº²åç¦»æ ‡è®°
   - <relationship>: è§’è‰²å…³ç³»
3. æ”¯æŒå®ä½“å±‚çº§åˆ†ç±»ï¼ˆæ ¸å¿ƒ/æ”¯çº¿/è£…é¥°ï¼‰
4. åŒæ­¥åˆ°è®¾å®šé›†å¯¹åº”æ–‡ä»¶
5. æ›´æ–° state.jsonï¼ˆentities_v3 + alias_index ä¸€å¯¹å¤šï¼‰
6. æ”¯æŒè‡ªåŠ¨åŒ–æ¨¡å¼å’Œäº¤äº’å¼æ¨¡å¼

v4.0 å˜æ›´ï¼š
- alias_index æ”¹ä¸ºä¸€å¯¹å¤šï¼ˆåŒä¸€åˆ«åå¯æ˜ å°„å¤šä¸ªå®ä½“ï¼‰
- åˆ é™¤æ—§æ ¼å¼å…¼å®¹ä»£ç 
- æ–°å¢æ“ä½œï¼š<unset>/<add>/<remove>/<inc>
- é¡¶å±‚å­—æ®µç™½åå•æ”¯æŒ

ä½¿ç”¨æ–¹å¼ï¼š
  python extract_entities.py <ç« èŠ‚æ–‡ä»¶> [--auto] [--dry-run]
  python extract_entities.py --project-root "path" --chapter 1 --auto
"""

import re
import json
import os
import shutil
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Any

# ============================================================================
# å®‰å…¨ä¿®å¤ï¼šå¯¼å…¥å®‰å…¨å·¥å…·å‡½æ•°ï¼ˆP0 CRITICALï¼‰
# ============================================================================
from security_utils import sanitize_filename, create_secure_directory, atomic_write_json
from project_locator import resolve_project_root, resolve_state_file
from chapter_paths import find_chapter_file, extract_chapter_num_from_filename

# Windows ç¼–ç å…¼å®¹æ€§ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# å®ä½“ç±»å‹ä¸ç›®æ ‡æ–‡ä»¶æ˜ å°„
ENTITY_TYPE_MAP = {
    "è§’è‰²": "è®¾å®šé›†/è§’è‰²åº“/{category}/{name}.md",
    "åœ°ç‚¹": "è®¾å®šé›†/ä¸–ç•Œè§‚.md",
    "ç‰©å“": "è®¾å®šé›†/ç‰©å“åº“/{name}.md",
    "åŠ¿åŠ›": "è®¾å®šé›†/ä¸–ç•Œè§‚.md",
    "æ‹›å¼": "è®¾å®šé›†/åŠ›é‡ä½“ç³».md",
    "å…¶ä»–": "è®¾å®šé›†/å…¶ä»–è®¾å®š/{name}.md"
}

# æœ‰æ•ˆå®ä½“ç±»å‹ï¼ˆv4.0 ä¸å†å…¼å®¹æ—§åˆ«åï¼‰
VALID_ENTITY_TYPES = {"è§’è‰²", "åœ°ç‚¹", "ç‰©å“", "åŠ¿åŠ›", "æ‹›å¼"}

# é¡¶å±‚å­—æ®µç™½åå•ï¼ˆå¯é€šè¿‡ entity-update ç›´æ¥ä¿®æ”¹ï¼‰
TOP_LEVEL_FIELDS = {"tier", "desc", "canonical_name", "importance", "status", "parent"}


class AmbiguousAliasError(RuntimeError):
    """åˆ«åå‘½ä¸­å¤šä¸ªå®ä½“ä¸”æ— æ³•æ¶ˆæ­§ï¼ˆå¿…é¡»æ”¹ç”¨ id æˆ–è¡¥å…… typeï¼‰ã€‚"""


def normalize_entity_type(raw: Any) -> str:
    """éªŒè¯å®ä½“ç±»å‹ï¼ˆv4.0 ä¸å†æ”¯æŒåˆ«åè½¬æ¢ï¼‰ã€‚"""
    t = str(raw or "").strip()
    if not t:
        return ""
    if t in VALID_ENTITY_TYPES:
        return t
    return ""  # æ— æ•ˆç±»å‹è¿”å›ç©º

# è§’è‰²åˆ†ç±»è§„åˆ™
ROLE_CATEGORY_MAP = {
    "ä¸»è§’": "ä¸»è¦è§’è‰²",
    "é…è§’": "æ¬¡è¦è§’è‰²",
    "åæ´¾": "åæ´¾è§’è‰²",
    "è·¯äºº": "æ¬¡è¦è§’è‰²"
}

# å®ä½“å±‚çº§æƒé‡ï¼ˆåŒ¹é…ä¼ç¬”ä¸‰å±‚çº§ç³»ç»Ÿï¼‰
ENTITY_TIER_MAP = {
    "æ ¸å¿ƒ": {"weight": 3.0, "desc": "å¿…é¡»è¿½è¸ªï¼Œå½±å“ä¸»çº¿"},
    "core": {"weight": 3.0, "desc": "å¿…é¡»è¿½è¸ªï¼Œå½±å“ä¸»çº¿"},
    "æ”¯çº¿": {"weight": 2.0, "desc": "åº”è¯¥è¿½è¸ªï¼Œä¸°å¯Œå‰§æƒ…"},
    "sub": {"weight": 2.0, "desc": "åº”è¯¥è¿½è¸ªï¼Œä¸°å¯Œå‰§æƒ…"},
    "è£…é¥°": {"weight": 1.0, "desc": "å¯é€‰è¿½è¸ªï¼Œå¢åŠ çœŸå®æ„Ÿ"},
    "decor": {"weight": 1.0, "desc": "å¯é€‰è¿½è¸ªï¼Œå¢åŠ çœŸå®æ„Ÿ"}
}

# ============================================================================
# å®ä½“ç®¡ç†æ ¸å¿ƒå‡½æ•° (v3.0 æ–°å¢)
# ============================================================================

def generate_entity_id(entity_type: str, name: str, existing_ids: set) -> str:
    """
    ç”Ÿæˆå”¯ä¸€å®ä½“ ID

    è§„åˆ™:
    1. ä¼˜å…ˆä½¿ç”¨æ‹¼éŸ³ï¼ˆå»ç©ºæ ¼ã€å°å†™ï¼‰
    2. å†²çªæ—¶è¿½åŠ æ•°å­—åç¼€
    3. ç‰¹æ®Šå‰ç¼€æŒ‰ç±»å‹

    Args:
        entity_type: å®ä½“ç±»å‹ï¼ˆè§’è‰²/åœ°ç‚¹/ç‰©å“/åŠ¿åŠ›/æ‹›å¼ï¼‰
        name: å®ä½“åç§°
        existing_ids: å·²å­˜åœ¨çš„ ID é›†åˆ

    Returns:
        str: å”¯ä¸€çš„å®ä½“ ID
    """
    # ç±»å‹å‰ç¼€æ˜ å°„
    prefix_map = {
        "ç‰©å“": "item_",
        "åŠ¿åŠ›": "faction_",
        "æ‹›å¼": "skill_",
        "åœ°ç‚¹": "loc_"
        # è§’è‰²æ— å‰ç¼€
    }

    # å°è¯•ä½¿ç”¨ pypinyinï¼Œå¦‚æœä¸å¯ç”¨åˆ™ç”¨ç®€å•çš„ hash
    try:
        from pypinyin import lazy_pinyin
        pinyin = ''.join(lazy_pinyin(name))
        base_id = prefix_map.get(entity_type, '') + pinyin.lower()
    except ImportError:
        # pypinyin ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ¡ˆ
        import hashlib
        hash_suffix = hashlib.md5(name.encode('utf-8')).hexdigest()[:8]
        base_id = prefix_map.get(entity_type, '') + hash_suffix

    # æ¸…ç†éæ³•å­—ç¬¦
    base_id = re.sub(r'[^a-z0-9_]', '', base_id)

    # å¤„ç†å†²çª
    final_id = base_id
    counter = 1
    while final_id in existing_ids:
        final_id = f"{base_id}_{counter}"
        counter += 1

    return final_id


def resolve_entity_by_alias(alias: str, entity_type: Optional[str], state: dict) -> Tuple[Optional[str], Optional[str], Optional[dict]]:
    """
    é€šè¿‡åˆ«åè§£æå®ä½“ï¼ˆv4.0 ä¸€å¯¹å¤šç‰ˆæœ¬ï¼‰

    Args:
        alias: åˆ«åæˆ–åç§°
        entity_type: å®ä½“ç±»å‹æç¤ºï¼ˆå¯é€‰ï¼Œç”¨äºæ­§ä¹‰æ¶ˆè§£ï¼‰
        state: state.json å†…å®¹

    Returns:
        (entity_type, entity_id, entity_data) æˆ– (None, None, None)

    Raises:
        AmbiguousAliasError: åˆ«åå‘½ä¸­å¤šä¸ªå®ä½“ä¸”æ— æ³•æ¶ˆæ­§ï¼ˆå¿…é¡»æ”¹ç”¨ id æˆ–è¡¥å…… typeï¼‰
        ValueError: alias_index æ•°æ®æ ¼å¼ä¸ç¬¦åˆ v4.0 è§„èŒƒ
    """
    alias_index = state.get("alias_index", {})

    # alias_index æ–°æ ¼å¼: {"åˆ«å": [{"type": "è§’è‰²", "id": "xxx"}, ...]}
    entries = alias_index.get(alias)
    if not entries:
        return (None, None, None)

    if not isinstance(entries, list):
        raise ValueError(
            f"alias_index æ•°æ®æ ¼å¼é”™è¯¯ï¼šæœŸæœ› alias_index[{alias!r}] ä¸º list[{{type,id,...}}]ï¼Œå®é™…ä¸º {type(entries).__name__}"
        )

    # åªæœ‰ä¸€ä¸ªåŒ¹é… -> ç›´æ¥è¿”å›
    if len(entries) == 1:
        ref = entries[0]
        et = ref.get("type", "")
        eid = ref.get("id", "")
        entities_v3 = state.get("entities_v3", {})
        entity_data = entities_v3.get(et, {}).get(eid)
        return (et, eid, entity_data) if entity_data else (None, None, None)

    # å¤šä¸ªåŒ¹é… -> å°è¯•ç”¨ type æ¶ˆè§£
    if entity_type:
        matches = [e for e in entries if e.get("type") == entity_type]
        if len(matches) == 1:
            ref = matches[0]
            et = ref.get("type", "")
            eid = ref.get("id", "")
            entities_v3 = state.get("entities_v3", {})
            entity_data = entities_v3.get(et, {}).get(eid)
            return (et, eid, entity_data) if entity_data else (None, None, None)

    # æ­§ä¹‰æ— æ³•æ¶ˆè§£ï¼šå¿…é¡»å¼ºåˆ¶æŠ¥é”™ï¼Œé¿å…å†™é”™å®ä½“
    raise AmbiguousAliasError(f"åˆ«åæ­§ä¹‰: {alias!r} å‘½ä¸­ {len(entries)} ä¸ªå®ä½“ï¼Œè¯·æ”¹ç”¨ id æˆ–è¡¥å…… type å±æ€§")


def ensure_entities_v3_structure(state: dict) -> dict:
    """
    ç¡®ä¿ state.json æœ‰ entities_v3 å’Œ alias_index ç»“æ„

    entities_v3 æ ¼å¼:
    {
        "è§’è‰²": {
            "lintian": {
                "id": "lintian",
                "canonical_name": "æ—å¤©",
                "aliases": ["åºŸç‰©", "æ—å¤©"],
                "tier": "æ ¸å¿ƒ",
                "current": {...},
                "history": [...],
                "created_chapter": 1
            }
        },
        "åœ°ç‚¹": {...},
        ...
    }

    alias_index æ ¼å¼ (v4.0 ä¸€å¯¹å¤š):
    {
        "åºŸç‰©": [{"type": "è§’è‰²", "id": "lintian"}],
        "å¤©äº‘å®—": [
            {"type": "åœ°ç‚¹", "id": "loc_tianyunzong"},
            {"type": "åŠ¿åŠ›", "id": "faction_tianyunzong"}
        ],
        ...
    }
    """
    if "entities_v3" not in state:
        state["entities_v3"] = {
            "è§’è‰²": {},
            "åœ°ç‚¹": {},
            "ç‰©å“": {},
            "åŠ¿åŠ›": {},
            "æ‹›å¼": {}
        }

    if "alias_index" not in state:
        state["alias_index"] = {}

    return state


_XML_ATTR_RE = re.compile(r'([A-Za-z_][A-Za-z0-9_-]*)\s*=\s*(["\'])(.*?)\2', re.DOTALL)


def parse_xml_attributes(tag: str) -> Dict[str, str]:
    """ä»å½¢å¦‚ `<tag a=\"1\" b='2'/>` çš„ç‰‡æ®µä¸­æå–å±æ€§å­—å…¸ï¼ˆä¸åš XML è¯­ä¹‰æ ¡éªŒï¼‰ã€‚"""
    attrs: Dict[str, str] = {}
    for m in _XML_ATTR_RE.finditer(tag):
        key = m.group(1).strip()
        value = m.group(3).strip()
        if not key:
            continue
        attrs[key] = value
    return attrs


def _line_number_from_index(text: str, index: int) -> int:
    return text[:index].count("\n") + 1


def extract_new_entities(file_path: str) -> List[Dict]:
    """
    ä»ç« èŠ‚æ–‡ä»¶ä¸­æå–æ‰€æœ‰å®ä½“æ ‡ç­¾ï¼ˆv4.0 ä»…æ”¯æŒ XML æ ¼å¼ï¼‰ã€‚

    æ”¯æŒ XML å½¢æ€ï¼š
      1) è‡ªé—­åˆï¼š<entity type="è§’è‰²" name="æ—å¤©" desc="..." tier="æ ¸å¿ƒ" [id="lintian"] [ä»»æ„å±æ€§...]/>
      2) æˆå¯¹ï¼š
         <entity type="è§’è‰²" id="lintian" name="æ—å¤©" desc="..." tier="æ ¸å¿ƒ">
           <alias>åºŸç‰©</alias>
           <alias>æ—å®—ä¸»</alias>
         </entity>

    Returns:
        List[Dict]: [{"type","name","desc","tier","id?","attrs","aliases","line","source_file"}, ...]
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    entities: List[Dict[str, Any]] = []

    # ============================================================
    # XML æˆå¯¹æ ¼å¼: <entity ...> ... </entity>ï¼ˆç”¨äºå†…åµŒ aliasï¼‰
    # ============================================================
    block_pattern = re.compile(r"(?s)(<entity\b[^>]*>)(.*?)</entity>")
    for m in block_pattern.finditer(text):
        open_tag = m.group(1)
        body = m.group(2)
        attrs = parse_xml_attributes(open_tag)

        entity_type = str(attrs.get("type", "")).strip()
        entity_name = str(attrs.get("name", "")).strip()
        if not entity_type or not entity_name:
            continue

        # éªŒè¯ entity_type
        if entity_type not in VALID_ENTITY_TYPES:
            print(f"âš ï¸ æ— æ•ˆå®ä½“ç±»å‹: {entity_type}ï¼ˆç¬¬{_line_number_from_index(text, m.start())}è¡Œï¼‰ï¼Œè·³è¿‡")
            continue

        entity_desc = str(attrs.get("desc", "")).strip()
        entity_tier = str(attrs.get("tier", "æ”¯çº¿")).strip() or "æ”¯çº¿"
        if entity_tier.lower() not in ENTITY_TIER_MAP:
            entity_tier = "æ”¯çº¿"

        entity_id = str(attrs.get("id", "")).strip() or None
        extra_attrs = {k: v for k, v in attrs.items() if k not in {"type", "id", "name", "desc", "tier"}}
        aliases = [a.strip() for a in re.findall(r"(?s)<alias>(.*?)</alias>", body) if str(a).strip()]

        entities.append(
            {
                "type": entity_type,
                "id": entity_id,
                "name": entity_name,
                "desc": entity_desc,
                "tier": entity_tier,
                "attrs": extra_attrs,
                "aliases": aliases,
                "line": _line_number_from_index(text, m.start()),
                "source_file": file_path,
            }
        )

    # ============================================================
    # XML è‡ªé—­åˆæ ¼å¼: <entity .../>
    # ============================================================
    self_closing_pattern = re.compile(r"<entity\b[^>]*?/\s*>")
    for m in self_closing_pattern.finditer(text):
        tag = m.group(0)
        attrs = parse_xml_attributes(tag)

        entity_type = str(attrs.get("type", "")).strip()
        entity_name = str(attrs.get("name", "")).strip()
        if not entity_type or not entity_name:
            continue

        # éªŒè¯ entity_type
        if entity_type not in VALID_ENTITY_TYPES:
            print(f"âš ï¸ æ— æ•ˆå®ä½“ç±»å‹: {entity_type}ï¼ˆç¬¬{_line_number_from_index(text, m.start())}è¡Œï¼‰ï¼Œè·³è¿‡")
            continue

        entity_desc = str(attrs.get("desc", "")).strip()
        entity_tier = str(attrs.get("tier", "æ”¯çº¿")).strip() or "æ”¯çº¿"
        if entity_tier.lower() not in ENTITY_TIER_MAP:
            entity_tier = "æ”¯çº¿"

        entity_id = str(attrs.get("id", "")).strip() or None
        extra_attrs = {k: v for k, v in attrs.items() if k not in {"type", "id", "name", "desc", "tier"}}

        entities.append(
            {
                "type": entity_type,
                "id": entity_id,
                "name": entity_name,
                "desc": entity_desc,
                "tier": entity_tier,
                "attrs": extra_attrs,
                "aliases": [],
                "line": _line_number_from_index(text, m.start()),
                "source_file": file_path,
            }
        )

    return entities


def extract_entity_alias_ops(file_path: str) -> List[Dict[str, Any]]:
    """
    æå–å®ä½“åˆ«åæ“ä½œï¼š
      <entity-alias id="lintian" alias="æ—å®—ä¸»" context="æˆä¸ºå®—ä¸»å"/>
      <entity-alias ref="æ—å¤©" alias="ä¸ç­æˆ˜ç¥" context="æ™‹å‡ç§°å·å"/>

    å¯é€‰ï¼štype="è§’è‰²|åœ°ç‚¹|ç‰©å“|åŠ¿åŠ›|æ‹›å¼" ç”¨äº disambiguationã€‚
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    results: List[Dict[str, Any]] = []
    pattern = re.compile(r"<entity[-_]alias\b[^>]*?/\s*>", re.IGNORECASE)
    for m in pattern.finditer(text):
        tag = m.group(0)
        attrs = parse_xml_attributes(tag)

        alias = str(attrs.get("alias", "")).strip()
        if not alias:
            continue

        results.append(
            {
                "id": str(attrs.get("id", "")).strip() or None,
                "ref": str(attrs.get("ref", "")).strip() or None,
                "type": str(attrs.get("type", "")).strip() or None,
                "alias": alias,
                "context": str(attrs.get("context", "")).strip(),
                "line": _line_number_from_index(text, m.start()),
                "source_file": file_path,
            }
        )

    return results


def extract_entity_update_ops(file_path: str) -> List[Dict[str, Any]]:
    """
    æå–å®ä½“æ›´æ–°æ“ä½œï¼ˆv4.0 æ”¯æŒ set/unset/add/remove/incï¼‰ï¼š
      <entity-update id="lintian">
        <set key="realm" value="ç­‘åŸºæœŸä¸€å±‚" reason="çªç ´"/>
        <unset key="bottleneck"/>
        <add key="titles" value="ä¸ç­æˆ˜ç¥"/>
        <remove key="allies" value="å¼ ä¸‰"/>
        <inc key="kill_count" delta="1"/>
      </entity-update>

      <entity-update ref="æ—å®—ä¸»" type="è§’è‰²">
        <set key="realm" value="é‡‘ä¸¹æœŸ"/>
      </entity-update>

    å¯é€‰ï¼štype="è§’è‰²|åœ°ç‚¹|ç‰©å“|åŠ¿åŠ›|æ‹›å¼" ç”¨äº disambiguationã€‚
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    results: List[Dict[str, Any]] = []

    block_pattern = re.compile(r"(?s)(<entity-update\b[^>]*>)(.*?)</entity-update>", re.IGNORECASE)
    for m in block_pattern.finditer(text):
        open_tag = m.group(1)
        body = m.group(2)
        attrs = parse_xml_attributes(open_tag)

        operations: List[Dict[str, Any]] = []

        # <set key="..." value="..." reason="..."/>
        for sm in re.finditer(r"<set\b[^>]*?/\s*>", body, re.IGNORECASE):
            set_attrs = parse_xml_attributes(sm.group(0))
            key = str(set_attrs.get("key", "")).strip()
            value = str(set_attrs.get("value", "")).strip()
            if not key:
                continue
            operations.append({
                "op": "set",
                "key": key,
                "value": value,
                "reason": str(set_attrs.get("reason", "")).strip()
            })

        # <unset key="..."/>
        for sm in re.finditer(r"<unset\b[^>]*?/\s*>", body, re.IGNORECASE):
            set_attrs = parse_xml_attributes(sm.group(0))
            key = str(set_attrs.get("key", "")).strip()
            if not key:
                continue
            operations.append({
                "op": "unset",
                "key": key,
                "reason": str(set_attrs.get("reason", "")).strip()
            })

        # <add key="..." value="..."/>
        for sm in re.finditer(r"<add\b[^>]*?/\s*>", body, re.IGNORECASE):
            set_attrs = parse_xml_attributes(sm.group(0))
            key = str(set_attrs.get("key", "")).strip()
            value = str(set_attrs.get("value", "")).strip()
            if not key or not value:
                continue
            operations.append({
                "op": "add",
                "key": key,
                "value": value,
                "reason": str(set_attrs.get("reason", "")).strip()
            })

        # <remove key="..." value="..."/>
        for sm in re.finditer(r"<remove\b[^>]*?/\s*>", body, re.IGNORECASE):
            set_attrs = parse_xml_attributes(sm.group(0))
            key = str(set_attrs.get("key", "")).strip()
            value = str(set_attrs.get("value", "")).strip()
            if not key or not value:
                continue
            operations.append({
                "op": "remove",
                "key": key,
                "value": value,
                "reason": str(set_attrs.get("reason", "")).strip()
            })

        # <inc key="..." delta="..."/>
        for sm in re.finditer(r"<inc\b[^>]*?/\s*>", body, re.IGNORECASE):
            set_attrs = parse_xml_attributes(sm.group(0))
            key = str(set_attrs.get("key", "")).strip()
            delta_str = str(set_attrs.get("delta", "1")).strip()
            if not key:
                continue
            try:
                delta = int(delta_str)
            except ValueError:
                delta = 1
            operations.append({
                "op": "inc",
                "key": key,
                "delta": delta,
                "reason": str(set_attrs.get("reason", "")).strip()
            })

        if not operations:
            continue

        results.append(
            {
                "id": str(attrs.get("id", "")).strip() or None,
                "ref": str(attrs.get("ref", "")).strip() or None,
                "type": str(attrs.get("type", "")).strip() or None,
                "operations": operations,
                "line": _line_number_from_index(text, m.start()),
                "source_file": file_path,
            }
        )

    return results


def extract_golden_finger_skills(file_path: str) -> List[Dict]:
    """
    ä»ç« èŠ‚æ–‡ä»¶ä¸­æå–é‡‘æ‰‹æŒ‡æŠ€èƒ½æ ‡ç­¾ï¼ˆv4.0 ä»…æ”¯æŒ XML æ ¼å¼ï¼‰

    XML æ ¼å¼ï¼š
      <skill name="æŠ€èƒ½å" level="ç­‰çº§" desc="æè¿°" cooldown="å†·å´æ—¶é—´"/>

      ç¤ºä¾‹ï¼š
      <skill name="æ—¶é—´å›æº¯" level="1" desc="å›åˆ°10ç§’å‰çš„çŠ¶æ€" cooldown="24å°æ—¶"/>

    Returns:
        List[Dict]: [{"name": "åå™¬", "level": "Lv1", "desc": "...", "cooldown": "10ç§’"}, ...]
    """
    skills = []

    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            xml_matches = re.findall(
                r'<skill\s+name=["\']([^"\']+)["\']\s+level=["\']([^"\']+)["\']\s+desc=["\']([^"\']+)["\']\s+cooldown=["\']([^"\']+)["\']\s*/?>',
                line
            )
            for match in xml_matches:
                skills.append({
                    "name": match[0].strip(),
                    "level": match[1].strip(),
                    "desc": match[2].strip(),
                    "cooldown": match[3].strip(),
                    "line": line_num,
                    "source_file": file_path
                })

    return skills


def extract_foreshadowing_json(file_path: str) -> List[Dict[str, Any]]:
    """
    ä»ç« èŠ‚æ–‡ä»¶æå–ä¼ç¬”æ ‡ç­¾ï¼ˆv4.0 ä»…æ”¯æŒ XML æ ¼å¼ï¼‰

    XML æ ¼å¼ï¼š
      <foreshadow content="ä¼ç¬”å†…å®¹" tier="å±‚çº§" target="ç›®æ ‡ç« èŠ‚" location="åœ°ç‚¹" characters="è§’è‰²1,è§’è‰²2"/>

      ç¤ºä¾‹ï¼š
      <foreshadow content="ç¥ç§˜è€è€…ç•™ä¸‹çš„ç‰ä½©å¼€å§‹å‘å…‰" tier="æ ¸å¿ƒ" target="50" location="åºŸå¼ƒå®éªŒå®¤" characters="é™†è¾°"/>

    å­—æ®µï¼š
      - content (å¿…å¡«)
      - tier (å¯é€‰: æ ¸å¿ƒ/æ”¯çº¿/è£…é¥°ï¼Œé»˜è®¤ æ”¯çº¿)
      - planted_chapter (å¯é€‰: é»˜è®¤ç”±è°ƒç”¨æ–¹è¡¥é½)
      - target_chapter / target (å¯é€‰: é»˜è®¤ planted_chapter + 100)
      - location (å¯é€‰)
      - characters (å¯é€‰: é€—å·åˆ†éš”å­—ç¬¦ä¸²)
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    results: List[Dict[str, Any]] = []

    xml_pattern = re.compile(
        r'<foreshadow\s+'
        r'content=["\']([^"\']+)["\']\s+'
        r'tier=["\']([^"\']+)["\']'
        r'(?:\s+target=["\']([^"\']*)["\'])?'
        r'(?:\s+location=["\']([^"\']*)["\'])?'
        r'(?:\s+characters=["\']([^"\']*)["\'])?'
        r'\s*/?>',
        re.DOTALL
    )

    for m in xml_pattern.finditer(text):
        line_num = text[: m.start()].count("\n") + 1
        content = m.group(1).strip()
        if not content:
            continue

        tier = m.group(2).strip() or "æ”¯çº¿"
        if tier.lower() not in ENTITY_TIER_MAP:
            tier = "æ”¯çº¿"

        target_str = m.group(3)
        target_chapter = None
        if target_str:
            try:
                target_chapter = int(target_str.strip())
            except (TypeError, ValueError):
                pass

        location = (m.group(4) or "").strip()

        characters_str = m.group(5) or ""
        characters_list = [c.strip() for c in re.split(r"[,ï¼Œ]", characters_str) if c.strip()]

        results.append({
            "content": content,
            "tier": tier,
            "planted_chapter": None,
            "target_chapter": target_chapter,
            "location": location,
            "characters": characters_list,
            "line": line_num,
            "source_file": str(p),
        })

    return results


def extract_deviations(file_path: str) -> List[Dict[str, Any]]:
    """
    ä»ç« èŠ‚æ–‡ä»¶æå–å¤§çº²åç¦»æ ‡ç­¾ï¼ˆv4.0 ä»…æ”¯æŒ XML æ ¼å¼ï¼‰

    XML æ ¼å¼ï¼š
      <deviation reason="åç¦»åŸå› "/>

      ç¤ºä¾‹ï¼š
      <deviation reason="ä¸´æ—¶çµæ„Ÿï¼Œå¢åŠ æè–‡ä¸é™†è¾°çš„æƒ…æ„Ÿäº’åŠ¨ï¼Œä¸ºåç»­æ„Ÿæƒ…çº¿é“ºå«"/>

    Returns:
        List[Dict]: [{"reason": "...", "line": 123}, ...]
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    results: List[Dict[str, Any]] = []

    xml_pattern = re.compile(
        r'<deviation\s+reason=["\']([^"\']+)["\']\s*/?>',
        re.DOTALL
    )

    for m in xml_pattern.finditer(text):
        line_num = text[: m.start()].count("\n") + 1
        reason = m.group(1).strip()
        if reason:
            results.append({
                "reason": reason,
                "line": line_num,
                "source_file": str(p),
            })

    return results


def extract_relationships(file_path: str) -> List[Dict[str, Any]]:
    """
    ä»ç« èŠ‚æ–‡ä»¶æå–è§’è‰²å…³ç³»æ ‡ç­¾

    XML æ ¼å¼ï¼ˆæ¨èä½¿ç”¨ entity_idï¼Œé¿å…æ”¹åå¯¼è‡´æ–­é“¾ï¼‰ï¼š
      <relationship char1_id="lintian" char2_id="lixue" type="romance" intensity="60" desc="æš§æ˜§ä¸­ï¼Œäº’æœ‰å¥½æ„Ÿ"/>
      <relationship char1="æ—å¤©" char2="æé›ª" type="romance" intensity="60" desc="æš§æ˜§ä¸­ï¼Œäº’æœ‰å¥½æ„Ÿ"/>

      ç¤ºä¾‹ï¼š
      <relationship char1="æ—å¤©" char2="æé›ª" type="romance" intensity="60" desc="æš§æ˜§ä¸­ï¼Œäº’æœ‰å¥½æ„Ÿ"/>
      <relationship char1="æ—å¤©" char2="ç‹å°‘" type="enemy" intensity="90" desc="æ€çˆ¶ä¹‹ä»‡"/>
      <relationship char1="æ—å¤©" char2="äº‘é•¿è€" type="mentor" intensity="80" desc="å¸ˆå¾’å…³ç³»ï¼Œå—å…¶æŒ‡ç‚¹"/>

    å…³ç³»ç±»å‹ (type):
      - ally: ç›Ÿå‹
      - enemy: æ•Œäºº
      - romance: æ‹äºº/æš§æ˜§
      - mentor: å¸ˆå¾’
      - debtor: æ©æ€¨ï¼ˆæ¬ äººæƒ…/è¢«æ¬ ï¼‰
      - family: å®¶æ—/è¡€ç¼˜
      - rival: ç«äº‰å¯¹æ‰‹

    å¼ºåº¦ (intensity): 0-100ï¼Œè¶Šé«˜å…³ç³»è¶Šå¼ºçƒˆ

    Returns:
        List[Dict]: [{"char1","char2","char1_id?","char2_id?","type","intensity","desc",...}, ...]
    """
    p = Path(file_path)
    text = p.read_text(encoding="utf-8")

    results: List[Dict[str, Any]] = []

    valid_types = {"ally", "enemy", "romance", "mentor", "debtor", "family", "rival"}

    # XML æ ¼å¼: <relationship .../>
    xml_pattern = re.compile(r"<relationship\b[^>]*?/\s*>", re.IGNORECASE)
    for m in xml_pattern.finditer(text):
        line_num = text[: m.start()].count("\n") + 1
        attrs = parse_xml_attributes(m.group(0))

        char1 = str(attrs.get("char1", "")).strip()
        char2 = str(attrs.get("char2", "")).strip()
        char1_id = str(attrs.get("char1_id", "")).strip() or None
        char2_id = str(attrs.get("char2_id", "")).strip() or None
        rel_type = str(attrs.get("type", "")).strip().lower() or "ally"
        intensity_str = str(attrs.get("intensity", "")).strip() or "50"
        desc = str(attrs.get("desc", "")).strip()

        if not ((char1_id or char1) and (char2_id or char2)):
            continue

        # éªŒè¯å…³ç³»ç±»å‹
        if rel_type not in valid_types:
            print(f"âš ï¸ æœªçŸ¥å…³ç³»ç±»å‹ '{rel_type}'ï¼ˆç¬¬{line_num}è¡Œï¼‰ï¼Œä½¿ç”¨é»˜è®¤ 'ally'")
            rel_type = "ally"

        # è§£æå¼ºåº¦
        try:
            intensity = int(intensity_str)
            intensity = max(0, min(100, intensity))  # é™åˆ¶ 0-100
        except ValueError:
            intensity = 50  # é»˜è®¤ä¸­ç­‰å¼ºåº¦

        results.append({
            "char1": char1,
            "char2": char2,
            "char1_id": char1_id,
            "char2_id": char2_id,
            "type": rel_type,
            "intensity": intensity,
            "desc": desc,
            "line": line_num,
            "source_file": str(p),
        })

    return results


def categorize_character(desc: str) -> str:
    """
    æ ¹æ®æè¿°åˆ¤æ–­è§’è‰²åˆ†ç±»

    è§„åˆ™ï¼š
      - åŒ…å«"ä¸»è§’"/"æ—å¤©" â†’ ä¸»è¦è§’è‰²
      - åŒ…å«"åæ´¾"/"æ•Œå¯¹"/"è¡€ç…é—¨" â†’ åæ´¾è§’è‰²
      - å…¶ä»– â†’ æ¬¡è¦è§’è‰²
    """
    if "ä¸»è§’" in desc or "é‡è¦" in desc:
        return "ä¸»è¦è§’è‰²"
    elif "åæ´¾" in desc or "æ•Œå¯¹" in desc or "è¡€ç…" in desc:
        return "åæ´¾è§’è‰²"
    else:
        return "æ¬¡è¦è§’è‰²"

def generate_character_card(entity: Dict, category: str) -> str:
    """ç”Ÿæˆè§’è‰²å¡ Markdown å†…å®¹"""
    return f"""# {entity['name']}

> **é¦–æ¬¡ç™»åœº**: {entity.get('source_file', 'æœªçŸ¥')}ï¼ˆç¬¬ {entity.get('line', '?')} è¡Œï¼‰
> **åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d')}

## åŸºæœ¬ä¿¡æ¯

- **å§“å**: {entity['name']}
- **æ€§åˆ«**: å¾…è¡¥å……
- **å¹´é¾„**: å¾…è¡¥å……
- **èº«ä»½**: {entity['desc']}
- **æ‰€å±åŠ¿åŠ›**: å¾…è¡¥å……

## å®åŠ›è®¾å®š

- **å½“å‰å¢ƒç•Œ**: å¾…è¡¥å……
- **æ“…é•¿æ‹›å¼**: å¾…è¡¥å……
- **ç‰¹æ®Šèƒ½åŠ›**: å¾…è¡¥å……

## æ€§æ ¼ç‰¹ç‚¹

{entity['desc']}

## å¤–è²Œæè¿°

å¾…è¡¥å……

## äººé™…å…³ç³»

- **ä¸ä¸»è§’**: å¾…è¡¥å……

## é‡è¦å‰§æƒ…

- ã€ç¬¬ X ç« ã€‘{entity['desc']}

## å¤‡æ³¨

è‡ªåŠ¨æå–è‡ª `<entity/>` æ ‡ç­¾ï¼Œè¯·è¡¥å……å®Œå–„ã€‚
"""

def update_world_view(entity: Dict, target_file: str, section: str):
    """æ›´æ–°ä¸–ç•Œè§‚.mdï¼ˆè¿½åŠ åœ°ç‚¹/åŠ¿åŠ›ä¿¡æ¯ï¼‰"""
    if not os.path.exists(target_file):
        # åˆ›å»ºåŸºç¡€æ¨¡æ¿
        content = f"""# ä¸–ç•Œè§‚

## åœ°ç†

## åŠ¿åŠ›

## å†å²èƒŒæ™¯

"""
        with open(target_file, 'w', encoding='utf-8') as f:
            f.write(content)

    # è¯»å–ç°æœ‰å†…å®¹
    with open(target_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # è¿½åŠ åˆ°å¯¹åº”ç« èŠ‚
    if section == "åœ°ç†":
        entry = f"""
### {entity['name']}

{entity['desc']}

> é¦–æ¬¡ç™»åœº: {entity.get('source_file', 'æœªçŸ¥')}
"""
    elif section == "åŠ¿åŠ›":
        entry = f"""
### {entity['name']}

{entity['desc']}

> é¦–æ¬¡ç™»åœº: {entity.get('source_file', 'æœªçŸ¥')}
"""

    # åœ¨å¯¹åº”ç« èŠ‚åè¿½åŠ 
    pattern = f"## {section}"
    if pattern in content:
        content = content.replace(pattern, f"{pattern}\n{entry}")
    else:
        content += f"\n## {section}\n{entry}"

    with open(target_file, 'w', encoding='utf-8') as f:
        f.write(content)

def update_power_system(entity: Dict, target_file: str):
    """æ›´æ–°åŠ›é‡ä½“ç³».mdï¼ˆè¿½åŠ æ‹›å¼ï¼‰"""
    if not os.path.exists(target_file):
        content = f"""# åŠ›é‡ä½“ç³»

## å¢ƒç•Œåˆ’åˆ†

## ä¿®ç‚¼æ–¹æ³•

## æ‹›å¼åº“

"""
        with open(target_file, 'w', encoding='utf-8') as f:
            f.write(content)

    with open(target_file, 'r', encoding='utf-8') as f:
        content = f.read()

    entry = f"""
### {entity['name']}

{entity['desc']}

> é¦–æ¬¡ç™»åœº: {entity.get('source_file', 'æœªçŸ¥')}
"""

    if "## æ‹›å¼åº“" in content:
        content = content.replace("## æ‹›å¼åº“", f"## æ‹›å¼åº“\n{entry}")
    else:
        content += f"\n## æ‹›å¼åº“\n{entry}"

    with open(target_file, 'w', encoding='utf-8') as f:
        f.write(content)

def update_state_json(
    entities: List[Dict],
    state_file: str,
    golden_finger_skills: Optional[List[Dict]] = None,
    foreshadowing_items: Optional[List[Dict[str, Any]]] = None,
    relationship_items: Optional[List[Dict[str, Any]]] = None,
    entity_alias_ops: Optional[List[Dict[str, Any]]] = None,
    entity_update_ops: Optional[List[Dict[str, Any]]] = None,
    *,
    default_planted_chapter: Optional[int] = None,
):
    """æ›´æ–° state.jsonï¼ˆå®ä½“/åˆ«å/å±æ€§æ›´æ–° + é‡‘æ‰‹æŒ‡/ä¼ç¬”/å…³ç³»ï¼‰ã€‚"""

    def _to_int(value: Any, default: int = 0) -> int:
        try:
            return int(value)
        except (TypeError, ValueError):
            return default

    with open(state_file, 'r', encoding='utf-8') as f:
        state = json.load(f)

    first_seen_chapter = _to_int(default_planted_chapter, 0)
    project_root = Path(state_file).resolve().parent.parent

    # ç¡®ä¿å­˜åœ¨é‡‘æ‰‹æŒ‡æŠ€èƒ½åˆ—è¡¨
    if 'protagonist_state' not in state:
        state['protagonist_state'] = {}
    golden_finger = state['protagonist_state'].get('golden_finger')
    if not isinstance(golden_finger, dict):
        golden_finger = {}
        state['protagonist_state']['golden_finger'] = golden_finger
    golden_finger.setdefault("name", "")
    golden_finger.setdefault("level", 1)
    golden_finger.setdefault("cooldown", 0)
    golden_finger.setdefault("skills", [])

    # --- å®ä½“åˆ«å/æ›´æ–°ç³»ç»Ÿï¼ˆentities_v3 + alias_indexï¼‰---
    state = ensure_entities_v3_structure(state)

    entity_alias_ops = entity_alias_ops or []
    entity_update_ops = entity_update_ops or []

    touched = set()

    def _normalize_entity_type(raw: Any) -> str:
        t = normalize_entity_type(raw)
        if not t or t not in state.get("entities_v3", {}):
            return ""
        return t

    def _normalize_first_appearance(source_file: Any) -> str:
        raw = str(source_file or "").strip()
        if not raw:
            return ""
        try:
            p = Path(raw)
            if not p.is_absolute():
                p = (Path.cwd() / p).resolve()
            if p == project_root or project_root in p.parents:
                return str(p.relative_to(project_root)).replace("\\", "/")
            return str(p).replace("\\", "/")
        except Exception:
            return raw.replace("\\", "/")

    def _resolve_by_id(entity_id: Any, entity_type: Optional[str]) -> tuple[Optional[str], Optional[str], Optional[dict]]:
        eid = str(entity_id or "").strip()
        if not eid:
            return (None, None, None)

        if entity_type:
            et = _normalize_entity_type(entity_type)
            data = state.get("entities_v3", {}).get(et, {}).get(eid)
            return (et, eid, data) if isinstance(data, dict) else (None, None, None)

        hits: list[tuple[str, dict]] = []
        for et, bucket in (state.get("entities_v3") or {}).items():
            if isinstance(bucket, dict) and eid in bucket:
                data = bucket.get(eid)
                if isinstance(data, dict):
                    hits.append((et, data))
        if len(hits) == 1:
            return (hits[0][0], eid, hits[0][1])
        return (None, None, None)

    def _resolve_ref(ref: Any, entity_type: Optional[str]) -> tuple[Optional[str], Optional[str], Optional[dict]]:
        """é€šè¿‡åˆ«å/åç§°è§£æå®ä½“ï¼ˆv4.0 ä½¿ç”¨ä¸€å¯¹å¤š alias_indexï¼‰"""
        r = str(ref or "").strip()
        if not r:
            return (None, None, None)

        # ä½¿ç”¨æ–°ç‰ˆ resolve_entity_by_aliasï¼ˆæ”¯æŒä¸€å¯¹å¤š + æ­§ä¹‰æ£€æµ‹ï¼‰
        et_hint = _normalize_entity_type(entity_type) if entity_type else None
        et, eid, data = resolve_entity_by_alias(r, et_hint, state)
        if et and eid and isinstance(data, dict):
            return (et, eid, data)

        return (None, None, None)

    def _register_alias(entity_type: str, entity_id: str, alias: Any, *, context: str = "", first_seen: int = 0) -> None:
        """æ³¨å†Œåˆ«ååˆ° alias_indexï¼ˆv4.0 ä¸€å¯¹å¤šç‰ˆæœ¬ï¼‰"""
        a = str(alias or "").strip()
        if not a:
            return

        state.setdefault("alias_index", {})
        alias_index = state["alias_index"]

        # æ–°æ ¼å¼ï¼šalias_index[alias] = [{type, id, first_seen_chapter?, context?}, ...]
        entries = alias_index.get(a)
        if entries is None:
            entries = []
        if not isinstance(entries, list):
            raise ValueError(
                f"alias_index æ•°æ®æ ¼å¼é”™è¯¯ï¼šæœŸæœ› alias_index[{a!r}] ä¸º list[{{type,id,...}}]ï¼Œå®é™…ä¸º {type(entries).__name__}"
            )

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ (type, id) ç»„åˆ
        new_entry: Dict[str, Any] = {"type": entity_type, "id": entity_id}
        if first_seen:
            new_entry["first_seen_chapter"] = int(first_seen)
        if context:
            new_entry["context"] = context
        for existing in entries:
            if existing.get("type") == entity_type and existing.get("id") == entity_id:
                # è¡¥é½é¦–æ¬¡å‡ºç°/ä¸Šä¸‹æ–‡ï¼ˆåªå¡«ç©ºç¼ºï¼‰
                if first_seen and not existing.get("first_seen_chapter"):
                    existing["first_seen_chapter"] = int(first_seen)
                if context and not existing.get("context"):
                    existing["context"] = context
                return  # å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤æ³¨å†Œ

        # æ·»åŠ æ–°æ¡ç›®
        entries.append(new_entry)
        alias_index[a] = entries

        # åŒæ—¶æ›´æ–°å®ä½“çš„ aliases åˆ—è¡¨
        data = state.get("entities_v3", {}).get(entity_type, {}).get(entity_id)
        if not isinstance(data, dict):
            return
        data.setdefault("aliases", [])
        if a not in data["aliases"]:
            data["aliases"].append(a)

    def _ensure_v3_entity(entity_type: str, entity_id: str, canonical_name: str, *, tier: str, desc: str, first_appearance: str) -> dict:
        bucket = state.setdefault("entities_v3", {}).setdefault(entity_type, {})
        data = bucket.get(entity_id)
        if not isinstance(data, dict):
            data = {
                "id": entity_id,
                "canonical_name": canonical_name,
                "aliases": [],
                "tier": tier or "æ”¯çº¿",
                "desc": desc or "",
                "current": {},
                "history": [],
                "created_chapter": first_seen_chapter or 1,
                "first_appearance": first_appearance or "",
            }
            bucket[entity_id] = data

        if canonical_name and not data.get("canonical_name"):
            data["canonical_name"] = canonical_name
        if tier and str(tier).lower() in ENTITY_TIER_MAP:
            data["tier"] = tier
        if desc:
            data["desc"] = desc
        if first_appearance and not data.get("first_appearance"):
            data["first_appearance"] = first_appearance

        data.setdefault("current", {})
        data.setdefault("history", [])
        data.setdefault("aliases", [])
        return data

    def _apply_operations(entity_type: str, entity_id: str, data: dict, operations: List[Dict[str, Any]]) -> None:
        """åº”ç”¨å®ä½“æ›´æ–°æ“ä½œï¼ˆv4.0 æ”¯æŒ set/unset/add/remove/inc + é¡¶å±‚å­—æ®µï¼‰"""
        if not operations:
            return

        current = data.setdefault("current", {})
        changes: Dict[str, Any] = {}
        reasons: Dict[str, str] = {}

        def _rename(new_name: str, reason: str = "") -> None:
            new_name = str(new_name or "").strip()
            if not new_name:
                return
            old_name = str(data.get("canonical_name", "")).strip()
            if old_name and old_name != new_name:
                _register_alias(entity_type, entity_id, old_name, first_seen=first_seen_chapter)
            data["canonical_name"] = new_name
            _register_alias(entity_type, entity_id, new_name, first_seen=first_seen_chapter)
            changes["canonical_name"] = new_name
            if reason:
                reasons["canonical_name"] = reason

        for op_item in operations:
            op = str(op_item.get("op", "set")).strip().lower()
            key = str(op_item.get("key", "")).strip()
            reason = str(op_item.get("reason", "")).strip()
            if not key:
                continue

            # é¡¶å±‚å­—æ®µå¤„ç†
            if key in TOP_LEVEL_FIELDS:
                if op == "set":
                    value = str(op_item.get("value", "")).strip()
                    if key == "canonical_name":
                        _rename(value, reason)
                    elif key == "tier":
                        # æ ¡éªŒ tier å€¼
                        if value.lower() in ENTITY_TIER_MAP or value in {"æ ¸å¿ƒ", "æ”¯çº¿", "è£…é¥°"}:
                            if data.get("tier") != value:
                                data["tier"] = value
                                changes["tier"] = value
                                if reason:
                                    reasons["tier"] = reason
                        else:
                            print(f"âš ï¸ æ— æ•ˆ tier å€¼: {value}ï¼Œè·³è¿‡")
                    else:
                        if data.get(key) != value:
                            data[key] = value
                            changes[key] = value
                            if reason:
                                reasons[key] = reason
                elif op == "unset":
                    if key in data:
                        del data[key]
                        changes[key] = None
                        if reason:
                            reasons[key] = reason
                continue

            # canonical_name çš„ç‰¹æ®Šåˆ«å
            if key in {"name", "canonical_name"} and op == "set":
                value = str(op_item.get("value", "")).strip()
                _rename(value, reason)
                continue

            # current å­—æ®µæ“ä½œ
            if op == "set":
                value = str(op_item.get("value", "")).strip()
                prev = current.get(key)
                if prev != value:
                    current[key] = value
                    changes[key] = value
                    if reason:
                        reasons[key] = reason

            elif op == "unset":
                if key in current:
                    del current[key]
                    changes[key] = None
                    if reason:
                        reasons[key] = reason

            elif op == "add":
                value = str(op_item.get("value", "")).strip()
                if not value:
                    continue
                arr = current.get(key, [])
                if not isinstance(arr, list):
                    arr = [arr] if arr else []
                if value not in arr:
                    arr.append(value)
                    current[key] = arr
                    changes[key] = arr
                    if reason:
                        reasons[key] = reason

            elif op == "remove":
                value = str(op_item.get("value", "")).strip()
                if not value:
                    continue
                arr = current.get(key, [])
                if isinstance(arr, list) and value in arr:
                    arr.remove(value)
                    current[key] = arr
                    changes[key] = arr
                    if reason:
                        reasons[key] = reason

            elif op == "inc":
                delta = op_item.get("delta", 1)
                try:
                    delta = int(delta)
                except (TypeError, ValueError):
                    delta = 1
                prev = current.get(key, 0)
                try:
                    prev = int(prev)
                except (TypeError, ValueError):
                    prev = 0
                new_val = prev + delta
                current[key] = new_val
                changes[key] = new_val
                if reason:
                    reasons[key] = reason

        if first_seen_chapter:
            current["last_chapter"] = max(_to_int(current.get("last_chapter"), 0), first_seen_chapter)

        if changes:
            entry: Dict[str, Any] = {"chapter": first_seen_chapter or 0, "changes": changes}
            if reasons:
                entry["reasons"] = reasons
            entry["added_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            data.setdefault("history", []).append(entry)

    # 1) å¤„ç† <entity .../> / <entity>...</entity>
    for entity in entities or []:
        entity_type = _normalize_entity_type(entity.get("type", ""))
        name = str(entity.get("name", "")).strip()
        if not name:
            continue

        raw_id = entity.get("id")
        entity_id = (str(raw_id).strip() if raw_id is not None else "") or None
        data: Optional[dict] = None

        if entity_id:
            _, _, data = _resolve_by_id(entity_id, entity_type)
        else:
            _, rid, rdata = _resolve_ref(name, entity_type)
            if rid and isinstance(rdata, dict):
                entity_id = rid
                data = rdata

        if not entity_id:
            existing_ids = set((state.get("entities_v3") or {}).get(entity_type, {}).keys())
            entity_id = generate_entity_id(entity_type, name, existing_ids)

        first_appearance = _normalize_first_appearance(entity.get("source_file", ""))
        tier = str(entity.get("tier", "æ”¯çº¿")).strip() or "æ”¯çº¿"
        if tier.lower() not in ENTITY_TIER_MAP:
            tier = "æ”¯çº¿"
        desc = str(entity.get("desc", "")).strip()

        data = _ensure_v3_entity(entity_type, entity_id, name, tier=tier, desc=desc, first_appearance=first_appearance)

        # canonical name & aliases
        _register_alias(entity_type, entity_id, str(data.get("canonical_name", "")).strip() or name, first_seen=first_seen_chapter)
        _register_alias(entity_type, entity_id, name, first_seen=first_seen_chapter)
        for alias in (entity.get("aliases") or []):
            _register_alias(entity_type, entity_id, alias, first_seen=first_seen_chapter)

        # attribute updates (auto mode)
        extra_attrs = entity.get("attrs") or {}
        if isinstance(extra_attrs, dict) and extra_attrs:
            ops = [{"op": "set", "key": k, "value": str(v), "reason": ""} for k, v in extra_attrs.items()]
            _apply_operations(entity_type, entity_id, data, ops)

        touched.add((entity_type, entity_id))

    # 2) å¤„ç† <entity-alias .../>
    for op in entity_alias_ops:
        alias = str(op.get("alias", "")).strip()
        if not alias:
            continue

        hint = op.get("type")
        entity_type_hint = _normalize_entity_type(hint) if hint else None

        et: Optional[str] = None
        eid: Optional[str] = None
        data: Optional[dict] = None

        if op.get("id"):
            et, eid, data = _resolve_by_id(op.get("id"), entity_type_hint)
        elif op.get("ref"):
            et, eid, data = _resolve_ref(op.get("ref"), entity_type_hint)

        if not (et and eid and isinstance(data, dict)):
            print(f"??  entity-alias æ— æ³•è§£æå¼•ç”¨: id={op.get('id')!r} ref={op.get('ref')!r}")
            continue

        _register_alias(et, eid, alias, context=str(op.get("context", "")).strip(), first_seen=first_seen_chapter)
        touched.add((et, eid))

    # 3) å¤„ç† <entity-update>...</entity-update>
    for op in entity_update_ops:
        operations = op.get("operations") or []
        if not isinstance(operations, list) or not operations:
            continue

        hint = op.get("type")
        entity_type_hint = _normalize_entity_type(hint) if hint else None

        et: Optional[str] = None
        eid: Optional[str] = None
        data: Optional[dict] = None

        if op.get("id"):
            et, eid, data = _resolve_by_id(op.get("id"), entity_type_hint)
        elif op.get("ref"):
            et, eid, data = _resolve_ref(op.get("ref"), entity_type_hint)

        if not (et and eid and isinstance(data, dict)):
            print(f"âš ï¸ entity-update æ— æ³•è§£æå¼•ç”¨: id={op.get('id')!r} ref={op.get('ref')!r}")
            continue

        _apply_operations(et, eid, data, operations)
        touched.add((et, eid))

    # 4) æ›´æ–°é‡‘æ‰‹æŒ‡æŠ€èƒ½
    if golden_finger_skills:
        existing = state['protagonist_state']['golden_finger'].get('skills', [])
        if not isinstance(existing, list):
            existing = []
            state['protagonist_state']['golden_finger']['skills'] = existing

        existing_by_name = {s.get("name"): s for s in existing if isinstance(s, dict) and s.get("name")}
        for skill in golden_finger_skills:
            if not isinstance(skill, dict):
                continue

            name = str(skill.get("name", "")).strip()
            if not name:
                continue

            level = str(skill.get("level", "")).strip()
            desc = str(skill.get("desc", "")).strip()
            cooldown = str(skill.get("cooldown", "")).strip()
            source_file = str(skill.get("source_file", "")).strip()

            existing_skill = existing_by_name.get(name)
            if existing_skill is None:
                new_skill = {
                    "name": name,
                    "level": level,
                    "desc": desc,
                    "cooldown": cooldown,
                    "unlocked_at": source_file,
                    "added_at": datetime.now().strftime('%Y-%m-%d')
                }
                existing.append(new_skill)
                existing_by_name[name] = new_skill
                print(f"  âœ¨ æ–°å¢é‡‘æ‰‹æŒ‡æŠ€èƒ½: {name} ({level})")
                continue

            changed = False
            if level and existing_skill.get("level") != level:
                existing_skill["level"] = level
                changed = True
            if desc and existing_skill.get("desc") != desc:
                existing_skill["desc"] = desc
                changed = True
            if cooldown and existing_skill.get("cooldown") != cooldown:
                existing_skill["cooldown"] = cooldown
                changed = True
            if source_file and not existing_skill.get("unlocked_at"):
                existing_skill["unlocked_at"] = source_file
                changed = True

            if changed:
                existing_skill["updated_at"] = datetime.now().strftime('%Y-%m-%d')
                print(f"  ğŸ” æ›´æ–°é‡‘æ‰‹æŒ‡æŠ€èƒ½: {name} ({existing_skill.get('level', level)})")

    # æ›´æ–°ä¼ç¬”ï¼ˆç»“æ„åŒ–ï¼‰
    if foreshadowing_items:
        state.setdefault("plot_threads", {"active_threads": [], "foreshadowing": []})
        state["plot_threads"].setdefault("foreshadowing", [])

        existing = state["plot_threads"]["foreshadowing"]

        for item in foreshadowing_items:
            content = str(item.get("content", "")).strip()
            if not content:
                continue

            planted = item.get("planted_chapter") or default_planted_chapter or 1
            try:
                planted = int(planted)
            except (TypeError, ValueError):
                planted = default_planted_chapter or 1

            target = item.get("target_chapter")
            if target is None:
                target = planted + 100
            try:
                target = int(target)
            except (TypeError, ValueError):
                target = planted + 100

            tier = str(item.get("tier", "æ”¯çº¿")).strip() or "æ”¯çº¿"
            if tier.lower() not in ENTITY_TIER_MAP:
                tier = "æ”¯çº¿"

            location = str(item.get("location", "")).strip()
            characters = item.get("characters", [])
            if not isinstance(characters, list):
                characters = []

            found = None
            for old in existing:
                if old.get("content") == content:
                    found = old
                    break

            if found is None:
                existing.append({
                    "content": content,
                    "status": "æœªå›æ”¶",
                    "tier": tier,
                    "planted_chapter": planted,
                    "target_chapter": target,
                    "location": location,
                    "characters": characters,
                    "added_at": datetime.now().strftime("%Y-%m-%d"),
                })
                print(f"  ?? æ–°å¢ä¼ç¬”: {content[:30]}...")
            else:
                found["tier"] = tier
                found["planted_chapter"] = planted
                found["target_chapter"] = target
                if location:
                    found["location"] = location

                old_chars = found.get("characters", [])
                if not isinstance(old_chars, list):
                    old_chars = []
                merged = []
                seen = set()
                for n in [*old_chars, *characters]:
                    s = str(n).strip()
                    if not s or s in seen:
                        continue
                    merged.append(s)
                    seen.add(s)
                found["characters"] = merged

    # æ›´æ–°å…³ç³»ï¼ˆç»“æ„åŒ–ï¼Œæ¨èä½¿ç”¨ entity_idï¼‰
    if relationship_items:
        state.setdefault("structured_relationships", [])
        existing = state["structured_relationships"]

        for item in relationship_items:
            # ä¼˜å…ˆä½¿ç”¨æ˜¾å¼ entity_idï¼›å¦åˆ™æŒ‰åˆ«åè§£æï¼ˆå¼ºåˆ¶æ¶ˆæ­§ï¼‰
            char1_id = str(item.get("char1_id", "") or "").strip()
            char2_id = str(item.get("char2_id", "") or "").strip()
            char1_ref = str(item.get("char1", "")).strip()
            char2_ref = str(item.get("char2", "")).strip()

            # relationship åªå…è®¸è§’è‰²
            if char1_id:
                _, rid, rdata = _resolve_by_id(char1_id, "è§’è‰²")
                if not rid or not isinstance(rdata, dict):
                    raise ValueError(f"relationship.char1_id æ— æ³•è§£æ: {char1_id!r}")
                char1_id = rid
                char1_name = str(rdata.get("canonical_name", "")).strip() or char1_ref
            else:
                _, rid, rdata = _resolve_ref(char1_ref, "è§’è‰²")
                if not rid or not isinstance(rdata, dict):
                    raise ValueError(f"relationship.char1 æ— æ³•è§£æ: {char1_ref!r}")
                char1_id = rid
                char1_name = str(rdata.get("canonical_name", "")).strip() or char1_ref

            if char2_id:
                _, rid, rdata = _resolve_by_id(char2_id, "è§’è‰²")
                if not rid or not isinstance(rdata, dict):
                    raise ValueError(f"relationship.char2_id æ— æ³•è§£æ: {char2_id!r}")
                char2_id = rid
                char2_name = str(rdata.get("canonical_name", "")).strip() or char2_ref
            else:
                _, rid, rdata = _resolve_ref(char2_ref, "è§’è‰²")
                if not rid or not isinstance(rdata, dict):
                    raise ValueError(f"relationship.char2 æ— æ³•è§£æ: {char2_ref!r}")
                char2_id = rid
                char2_name = str(rdata.get("canonical_name", "")).strip() or char2_ref

            rel_type = str(item.get("type", "ally")).strip().lower() or "ally"
            intensity = item.get("intensity", 50)
            desc = str(item.get("desc", "")).strip()

            try:
                intensity = int(intensity)
                intensity = max(0, min(100, intensity))
            except (TypeError, ValueError):
                intensity = 50

            # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå…³ç³»
            found = None
            for old in existing:
                if (
                    old.get("char1_id") == char1_id
                    and old.get("char2_id") == char2_id
                    and old.get("type") == rel_type
                ):
                    found = old
                    break

            if found is None:
                existing.append({
                    "char1_id": char1_id,
                    "char2_id": char2_id,
                    "char1_name": char1_name,
                    "char2_name": char2_name,
                    "type": rel_type,
                    "intensity": intensity,
                    "description": desc,
                    "last_update_chapter": default_planted_chapter or 1,
                    "added_at": datetime.now().strftime("%Y-%m-%d"),
                })
                print(f"  ğŸ’• æ–°å¢å…³ç³»: {char1_name} â†” {char2_name} ({rel_type}, å¼ºåº¦ {intensity})")
            else:
                # æ›´æ–°å¼ºåº¦å’Œæè¿°
                found["intensity"] = intensity
                found["description"] = desc
                found["last_update_chapter"] = default_planted_chapter or found.get("last_update_chapter", 1)
                found.setdefault("char1_name", char1_name)
                found.setdefault("char2_name", char2_name)
                print(f"  ğŸ’• æ›´æ–°å…³ç³»: {char1_name} â†” {char2_name} ({rel_type}, å¼ºåº¦ {intensity})")

    # ä½¿ç”¨é›†ä¸­å¼åŸå­å†™å…¥ï¼ˆå¸¦ filelock + è‡ªåŠ¨å¤‡ä»½ï¼‰
    atomic_write_json(state_file, state, use_lock=True, backup=True)
    print(f"âœ… state.json å·²åŸå­åŒ–æ›´æ–°ï¼ˆå¸¦å¤‡ä»½ï¼‰")

def sync_entity_to_settings(entity: Dict, project_root: str, auto_mode: bool = False) -> bool:
    """
    å°†å®ä½“åŒæ­¥åˆ°è®¾å®šé›†

    Returns:
        bool: æ˜¯å¦æˆåŠŸåŒæ­¥
    """
    entity_type = normalize_entity_type(entity.get('type'))
    entity_name = entity['name']

    if entity_type == "è§’è‰²":
        category = categorize_character(entity['desc'])
        category_dir = ROLE_CATEGORY_MAP.get(category.split('/')[0], "æ¬¡è¦è§’è‰²")

        target_dir = Path(project_root) / f"è®¾å®šé›†/è§’è‰²åº“/{category_dir}"
        # ============================================================================
        # å®‰å…¨ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨ç›®å½•åˆ›å»ºå‡½æ•°ï¼ˆæ–‡ä»¶æƒé™ä¿®å¤ï¼‰
        # ============================================================================
        create_secure_directory(str(target_dir))

        # ============================================================================
        # å®‰å…¨ä¿®å¤ï¼šæ¸…ç†æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„éå† (CWE-22) - P0 CRITICAL
        # åŸä»£ç : target_file = target_dir / f"{entity_name}.md"
        # æ¼æ´: entity_nameå¯èƒ½åŒ…å« "../" å¯¼è‡´ç›®å½•éå†æ”»å‡»
        # ============================================================================
        safe_entity_name = sanitize_filename(entity_name)
        target_file = target_dir / f"{safe_entity_name}.md"

        if target_file.exists():
            print(f"âš ï¸  è§’è‰²å¡å·²å­˜åœ¨: {target_file}")
            if not auto_mode:
                choice = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/n): ")
                if choice.lower() != 'y':
                    return False

        with open(target_file, 'w', encoding='utf-8') as f:
            f.write(generate_character_card(entity, category))

        print(f"âœ… å·²åˆ›å»ºè§’è‰²å¡: {target_file}")
        return True

    elif entity_type == "åœ°ç‚¹":
        target_file = Path(project_root) / "è®¾å®šé›†/ä¸–ç•Œè§‚.md"
        update_world_view(entity, str(target_file), "åœ°ç†")
        print(f"âœ… å·²æ›´æ–°ä¸–ç•Œè§‚ï¼ˆåœ°ç†ï¼‰: {entity_name}")
        return True

    elif entity_type == "åŠ¿åŠ›":
        target_file = Path(project_root) / "è®¾å®šé›†/ä¸–ç•Œè§‚.md"
        update_world_view(entity, str(target_file), "åŠ¿åŠ›")
        print(f"âœ… å·²æ›´æ–°ä¸–ç•Œè§‚ï¼ˆåŠ¿åŠ›ï¼‰: {entity_name}")
        return True

    elif entity_type == "æ‹›å¼":
        target_file = Path(project_root) / "è®¾å®šé›†/åŠ›é‡ä½“ç³».md"
        update_power_system(entity, str(target_file))
        print(f"âœ… å·²æ›´æ–°åŠ›é‡ä½“ç³»ï¼ˆæ‹›å¼ï¼‰: {entity_name}")
        return True

    elif entity_type == "ç‰©å“":
        target_dir = Path(project_root) / "è®¾å®šé›†/ç‰©å“åº“"
        # ============================================================================
        # å®‰å…¨ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨ç›®å½•åˆ›å»ºå‡½æ•°ï¼ˆæ–‡ä»¶æƒé™ä¿®å¤ï¼‰
        # ============================================================================
        create_secure_directory(str(target_dir))

        # ============================================================================
        # å®‰å…¨ä¿®å¤ï¼šæ¸…ç†æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„éå† (CWE-22) - P0 CRITICAL
        # åŸä»£ç : target_file = target_dir / f"{entity_name}.md"
        # æ¼æ´: entity_nameå¯èƒ½åŒ…å« "../" å¯¼è‡´ç›®å½•éå†æ”»å‡»
        # ============================================================================
        safe_entity_name = sanitize_filename(entity_name)
        target_file = target_dir / f"{safe_entity_name}.md"

        if target_file.exists():
            print(f"âš ï¸  ç‰©å“å¡å·²å­˜åœ¨: {target_file}")
            if not auto_mode:
                choice = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/n): ")
                if choice.lower() != 'y':
                    return False

        content = f"""# {entity_name}

> **é¦–æ¬¡ç™»åœº**: {entity.get('source_file', 'æœªçŸ¥')}
> **åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d')}

## åŸºæœ¬ä¿¡æ¯

{entity['desc']}

## è¯¦ç»†è®¾å®š

å¾…è¡¥å……

## ç›¸å…³å‰§æƒ…

- ã€ç¬¬ X ç« ã€‘é¦–æ¬¡å‡ºç°

## å¤‡æ³¨

è‡ªåŠ¨æå–è‡ª `<entity/>` æ ‡ç­¾ï¼Œè¯·è¡¥å……å®Œå–„ã€‚
"""

        with open(target_file, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… å·²åˆ›å»ºç‰©å“å¡: {target_file}")
        return True

    else:
        print(f"âš ï¸  æœªçŸ¥å®ä½“ç±»å‹: {entity_type}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description="XML æ ‡ç­¾æå–ä¸åŒæ­¥ (<entity/>, <entity-alias/>, <entity-update>, <skill/>, <foreshadow/>, <deviation/>, <relationship/>)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # æŒ‡å®šæ–‡ä»¶ï¼ˆå…¼å®¹å·ç›®å½•ï¼‰
  python extract_entities.py "webnovel-project/æ­£æ–‡/ç¬¬1å·/ç¬¬001ç« -æ­»äº¡é™ä¸´.md" --auto

  # æŒ‡å®šç« èŠ‚å·ï¼ˆæ¨èï¼‰
  python extract_entities.py --project-root "webnovel-project" --chapter 1 --auto
""".strip(),
    )

    parser.add_argument("chapter_file", nargs="?", help="ç« èŠ‚æ–‡ä»¶è·¯å¾„ï¼ˆæˆ–ä½¿ç”¨ --chapterï¼‰")
    parser.add_argument("--chapter", type=int, help="ç« èŠ‚å·ï¼ˆä¸ --project-root é…åˆï¼Œè‡ªåŠ¨å®šä½ç« èŠ‚æ–‡ä»¶ï¼‰")
    parser.add_argument("--project-root", default=None, help="é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« .webnovel/state.jsonï¼‰")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¨¡å¼ï¼ˆéäº¤äº’ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…é¢„è§ˆï¼Œä¸å†™å…¥æ–‡ä»¶/çŠ¶æ€")

    args = parser.parse_args()

    auto_mode = args.auto
    dry_run = args.dry_run

    project_root: Optional[Path] = None
    if args.project_root:
        project_root = resolve_project_root(args.project_root)
    else:
        try:
            project_root = resolve_project_root()
        except FileNotFoundError:
            project_root = None

    chapter_file: Optional[str] = None
    chapter_num: Optional[int] = None

    if args.chapter is not None:
        if not project_root:
            print("âŒ æœªæä¾›æœ‰æ•ˆçš„ --project-rootï¼Œæ— æ³•ç”¨ --chapter å®šä½ç« èŠ‚æ–‡ä»¶")
            sys.exit(1)

        chapter_num = int(args.chapter)
        chapter_path = find_chapter_file(project_root, chapter_num)
        if not chapter_path:
            print(f"âŒ æœªæ‰¾åˆ°ç¬¬{chapter_num}ç« æ–‡ä»¶ï¼ˆè¯·å…ˆç”Ÿæˆ/ä¿å­˜ç« èŠ‚ï¼‰")
            sys.exit(1)
        chapter_file = str(chapter_path)
    else:
        if not args.chapter_file:
            parser.error("å¿…é¡»æä¾› chapter_file æˆ– --chapter")
        chapter_file = args.chapter_file
        if not os.path.exists(chapter_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {chapter_file}")
            sys.exit(1)

        chapter_num = extract_chapter_num_from_filename(Path(chapter_file).name)

    print(f"ğŸ“– æ­£åœ¨æ‰«æ: {chapter_file}")
    entities = extract_new_entities(chapter_file)
    entity_alias_ops = extract_entity_alias_ops(chapter_file)
    entity_update_ops = extract_entity_update_ops(chapter_file)
    golden_finger_skills = extract_golden_finger_skills(chapter_file)
    foreshadowing_items = extract_foreshadowing_json(chapter_file)
    deviations = extract_deviations(chapter_file)
    relationship_items = extract_relationships(chapter_file)

    if not entities and not entity_alias_ops and not entity_update_ops and not golden_finger_skills and not foreshadowing_items and not deviations and not relationship_items:
        print("âœ… æœªå‘ç°ä»»ä½• XML æ ‡ç­¾ï¼ˆ<entity>/<entity-alias>/<entity-update>/<skill>/<foreshadow>/<deviation>/<relationship>ï¼‰")
        return

    if entities:
        print(f"\nğŸ” å‘ç° {len(entities)} ä¸ªæ–°å®ä½“ï¼š")
        for i, entity in enumerate(entities, 1):
            tier_emoji = {"æ ¸å¿ƒ": "ğŸ”´", "æ”¯çº¿": "ğŸŸ¡", "è£…é¥°": "ğŸŸ¢"}.get(entity.get("tier", "æ”¯çº¿"), "âšª")
            print(
                f"  {i}. [{entity['type']}] {entity['name']} {tier_emoji}{entity.get('tier', 'æ”¯çº¿')} - {entity['desc'][:25]}..."
            )

    if golden_finger_skills:
        print(f"\nâœ¨ å‘ç° {len(golden_finger_skills)} ä¸ªé‡‘æ‰‹æŒ‡æŠ€èƒ½ï¼š")
        for i, skill in enumerate(golden_finger_skills, 1):
            print(f"  {i}. {skill['name']} ({skill['level']}) - {skill['desc'][:25]}...")

    if entity_alias_ops:
        print(f"\nğŸ·ï¸ å‘ç° {len(entity_alias_ops)} æ¡å®ä½“åˆ«åï¼š")
        for i, op in enumerate(entity_alias_ops, 1):
            ref = op.get("id") or op.get("ref") or "?"
            print(f"  {i}. {ref} -> {op.get('alias', '')}")

    if entity_update_ops:
        print(f"\nğŸ› ï¸ å‘ç° {len(entity_update_ops)} æ¡å®ä½“æ›´æ–°ï¼š")
        for i, op in enumerate(entity_update_ops, 1):
            ref = op.get("id") or op.get("ref") or "?"
            operations = op.get("operations") or []
            ops_preview = []
            for o in operations[:6]:
                if isinstance(o, dict):
                    op_type = o.get("op", "set")
                    key = o.get("key", "")
                    ops_preview.append(f"{op_type}:{key}")
            preview = ", ".join(ops_preview) + ("..." if len(operations) > 6 else "")
            print(f"  {i}. {ref}: {preview}")

    if foreshadowing_items:
        print(f"\nğŸ§© å‘ç° {len(foreshadowing_items)} æ¡ä¼ç¬”ï¼š")
        for i, item in enumerate(foreshadowing_items, 1):
            tier = item.get("tier", "æ”¯çº¿")
            target = item.get("target_chapter", "æœªè®¾å®š")
            print(f"  {i}. {tier} â†’ ç›®æ ‡Ch{target}: {str(item.get('content', ''))[:40]}...")

    if deviations:
        print(f"\nâš¡ å‘ç° {len(deviations)} æ¡å¤§çº²åç¦»ï¼š")
        for i, dev in enumerate(deviations, 1):
            print(f"  {i}. {dev.get('reason', '')[:50]}...")

    if relationship_items:
        print(f"\nğŸ’• å‘ç° {len(relationship_items)} æ¡å…³ç³»ï¼š")
        for i, rel in enumerate(relationship_items, 1):
            char1 = str(rel.get("char1") or rel.get("char1_id") or "").strip() or "?"
            char2 = str(rel.get("char2") or rel.get("char2_id") or "").strip() or "?"
            print(f"  {i}. {char1} â†” {char2} ({rel['type']}, å¼ºåº¦ {rel['intensity']})")

    if dry_run:
        print("\nâš ï¸  Dry-run æ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…å†™å…¥")
        return

    if not project_root:
        chapter_path = Path(chapter_file).resolve()
        for parent in [chapter_path.parent] + list(chapter_path.parents):
            if (parent / ".webnovel" / "state.json").exists():
                project_root = parent
                break

    if not project_root:
        print("âŒ æ‰¾ä¸åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆç¼ºå°‘ .webnovel/state.jsonï¼‰")
        print("è¯·å…ˆè¿è¡Œ /webnovel-init åˆå§‹åŒ–é¡¹ç›®ï¼Œæˆ–ä½¿ç”¨ --project-root æŒ‡å®šè·¯å¾„")
        sys.exit(1)

    state_file = resolve_state_file(explicit_project_root=str(project_root))

    print("\nğŸ“ å¼€å§‹åŒæ­¥åˆ°è®¾å®šé›†...")
    success_count = 0
    for entity in entities:
        if sync_entity_to_settings(entity, str(project_root), auto_mode):
            success_count += 1

    print("\nğŸ’¾ æ›´æ–° state.json...")
    try:
        update_state_json(
            entities=entities,
            state_file=str(state_file),
            golden_finger_skills=golden_finger_skills,
            foreshadowing_items=foreshadowing_items,
            relationship_items=relationship_items,
            entity_alias_ops=entity_alias_ops,
            entity_update_ops=entity_update_ops,
            default_planted_chapter=chapter_num,
        )
    except (AmbiguousAliasError, ValueError) as e:
        print(f"âŒ {e}")
        sys.exit(2)

    print("\nâœ… å®Œæˆï¼")
    print(f"  - å®ä½“åŒæ­¥: {success_count}/{len(entities)} ä¸ª")
    if golden_finger_skills:
        print(f"  - é‡‘æ‰‹æŒ‡æŠ€èƒ½: {len(golden_finger_skills)} ä¸ª")
    if foreshadowing_items:
        print(f"  - ä¼ç¬”åŒæ­¥: {len(foreshadowing_items)} æ¡")
    if relationship_items:
        print(f"  - å…³ç³»åŒæ­¥: {len(relationship_items)} æ¡")
    if deviations:
        print(f"  - å¤§çº²åç¦»: {len(deviations)} æ¡ï¼ˆä»…è®°å½•ï¼Œä¸åŒæ­¥åˆ° state.jsonï¼‰")

    if not auto_mode:
        print("\nğŸ’¡ å»ºè®®:")
        print("  1. æ£€æŸ¥ç”Ÿæˆçš„è§’è‰²å¡/ç‰©å“å¡ï¼Œè¡¥å……è¯¦ç»†è®¾å®š")
        print("  2. æŸ¥çœ‹ ä¸–ç•Œè§‚.md å’Œ åŠ›é‡ä½“ç³».md çš„æ›´æ–°")
        print("  3. ç¡®è®¤ .webnovel/state.json ä¸­çš„å®ä½“è®°å½•")
        if golden_finger_skills:
            print("  4. æ£€æŸ¥é‡‘æ‰‹æŒ‡æŠ€èƒ½æ˜¯å¦æ­£ç¡®è®°å½•åœ¨ protagonist_state.golden_finger.skills")
        if foreshadowing_items:
            print("  5. æ£€æŸ¥ plot_threads.foreshadowing çš„ planted/target/tier/location/characters æ˜¯å¦åˆç†")
        if relationship_items:
            print("  6. æ£€æŸ¥ structured_relationships å…³ç³»è®°å½•æ˜¯å¦åˆç†")
        if deviations:
            print("  7. å¤§çº²åç¦»å·²è®°å½•ï¼Œè¯·åœ¨ plan.md æˆ–å¤§çº²ä¸­åŒæ­¥è°ƒæ•´")

if __name__ == "__main__":
    main()
