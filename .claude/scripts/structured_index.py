#!/usr/bin/env python3
"""
ç»“æ„åŒ–ç´¢å¼•ç³»ç»Ÿï¼ˆStructured Index Systemï¼‰v4.0

ç›®æ ‡ï¼šå–ä»£å‘é‡åŒ–æ£€ç´¢ï¼Œä½¿ç”¨ SQLite æä¾›ç²¾ç¡®ã€å¿«é€Ÿçš„ç»“æ„åŒ–æŸ¥è¯¢

v4.0 å˜æ›´ï¼š
- æ–°å¢ entities/entity_aliases/entity_kv/entity_history è¡¨
- ä¸»é”®ä» name è¿ç§»åˆ° entity_id
- relationships è¡¨ä½¿ç”¨ char1_id/char2_id
- ä¸å†å†™å› state.jsonï¼ˆæ¶ˆé™¤å¾ªç¯ä¾èµ–ï¼‰
- ä» entities_v3 + alias_index åŒæ­¥æ•°æ®

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å®ä½“ç´¢å¼•ï¼ˆentities, entity_aliases, entity_kv, entity_historyï¼‰
2. ç« èŠ‚å…ƒæ•°æ®ç´¢å¼•ï¼ˆlocation, characters, word_countï¼‰
3. ä¼ç¬”è¿½è¸ªç´¢å¼•ï¼ˆstatus, urgency calculationï¼‰
4. æ–‡ä»¶ Hash è‡ªæ„ˆæœºåˆ¶ï¼ˆauto-rebuild on changeï¼‰

æ€§èƒ½ç›®æ ‡ï¼š
- æŸ¥è¯¢é€Ÿåº¦ï¼š2-5msï¼ˆvs æ–‡ä»¶éå† 500msï¼Œæå‡ 250xï¼‰
- ç´¢å¼•æ„å»ºï¼š10ms/ç« ï¼ˆå¢é‡æ›´æ–°ï¼‰
- å­˜å‚¨å¼€é”€ï¼š200 ç«  â‰ˆ 100 KB

ä½¿ç”¨æ–¹å¼ï¼š
  # æ›´æ–°å•ç« ç´¢å¼•
  python structured_index.py --update-chapter 7 --metadata-file /tmp/ch7.json

  # æ‰¹é‡é‡å»ºç´¢å¼•ï¼ˆå†å²ç« èŠ‚ï¼‰
  python structured_index.py --rebuild-index

  # æŸ¥è¯¢åœ°ç‚¹ç›¸å…³ç« èŠ‚
  python structured_index.py --query-location "è¡€ç…ç§˜å¢ƒ"

  # æŸ¥è¯¢ç´§æ€¥ä¼ç¬”
  python structured_index.py --query-urgent-foreshadowing

  # æ¨¡ç³ŠæŸ¥è¯¢è§’è‰²
  python structured_index.py --fuzzy-search "å§“æ" "å¥³å¼Ÿå­"

  # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
  python structured_index.py --stats
"""

import json
import os
import sys
import argparse
import sqlite3
import hashlib
import re
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Tuple

# ============================================================================
# å®‰å…¨ä¿®å¤ï¼šå¯¼å…¥å®‰å…¨å·¥å…·å‡½æ•°ï¼ˆP1 MEDIUMï¼‰
# ============================================================================
from security_utils import create_secure_directory
from project_locator import resolve_project_root
from chapter_paths import find_chapter_file


class StructuredIndex:
    """ç»“æ„åŒ–ç´¢å¼•ç®¡ç†å™¨ï¼ˆå–ä»£å‘é‡åŒ–æ£€ç´¢ï¼‰"""

    def __init__(self, project_root=None):
        if project_root is None:
            try:
                project_root = resolve_project_root()
            except FileNotFoundError:
                project_root = Path.cwd()
        else:
            project_root = Path(project_root)

        self.project_root = project_root
        self.state_file = project_root / ".webnovel" / "state.json"
        self.chapters_dir = project_root / "æ­£æ–‡"
        self.index_db = project_root / ".webnovel" / "index.db"

        # ============================================================================
        # å®‰å…¨ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨ç›®å½•åˆ›å»ºå‡½æ•°ï¼ˆP1 MEDIUMï¼‰
        # åŸä»£ç : self.index_db.parent.mkdir(parents=True, exist_ok=True)
        # æ¼æ´: æœªè®¾ç½®æƒé™ï¼Œä½¿ç”¨OSé»˜è®¤ï¼ˆå¯èƒ½ä¸º755ï¼Œå…è®¸åŒç»„ç”¨æˆ·è¯»å–ï¼‰
        # ============================================================================
        create_secure_directory(str(self.index_db.parent))

        # è¿æ¥æ•°æ®åº“
        self.conn = sqlite3.connect(str(self.index_db))
        self.conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸å¼è¡Œ

        # åˆ›å»ºè¡¨ç»“æ„
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºç´¢å¼•è¡¨ç»“æ„ï¼ˆv4.0 ä¸»é”®è¿ç§»åˆ° entity_idï¼‰"""

        # ============== æ–°å¢å®ä½“è¡¨ï¼ˆv4.0ï¼‰==============

        # å®ä½“ä¸»è¡¨ï¼ˆå–ä»£æ—§ characters è¡¨ï¼‰
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS entities (
                entity_id TEXT PRIMARY KEY,
                entity_type TEXT NOT NULL,
                canonical_name TEXT,
                tier TEXT,
                desc TEXT,
                created_chapter INTEGER,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # å®ä½“ç±»å‹ç´¢å¼•
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_entity_type
            ON entities(entity_type)
        """)

        # åˆ«åè¡¨ï¼ˆæ”¯æŒä¸€å¯¹å¤šæŸ¥è¯¢ï¼‰
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS entity_aliases (
                alias TEXT,
                entity_id TEXT,
                entity_type TEXT,
                first_seen_chapter INTEGER,
                context TEXT,
                PRIMARY KEY (alias, entity_id)
            )
        """)

        # åˆ«åç´¢å¼•ï¼ˆåŠ é€Ÿåå‘æŸ¥è¯¢ï¼‰
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_alias
            ON entity_aliases(alias)
        """)

        # å®ä½“å±æ€§ KV è¡¨
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS entity_kv (
                entity_id TEXT,
                key TEXT,
                value TEXT,
                last_chapter INTEGER,
                PRIMARY KEY (entity_id, key)
            )
        """)

        # å®ä½“å†å²è¡¨
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS entity_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                entity_id TEXT,
                chapter INTEGER,
                changes_json TEXT,
                reasons_json TEXT,
                added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # å†å²ç´¢å¼•
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_entity_history
            ON entity_history(entity_id, chapter)
        """)

        # ============== ç« èŠ‚å…ƒæ•°æ®è¡¨ ==============

        # 1. ç« èŠ‚å…ƒæ•°æ®è¡¨ï¼ˆv4.0: characters æ”¹ä¸ºå­˜ entity_id åˆ—è¡¨ï¼‰
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS chapters (
                chapter_num INTEGER PRIMARY KEY,
                title TEXT,
                location TEXT,
                location_id TEXT,
                characters TEXT,  -- JSON: ["entity_id_1", "entity_id_2"]
                word_count INTEGER,
                content_hash TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # åœ°ç‚¹ç´¢å¼•ï¼ˆåŠ é€ŸæŸ¥è¯¢ï¼‰
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_location
            ON chapters(location)
        """)

        # 2. ä¼ç¬”è¿½è¸ªè¡¨
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS foreshadowing_index (
                id INTEGER PRIMARY KEY,
                content TEXT,
                location TEXT,
                characters TEXT,  -- JSON: ["æé›ª", "ä¸»è§’"]
                introduced_chapter INTEGER,
                resolved_chapter INTEGER,
                status TEXT,  -- 'æœªå›æ”¶' / 'å·²å›æ”¶'
                urgency INTEGER DEFAULT 0,  -- 0-100ï¼Œè‡ªåŠ¨è®¡ç®—
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # çŠ¶æ€ç´¢å¼•
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_status
            ON foreshadowing_index(status)
        """)

        # ç´§æ€¥åº¦ç´¢å¼•
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_urgency
            ON foreshadowing_index(urgency)
        """)

        # 3. è§’è‰²å…³ç³»è¡¨ï¼ˆv4.0: ä½¿ç”¨ entity_idï¼‰
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS relationships (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                char1_id TEXT,
                char2_id TEXT,
                char1_name TEXT,
                char2_name TEXT,
                relation_type TEXT,  -- 'ally', 'enemy', 'romance', 'mentor', 'debtor'
                intensity INTEGER,    -- å…³ç³»å¼ºåº¦ 0-100
                description TEXT,
                last_update_chapter INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(char1_id, char2_id, relation_type)  -- é˜²æ­¢é‡å¤
            )
        """)

        # å…³ç³»ç´¢å¼•ï¼ˆv4.0: ä½¿ç”¨ entity_idï¼‰
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_char1_char2
            ON relationships(char1_id, char2_id)
        """)

        # 4. è§’è‰²ç´¢å¼•è¡¨ï¼ˆv4.0 å·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹ï¼‰
        # æ–°ä»£ç åº”ä½¿ç”¨ entities è¡¨
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS characters (
                name TEXT PRIMARY KEY,
                description TEXT,
                personality TEXT,
                importance TEXT,  -- 'major' / 'minor'
                power_level TEXT,
                first_appearance INTEGER,
                last_appearance INTEGER,
                status TEXT DEFAULT 'active',  -- 'active' / 'archived'
                archived_at TEXT,  -- ISO timestamp
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # è§’è‰²åç´¢å¼•ï¼ˆåŠ é€Ÿæ¨¡ç³Šæœç´¢ï¼‰
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_character_name
            ON characters(name)
        """)

        # çŠ¶æ€ç´¢å¼•
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_character_status
            ON characters(status)
        """)

        self.conn.commit()

    # ================== æ ¸å¿ƒåŠŸèƒ½ 1ï¼šç« èŠ‚å…ƒæ•°æ®ç´¢å¼• ==================

    def index_chapter(self, chapter_num: int, metadata: Dict):
        """ä¸ºæ–°ç« èŠ‚å»ºç«‹ç´¢å¼•ï¼ˆåœ¨ webnovel-write Step 4.6 è°ƒç”¨ï¼‰

        Args:
            chapter_num: ç« èŠ‚ç¼–å·
            metadata: {
                'title': 'ç« èŠ‚æ ‡é¢˜',
                'location': 'åœ°ç‚¹',
                'characters': ['æé›ª', 'ä¸»è§’'],
                'word_count': 3500,
                'hash': 'md5_hash'
            }
        """
        def _normalize_str_list(v) -> List[str]:
            if v is None:
                return []
            if isinstance(v, list):
                return [str(x).strip() for x in v if str(x).strip()]
            if isinstance(v, str):
                return [s.strip() for s in re.split(r"[,ï¼Œ]", v) if s.strip()]
            return [str(v).strip()] if str(v).strip() else []

        def _exists_entity(entity_id: str, entity_type: str) -> bool:
            row = self.conn.execute(
                "SELECT 1 FROM entities WHERE entity_id = ? AND entity_type = ? LIMIT 1",
                (entity_id, entity_type),
            ).fetchone()
            return bool(row)

        def _resolve_alias_ids(alias: str, entity_type: str) -> List[str]:
            rows = self.conn.execute(
                "SELECT entity_id FROM entity_aliases WHERE alias = ? AND entity_type = ?",
                (alias, entity_type),
            ).fetchall()
            return [r["entity_id"] for r in rows] if rows else []

        # v4.0: chapters.characters å­˜ entity_id åˆ—è¡¨ï¼ˆmetadata å…è®¸ä¼ å…¥ name/aliasï¼Œç´¢å¼•å±‚è´Ÿè´£è§£æï¼‰
        resolved_character_ids: List[str] = []
        seen_ids = set()
        for ref in _normalize_str_list(metadata.get("characters", [])):
            if _exists_entity(ref, "è§’è‰²"):
                if ref not in seen_ids:
                    resolved_character_ids.append(ref)
                    seen_ids.add(ref)
                continue

            candidates = _resolve_alias_ids(ref, "è§’è‰²")
            if len(candidates) == 1:
                cid = candidates[0]
                if cid not in seen_ids:
                    resolved_character_ids.append(cid)
                    seen_ids.add(cid)
                continue

            if len(candidates) > 1:
                print(f"âš ï¸ è§’è‰²åˆ«åæ­§ä¹‰ï¼Œè·³è¿‡: {ref!r} å‘½ä¸­ {len(candidates)} ä¸ªè§’è‰²")
            else:
                print(f"âš ï¸ æœªçŸ¥è§’è‰²ï¼Œè·³è¿‡: {ref!r}")

        # v4.0: å¯é€‰ location_idï¼ˆåªè§£æä¸ºåœ°ç‚¹å®ä½“ï¼‰
        location = str(metadata.get("location", "")).strip()
        location_id = ""
        if location:
            if _exists_entity(location, "åœ°ç‚¹"):
                location_id = location
            else:
                loc_candidates = _resolve_alias_ids(location, "åœ°ç‚¹")
                if len(loc_candidates) == 1:
                    location_id = loc_candidates[0]
                elif len(loc_candidates) > 1:
                    print(f"âš ï¸ åœ°ç‚¹åˆ«åæ­§ä¹‰ï¼Œlocation_id ç•™ç©º: {location!r} å‘½ä¸­ {len(loc_candidates)} ä¸ªåœ°ç‚¹")

        self.conn.execute("""
            INSERT OR REPLACE INTO chapters
            (chapter_num, title, location, location_id, characters, word_count, content_hash, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            chapter_num,
            metadata['title'],
            location,
            location_id,
            json.dumps(resolved_character_ids, ensure_ascii=False),
            metadata['word_count'],
            metadata['hash']
        ))

        self.conn.commit()
        print(f"âœ… ç« èŠ‚ç´¢å¼•å·²æ›´æ–°ï¼šCh{chapter_num} - {metadata['title']}")

    # bump_character_last_appearance_in_state å·²åˆ é™¤ï¼ˆv4.0ï¼‰
    # åŸå› ï¼šæ¶ˆé™¤ç´¢å¼•å±‚å†™å› state.json çš„å¾ªç¯ä¾èµ–
    # last_appearance_chapter ç°åœ¨ä½œä¸º index.db çš„æ´¾ç”Ÿå­—æ®µ

    def query_chapters_by_location(self, location: str, limit: int = 10) -> List[Tuple]:
        """O(log n) æŸ¥è¯¢ï¼šè¿”å›è¯¥åœ°ç‚¹çš„æœ€è¿‘ N ç« 

        Args:
            location: åœ°ç‚¹åç§°
            limit: è¿”å›æ•°é‡

        Returns:
            [(chapter_num, title, characters), ...]
        """
        cursor = self.conn.execute("""
            SELECT chapter_num, title, characters
            FROM chapters
            WHERE location = ?
            ORDER BY chapter_num DESC
            LIMIT ?
        """, (location, limit))

        return cursor.fetchall()

    def calculate_chapter_hash(self, chapter_file: Path) -> str:
        """è®¡ç®—ç« èŠ‚æ–‡ä»¶ MD5 Hashï¼ˆç”¨äºè‡ªæ„ˆæœºåˆ¶ï¼‰"""
        if not chapter_file.exists():
            return ""

        with open(chapter_file, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()

    def get_stored_hash(self, chapter_num: int) -> Optional[str]:
        """ä»ç´¢å¼•ä¸­è¯»å–å­˜å‚¨çš„ Hash"""
        cursor = self.conn.execute("""
            SELECT content_hash FROM chapters WHERE chapter_num = ?
        """, (chapter_num,))

        row = cursor.fetchone()
        return row['content_hash'] if row else None

    def validate_and_rebuild_if_needed(self, chapter_num: int):
        """æ ¡éªŒç« èŠ‚ Hashï¼Œä¸ä¸€è‡´åˆ™è‡ªåŠ¨é‡å»ºç´¢å¼•ï¼ˆSelf-Healing Indexï¼‰

        è§¦å‘æ—¶æœºï¼š
        - context_manager.py æŸ¥è¯¢ç« èŠ‚å‰è°ƒç”¨
        - å¢åŠ è€—æ—¶ï¼š~5msï¼ˆHash è®¡ç®— + å¯¹æ¯”ï¼‰
        - ä»…å½“æ£€æµ‹åˆ°å˜æ›´æ—¶æ‰é‡å»ºï¼ˆå¢é‡æˆæœ¬ï¼‰
        """
        chapter_file = find_chapter_file(self.project_root, chapter_num)
        if chapter_file is None or not chapter_file.exists():
            return  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡

        # è®¡ç®—å½“å‰æ–‡ä»¶ Hash
        current_hash = self.calculate_chapter_hash(chapter_file)

        # ä»ç´¢å¼•ä¸­è¯»å–å­˜å‚¨çš„ Hash
        stored_hash = self.get_stored_hash(chapter_num)

        if current_hash != stored_hash:
            print(f"âš ï¸ æ£€æµ‹åˆ° Ch{chapter_num} å·²ä¿®æ”¹ï¼Œè‡ªåŠ¨é‡å»ºç´¢å¼•...")
            self._rebuild_chapter_index(chapter_num, chapter_file)
            print(f"âœ… Ch{chapter_num} ç´¢å¼•å·²æ›´æ–°")

    def _rebuild_chapter_index(self, chapter_num: int, chapter_file: Path):
        """é‡å»ºå•ç« ç´¢å¼•ï¼ˆè‡ªåŠ¨æå–å…ƒæ•°æ®ï¼‰"""

        # è¯»å–ç« èŠ‚å†…å®¹
        with open(chapter_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–å…ƒæ•°æ®
        metadata = self._extract_metadata_from_content(content, chapter_num)

        # é‡å»ºç´¢å¼•
        self.index_chapter(chapter_num, metadata)

    def _extract_metadata_from_content(self, content: str, chapter_num: int) -> Dict:
        """ä»ç« èŠ‚å†…å®¹ä¸­æå–å…ƒæ•°æ®"""

        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
        lines = content.split('\n')
        title = lines[0].strip('# ').strip() if lines else f"ç¬¬{chapter_num}ç« "

        # æå–åœ°ç‚¹ï¼ˆåœ¨ç« èŠ‚å¼€å¤´æŸ¥æ‰¾ï¼Œé€šå¸¸æ ¼å¼ä¸º **åœ°ç‚¹ï¼šXXX**ï¼‰
        location_match = re.search(r'\*\*åœ°ç‚¹[ï¼š:]\s*(.+?)\*\*', content)
        location = location_match.group(1).strip() if location_match else "æœªçŸ¥"

        # æå–è§’è‰²ï¼ˆæŸ¥æ‰¾æ‰€æœ‰å¯¹è¯å’Œæè¿°ä¸­çš„è§’è‰²åï¼‰
        # ç®€åŒ–å®ç°ï¼šä» state.json è¯»å–å·²çŸ¥è§’è‰²ï¼ŒåŒ¹é…å‡ºç°é¢‘ç‡
        characters = self._extract_characters_from_content(content)

        # è®¡ç®—å­—æ•°
        word_count = len(content)

        # è®¡ç®— Hash
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        return {
            'title': title,
            'location': location,
            'characters': characters[:5],  # æœ€å¤š 5 ä¸ªä¸»è¦è§’è‰²
            'word_count': word_count,
            'hash': content_hash
        }

    def _extract_characters_from_content(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–è§’è‰²ï¼ˆç®€åŒ–å®ç°ï¼šè¯»å–ç´¢å¼•ä¸­å·²çŸ¥è§’è‰² canonical_nameï¼‰"""

        # è·å–å·²çŸ¥è§’è‰²åˆ—è¡¨ï¼ˆé™åˆ¶è§„æ¨¡ï¼Œé¿å…è¶…å¤§è§’è‰²åº“æ‹–æ…¢ï¼‰
        rows = self.conn.execute(
            "SELECT canonical_name FROM entities WHERE entity_type = ? AND canonical_name != '' LIMIT 800",
            ("è§’è‰²",),
        ).fetchall()
        known_characters = [r["canonical_name"] for r in rows] if rows else []
        if not known_characters:
            return []

        # ç»Ÿè®¡æ¯ä¸ªè§’è‰²åœ¨å†…å®¹ä¸­çš„å‡ºç°æ¬¡æ•°
        char_counts = {}
        for char_name in known_characters:
            count = content.count(char_name)
            if count > 0:
                char_counts[char_name] = count

        # æŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼Œè¿”å›å‰ 5 ä¸ª
        sorted_chars = sorted(char_counts.items(), key=lambda x: x[1], reverse=True)
        return [char for char, _ in sorted_chars[:5]]

    # ================== æ ¸å¿ƒåŠŸèƒ½ 2ï¼šä¼ç¬”è¿½è¸ªç´¢å¼• ==================

    def sync_foreshadowing_from_state(self):
        """ä» state.json åŒæ­¥ä¼ç¬”æ•°æ®åˆ°ç´¢å¼•

        è§¦å‘æ—¶æœºï¼š
        - update_state.py æ›´æ–°ä¼ç¬”åè°ƒç”¨
        - --rebuild-index æ‰¹é‡é‡å»ºæ—¶è°ƒç”¨
        """
        if not self.state_file.exists():
            print("âŒ state.json ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¼ç¬”åŒæ­¥")
            return

        # è¯»å– state.json
        with open(self.state_file, 'r', encoding='utf-8') as f:
            state = json.load(f)

        current_chapter = state.get('progress', {}).get('current_chapter', 0)

        plot_threads = state.get('plot_threads', {}) or {}

        # å…¼å®¹æ–°æ ¼å¼ï¼šplot_threads.foreshadowing = [{"content": "...", "status": "active", ...}, ...]
        foreshadowing_items = plot_threads.get('foreshadowing', []) or []
        active_count = 0
        resolved_count = 0

        for item in foreshadowing_items:
            desc = item.get('description') or item.get('content') or ''
            if not desc:
                continue

            raw_status = (item.get('status') or '').strip()
            if raw_status in ['å·²å›æ”¶', 'resolved']:
                status = 'å·²å›æ”¶'
                resolved_count += 1
            else:
                # é»˜è®¤éƒ½è§†ä¸ºæœªå›æ”¶ï¼ˆå…¼å®¹ active/æœªå›æ”¶/pending/ç©ºï¼‰
                status = 'æœªå›æ”¶'
                active_count += 1

            normalized = {
                'description': desc,
                'location': item.get('location', ''),
                'characters': item.get('characters', []),
                # å¦‚æœæ²¡æœ‰æ˜ç¡®è®°å½•ï¼Œè‡³å°‘ç»™ä¸€ä¸ªå¯ç”¨çš„é»˜è®¤å€¼ï¼ˆé¿å…ç´§æ€¥åº¦æ’ä¸º0ï¼‰
                'introduced_chapter': item.get('introduced_chapter') or item.get('planted_chapter') or 1,
                'resolved_chapter': item.get('resolved_chapter', None),
            }

            self._index_foreshadowing(normalized, current_chapter, status=status)

        self.conn.commit()
        print(f"âœ… ä¼ç¬”ç´¢å¼•å·²åŒæ­¥ï¼š{active_count} æ¡æ´»è·ƒ + {resolved_count} æ¡å·²å›æ”¶")

    def _index_foreshadowing(self, plot: Dict, current_chapter: int, status: str):
        """ä¸ºå•ä¸ªä¼ç¬”å»ºç«‹ç´¢å¼•"""

        # è®¡ç®—ç´§æ€¥åº¦
        urgency = self._calculate_urgency(plot, current_chapter)

        # æå–åœ°ç‚¹å’Œè§’è‰²ï¼ˆå¦‚æœæœ‰ï¼‰
        location = plot.get('location', '')
        characters = plot.get('characters', [])

        self.conn.execute("""
            INSERT OR REPLACE INTO foreshadowing_index
            (id, content, location, characters, introduced_chapter, resolved_chapter, status, urgency, updated_at)
            VALUES ((SELECT id FROM foreshadowing_index WHERE content = ?), ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            plot.get('description', ''),  # ç”¨äºæŸ¥é‡
            plot.get('description', ''),
            location,
            json.dumps(characters, ensure_ascii=False),
            plot.get('introduced_chapter', 0),
            plot.get('resolved_chapter', None),
            status,
            urgency
        ))

    def _calculate_urgency(self, plot: Dict, current_chapter: int) -> int:
        """è®¡ç®—ä¼ç¬”ç´§æ€¥åº¦ï¼ˆ0-100ï¼‰

        è§„åˆ™ï¼š
        - è¶…è¿‡ 100 ç« æœªå›æ”¶ â†’ æåº¦ç´§æ€¥ï¼ˆ100ï¼‰
        - è¶…è¿‡ 50 ç« æœªå›æ”¶ â†’ ä¸­ç­‰ç´§æ€¥ï¼ˆ60ï¼‰
        - å…¶ä»– â†’ æ­£å¸¸ï¼ˆ20ï¼‰
        """
        introduced_ch = plot.get('introduced_chapter', 0)
        chapters_pending = current_chapter - introduced_ch

        if chapters_pending > 100:
            return 100  # æåº¦ç´§æ€¥
        elif chapters_pending > 50:
            return 60   # ä¸­ç­‰ç´§æ€¥
        else:
            return 20   # æ­£å¸¸

    # ================== v4.0 å®ä½“åŒæ­¥ï¼ˆä½¿ç”¨ entities_v3ï¼‰==================

    def sync_entities_from_state(self):
        """ä» state.json.entities_v3 åŒæ­¥å®ä½“åˆ° entities/entity_aliases è¡¨

        v4.0 æ–°å¢ï¼šå–ä»£æ—§çš„ sync_characters_from_state
        æ•°æ®æºï¼šstate.json.entities_v3 + alias_index
        """
        if not self.state_file.exists():
            print("âŒ state.json ä¸å­˜åœ¨ï¼Œè·³è¿‡å®ä½“åŒæ­¥")
            return

        with open(self.state_file, 'r', encoding='utf-8') as f:
            state = json.load(f)

        entities_v3 = state.get('entities_v3', {})
        alias_index = state.get('alias_index', {})

        # v4.0ï¼šç´¢å¼•å±‚ä¸ºæ´¾ç”Ÿæ•°æ®ï¼Œå¯ç›´æ¥é‡å»ºï¼ˆé¿å…é‡å¤æ’å…¥å¯¼è‡´è†¨èƒ€ï¼‰
        self.conn.execute("DELETE FROM entity_kv")
        self.conn.execute("DELETE FROM entity_aliases")
        self.conn.execute("DELETE FROM entity_history")
        self.conn.execute("DELETE FROM entities")

        entity_count = 0
        alias_count = 0

        # éå†æ‰€æœ‰å®ä½“ç±»å‹
        for entity_type, entities in entities_v3.items():
            for entity_id, entity_data in entities.items():
                # å†™å…¥ entities ä¸»è¡¨
                canonical_name = entity_data.get('canonical_name', '')
                tier = entity_data.get('tier', '')
                desc = entity_data.get('desc', '')
                created_chapter = entity_data.get('created_chapter', 0)

                self.conn.execute("""
                    INSERT OR REPLACE INTO entities
                    (entity_id, entity_type, canonical_name, tier, desc, created_chapter, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (entity_id, entity_type, canonical_name, tier, desc, created_chapter))
                entity_count += 1

                # å†™å…¥å®ä½“ KV å±æ€§
                current = entity_data.get('current', {})
                last_chapter = current.get("last_chapter", created_chapter) if isinstance(current, dict) else created_chapter
                try:
                    last_chapter = int(last_chapter)
                except (TypeError, ValueError):
                    last_chapter = int(created_chapter or 0)
                for key, value in current.items():
                    value_str = json.dumps(value, ensure_ascii=False) if isinstance(value, (dict, list)) else str(value)
                    self.conn.execute("""
                        INSERT OR REPLACE INTO entity_kv
                        (entity_id, key, value, last_chapter)
                        VALUES (?, ?, ?, ?)
                    """, (entity_id, key, value_str, last_chapter))

                # å†™å…¥å†å²è®°å½•
                history = entity_data.get('history', [])
                for record in history:
                    chapter = record.get('chapter', 0)
                    changes = record.get('changes', {})
                    reasons = record.get('reasons', {})
                    self.conn.execute("""
                        INSERT OR IGNORE INTO entity_history
                        (entity_id, chapter, changes_json, reasons_json)
                        VALUES (?, ?, ?, ?)
                    """, (entity_id, chapter, json.dumps(changes, ensure_ascii=False), json.dumps(reasons, ensure_ascii=False)))

        # åŒæ­¥åˆ«åç´¢å¼•
        for alias, entries in alias_index.items():
            # v4.0: entries å¿…é¡»æ˜¯æ•°ç»„ï¼ˆä¸€å¯¹å¤šï¼‰
            if not isinstance(entries, list):
                raise ValueError(
                    f"alias_index æ•°æ®æ ¼å¼é”™è¯¯ï¼šæœŸæœ› alias_index[{alias!r}] ä¸º list[{{type,id,...}}]ï¼Œå®é™…ä¸º {type(entries).__name__}"
                )
            for entry in entries:
                entry_type = entry.get('type', '')
                entry_id = entry.get('id', '')
                first_seen = entry.get('first_seen_chapter', 0)
                context = entry.get('context', '')

                self.conn.execute("""
                    INSERT OR REPLACE INTO entity_aliases
                    (alias, entity_id, entity_type, first_seen_chapter, context)
                    VALUES (?, ?, ?, ?, ?)
                """, (alias, entry_id, entry_type, first_seen, context))
                alias_count += 1

        self.conn.commit()
        print(f"âœ… å®ä½“ç´¢å¼•å·²åŒæ­¥ï¼š{entity_count} ä¸ªå®ä½“ï¼Œ{alias_count} ä¸ªåˆ«å")

    def query_entity_by_id(self, entity_id: str) -> Optional[Dict]:
        """é€šè¿‡ entity_id æŸ¥è¯¢å®ä½“è¯¦æƒ…"""
        cursor = self.conn.execute("""
            SELECT entity_id, entity_type, canonical_name, tier, desc, created_chapter
            FROM entities WHERE entity_id = ?
        """, (entity_id,))
        row = cursor.fetchone()
        if not row:
            return None

        result = dict(row)

        # è·å– KV å±æ€§
        cursor = self.conn.execute("""
            SELECT key, value FROM entity_kv WHERE entity_id = ?
        """, (entity_id,))
        result['current'] = {}
        for kv_row in cursor.fetchall():
            try:
                result['current'][kv_row['key']] = json.loads(kv_row['value'])
            except json.JSONDecodeError:
                result['current'][kv_row['key']] = kv_row['value']

        # è·å–åˆ«å
        cursor = self.conn.execute("""
            SELECT alias FROM entity_aliases WHERE entity_id = ?
        """, (entity_id,))
        result['aliases'] = [row['alias'] for row in cursor.fetchall()]

        return result

    def query_entities_by_alias(self, alias: str) -> List[Dict]:
        """é€šè¿‡åˆ«åæŸ¥è¯¢å®ä½“ï¼ˆæ”¯æŒä¸€å¯¹å¤šï¼‰"""
        cursor = self.conn.execute("""
            SELECT ea.entity_id, ea.entity_type, e.canonical_name, e.tier
            FROM entity_aliases ea
            LEFT JOIN entities e ON ea.entity_id = e.entity_id
            WHERE ea.alias = ?
        """, (alias,))
        return [dict(row) for row in cursor.fetchall()]

    def query_entities_by_type(self, entity_type: str, limit: int = 50) -> List[Dict]:
        """æŒ‰ç±»å‹æŸ¥è¯¢å®ä½“"""
        cursor = self.conn.execute("""
            SELECT entity_id, canonical_name, tier, desc
            FROM entities
            WHERE entity_type = ?
            ORDER BY created_chapter DESC
            LIMIT ?
        """, (entity_type, limit))
        return [dict(row) for row in cursor.fetchall()]

    def sync_characters_from_state(self):
        """ä» state.json åŒæ­¥è§’è‰²æ•°æ®åˆ°ç´¢å¼•ï¼ˆv4.0 å·²åºŸå¼ƒï¼‰

        ä¿ç•™å…¼å®¹ï¼šè°ƒç”¨æ–°çš„ sync_entities_from_state
        """
        # v4.0: å§”æ‰˜ç»™æ–°å‡½æ•°
        self.sync_entities_from_state()

    def _index_character(self, char: Dict, status: str = 'active'):
        """ä¸ºå•ä¸ªè§’è‰²å»ºç«‹ç´¢å¼•"""
        description = char.get('description') or char.get('desc') or ''
        tier = str(char.get('tier', '') or '').strip()
        importance = char.get('importance') or ('major' if tier == 'æ ¸å¿ƒ' else 'minor')

        first_appearance = char.get('first_appearance_chapter', 0) or 0
        try:
            first_appearance = int(first_appearance)
        except (TypeError, ValueError):
            first_appearance = 0

        if first_appearance == 0:
            src = char.get('first_appearance')
            if isinstance(src, str):
                m = re.search(r'ç¬¬(\d+)ç« ', src)
                if m:
                    try:
                        first_appearance = int(m.group(1))
                    except ValueError:
                        first_appearance = 0

        last_appearance = char.get('last_appearance_chapter', 0) or first_appearance
        try:
            last_appearance = int(last_appearance)
        except (TypeError, ValueError):
            last_appearance = first_appearance

        self.conn.execute("""
            INSERT OR REPLACE INTO characters
            (name, description, personality, importance, power_level,
             first_appearance, last_appearance, status, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            char.get('name', ''),
            description,
            char.get('personality', ''),
            importance,
            char.get('power_level', ''),
            first_appearance,
            last_appearance,
            status
        ))

    def mark_character_archived(self, name: str, archived_at: str = None):
        """æ ‡è®°è§’è‰²ä¸ºå·²å½’æ¡£çŠ¶æ€ï¼ˆPriority 2 ä¿®å¤ï¼‰

        Args:
            name: è§’è‰²å
            archived_at: å½’æ¡£æ—¶é—´æˆ³ï¼ˆISOæ ¼å¼ï¼‰ï¼Œé»˜è®¤å½“å‰æ—¶é—´
        """
        if archived_at is None:
            from datetime import datetime
            archived_at = datetime.now().isoformat()

        self.conn.execute("""
            UPDATE characters
            SET status = 'archived', archived_at = ?, updated_at = CURRENT_TIMESTAMP
            WHERE name = ?
        """, (archived_at, name))
        self.conn.commit()

    def mark_character_active(self, name: str):
        """æ¢å¤è§’è‰²ä¸ºæ´»è·ƒçŠ¶æ€ï¼ˆä¸ mark_character_archived å¯¹åº”ï¼‰"""
        self.conn.execute("""
            UPDATE characters
            SET status = 'active', archived_at = NULL, updated_at = CURRENT_TIMESTAMP
            WHERE name = ?
        """, (name,))
        self.conn.commit()

    def query_urgent_foreshadowing(self, threshold: int = 60) -> List[Dict]:
        """æŸ¥è¯¢ç´§æ€¥ä¼ç¬”ï¼ˆurgency >= thresholdï¼‰

        Args:
            threshold: ç´§æ€¥åº¦é˜ˆå€¼ï¼ˆ60=ä¸­ç­‰ç´§æ€¥ï¼Œ80=é«˜åº¦ç´§æ€¥ï¼Œ100=æåº¦ç´§æ€¥ï¼‰

        Returns:
            [{'content': '...', 'introduced_chapter': 45, 'urgency': 80}, ...]
        """
        cursor = self.conn.execute("""
            SELECT content, introduced_chapter, urgency
            FROM foreshadowing_index
            WHERE status = 'æœªå›æ”¶' AND urgency >= ?
            ORDER BY urgency DESC
        """, (threshold,))

        return [dict(row) for row in cursor.fetchall()]

    def sync_relationships_from_state(self):
        """ä» state.json åŒæ­¥å…³ç³»æ•°æ®åˆ°ç´¢å¼•ï¼ˆv4.0: ä½¿ç”¨ entity_idï¼‰

        è§¦å‘æ—¶æœºï¼š
        - extract_entities.py æ›´æ–°å…³ç³»åè°ƒç”¨
        - --rebuild-index æ‰¹é‡é‡å»ºæ—¶è°ƒç”¨

        æ•°æ®æ¥æº: state.json çš„ structured_relationships åˆ—è¡¨
        """
        if not self.state_file.exists():
            print("âŒ state.json ä¸å­˜åœ¨ï¼Œè·³è¿‡å…³ç³»åŒæ­¥")
            return

        # è¯»å– state.json
        with open(self.state_file, 'r', encoding='utf-8') as f:
            state = json.load(f)

        # è·å–ç»“æ„åŒ–å…³ç³»åˆ—è¡¨
        relationships = state.get('structured_relationships', [])
        if not relationships:
            print("â„¹ï¸ æ— ç»“æ„åŒ–å…³ç³»æ•°æ®")
            return

        count = 0
        for rel in relationships:
            # v4.0: å…³ç³»å¿…é¡»ç”¨ entity_idï¼ˆchapter tags æ˜¯çœŸç›¸ï¼Œé¿å… name æ¼‚ç§»ï¼‰
            char1_id = str(rel.get('char1_id', '') or '').strip()
            char2_id = str(rel.get('char2_id', '') or '').strip()
            char1_name = str(rel.get('char1_name', '') or '').strip()
            char2_name = str(rel.get('char2_name', '') or '').strip()
            rel_type = rel.get('type', 'ally')
            intensity = rel.get('intensity', 50)
            desc = rel.get('description', '')
            last_chapter = rel.get('last_update_chapter', 0)

            if not char1_id or not char2_id:
                print("âš ï¸ è·³è¿‡æ— æ•ˆå…³ç³»ï¼ˆç¼ºå°‘ char1_id/char2_idï¼‰")
                continue

            # è¡¥é½æ˜¾ç¤ºåï¼ˆå¯é€‰ï¼‰
            if not char1_name:
                row = self.conn.execute("SELECT canonical_name FROM entities WHERE entity_id = ? LIMIT 1", (char1_id,)).fetchone()
                char1_name = (row["canonical_name"] if row else "") or char1_id
            if not char2_name:
                row = self.conn.execute("SELECT canonical_name FROM entities WHERE entity_id = ? LIMIT 1", (char2_id,)).fetchone()
                char2_name = (row["canonical_name"] if row else "") or char2_id

            self.conn.execute("""
                INSERT OR REPLACE INTO relationships
                (id, char1_id, char2_id, char1_name, char2_name, relation_type, intensity, description, last_update_chapter, updated_at)
                VALUES (
                    (SELECT id FROM relationships WHERE char1_id = ? AND char2_id = ? AND relation_type = ?),
                    ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP
                )
            """, (
                char1_id, char2_id, rel_type,  # for subquery
                char1_id, char2_id, char1_name, char2_name, rel_type, intensity, desc, last_chapter
            ))
            count += 1

        self.conn.commit()
        print(f"âœ… å…³ç³»ç´¢å¼•å·²åŒæ­¥ï¼š{count} æ¡å…³ç³»")

    def query_relationships(self, char_id: str = None, rel_type: str = None) -> List[Dict]:
        """æŸ¥è¯¢è§’è‰²å…³ç³»ï¼ˆv4.0: ä½¿ç”¨ entity_idï¼‰

        Args:
            char_id: è§’è‰² entity_idï¼ˆå¯é€‰ï¼ŒæŸ¥è¯¥è§’è‰²çš„æ‰€æœ‰å…³ç³»ï¼‰
            rel_type: å…³ç³»ç±»å‹ï¼ˆå¯é€‰ï¼Œè¿‡æ»¤ç‰¹å®šç±»å‹ï¼‰

        Returns:
            [{'char1_id': '...', 'char2_id': '...', 'type': 'romance', 'intensity': 80, ...}, ...]
        """
        conditions = []
        params = []

        if char_id:
            conditions.append("(char1_id = ? OR char2_id = ?)")
            params.extend([char_id, char_id])

        if rel_type:
            conditions.append("relation_type = ?")
            params.append(rel_type)

        where_clause = " AND ".join(conditions) if conditions else "1=1"

        cursor = self.conn.execute(f"""
            SELECT char1_id, char2_id, char1_name, char2_name, relation_type, intensity, description, last_update_chapter
            FROM relationships
            WHERE {where_clause}
            ORDER BY intensity DESC
        """, params)

        return [dict(row) for row in cursor.fetchall()]

    # ================== æ ¸å¿ƒåŠŸèƒ½ 3ï¼šæ¨¡ç³ŠæŸ¥è¯¢ï¼ˆFuzzy Search via SQL LIKEï¼‰==================

    def fuzzy_search_entity(self, keywords: List[str], entity_type: str = None) -> List[Dict]:
        """æ¨¡ç³ŠæŸ¥è¯¢å®ä½“ï¼ˆv4.0 æ–°å¢ï¼Œæ”¯æŒå¤šå…³é”®è¯ + ç±»å‹è¿‡æ»¤ï¼‰

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚ ["æ", "å¥³å¼Ÿå­"]
            entity_type: å¯é€‰ï¼Œè¿‡æ»¤å®ä½“ç±»å‹ï¼ˆè§’è‰²/åœ°ç‚¹/ç‰©å“/åŠ¿åŠ›/æ‹›å¼ï¼‰

        Returns:
            [{'entity_id': '...', 'canonical_name': '...', 'desc': '...', 'tier': '...'}, ...]
        """
        # æ„å»º WHERE å­å¥
        conditions = []
        params = []

        for kw in keywords:
            # æ¯ä¸ªå…³é”®è¯åœ¨ canonical_name/desc ä»»ä¸€å­—æ®µä¸­å‡ºç°å³å¯
            conditions.append("(e.canonical_name LIKE ? OR e.desc LIKE ? OR ea.alias LIKE ?)")
            params.extend([f'%{kw}%', f'%{kw}%', f'%{kw}%'])

        if entity_type:
            conditions.append("e.entity_type = ?")
            params.append(entity_type)

        where_clause = " AND ".join(conditions)

        query = f"""
            SELECT DISTINCT e.entity_id, e.entity_type, e.canonical_name, e.tier, e.desc, e.created_chapter
            FROM entities e
            LEFT JOIN entity_aliases ea ON e.entity_id = ea.entity_id
            WHERE {where_clause}
            ORDER BY e.tier DESC, e.created_chapter DESC
            LIMIT 20
        """

        cursor = self.conn.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]

    def fuzzy_search_character(self, keywords: List[str]) -> List[Dict]:
        """æ¨¡ç³ŠæŸ¥è¯¢è§’è‰²ï¼ˆv4.0: å§”æ‰˜ç»™ fuzzy_search_entityï¼‰

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚ ["æ", "å¥³å¼Ÿå­"]

        Returns:
            [{'entity_id': '...', 'canonical_name': '...', 'desc': '...', ...}, ...]
        """
        return self.fuzzy_search_entity(keywords, entity_type="è§’è‰²")

    # ================== æ‰¹é‡æ“ä½œ ==================

    def rebuild_all_indexes(self):
        """æ‰¹é‡é‡å»ºæ‰€æœ‰å†å²ç« èŠ‚çš„ç´¢å¼•

        ä½¿ç”¨åœºæ™¯ï¼š
        - ç´¢å¼•ç³»ç»Ÿé¦–æ¬¡ä¸Šçº¿
        - ç´¢å¼•æ•°æ®åº“æŸå
        """
        if not self.chapters_dir.exists():
            print("âŒ ç« èŠ‚ç›®å½•ä¸å­˜åœ¨")
            return

        # è·å–æ‰€æœ‰ç« èŠ‚æ–‡ä»¶
        chapter_files = sorted(self.chapters_dir.rglob("ç¬¬*.md"))

        print(f"ğŸ” å‘ç° {len(chapter_files)} ä¸ªç« èŠ‚æ–‡ä»¶ï¼Œå¼€å§‹é‡å»ºç´¢å¼•...")

        seen = set()
        for chapter_file in chapter_files:
            # æå–ç« èŠ‚ç¼–å·
            match = re.search(r'ç¬¬(\d+)ç« ', chapter_file.name)
            if not match:
                continue

            chapter_num = int(match.group(1))
            if chapter_num in seen:
                continue
            seen.add(chapter_num)

            # é‡å»ºç´¢å¼•
            self._rebuild_chapter_index(chapter_num, chapter_file)

        # åŒæ­¥ä¼ç¬”ç´¢å¼•
        self.sync_foreshadowing_from_state()
        self.sync_characters_from_state()
        self.sync_relationships_from_state()

        print(f"âœ… æ‰¹é‡é‡å»ºå®Œæˆï¼š{len(seen)} ç« ")

    # ================== æŸ¥è¯¢ä¸ç»Ÿè®¡ ==================

    def get_index_stats(self) -> Dict:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯ï¼ˆv4.0: å¢åŠ å®ä½“/åˆ«åç»Ÿè®¡ï¼‰"""

        # ç« èŠ‚ç»Ÿè®¡
        cursor = self.conn.execute("SELECT COUNT(*) as count FROM chapters")
        chapter_count = cursor.fetchone()['count']

        # å®ä½“ç»Ÿè®¡ï¼ˆv4.0 æ–°å¢ï¼‰
        cursor = self.conn.execute("""
            SELECT entity_type, COUNT(*) as count
            FROM entities
            GROUP BY entity_type
        """)
        entity_stats = {row['entity_type']: row['count'] for row in cursor.fetchall()}

        # åˆ«åç»Ÿè®¡ï¼ˆv4.0 æ–°å¢ï¼‰
        cursor = self.conn.execute("SELECT COUNT(*) as count FROM entity_aliases")
        alias_count = cursor.fetchone()['count']

        # ä¼ç¬”ç»Ÿè®¡
        cursor = self.conn.execute("""
            SELECT status, COUNT(*) as count
            FROM foreshadowing_index
            GROUP BY status
        """)
        foreshadowing_stats = {row['status']: row['count'] for row in cursor.fetchall()}

        # å…³ç³»ç»Ÿè®¡
        cursor = self.conn.execute("SELECT COUNT(*) as count FROM relationships")
        relationship_count = cursor.fetchone()['count']

        # æ•°æ®åº“å¤§å°
        db_size_kb = self.index_db.stat().st_size / 1024

        return {
            'chapter_count': chapter_count,
            'entity_stats': entity_stats,
            'alias_count': alias_count,
            'foreshadowing_active': foreshadowing_stats.get('æœªå›æ”¶', 0),
            'foreshadowing_resolved': foreshadowing_stats.get('å·²å›æ”¶', 0),
            'relationship_count': relationship_count,
            'db_size_kb': round(db_size_kb, 2)
        }

    def __del__(self):
        """ææ„å‡½æ•°ï¼šå…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'conn'):
            self.conn.close()


def main():
    parser = argparse.ArgumentParser(description="ç»“æ„åŒ–ç´¢å¼•ç³»ç»Ÿï¼ˆå–ä»£å‘é‡åŒ–æ£€ç´¢ï¼‰")

    # æ›´æ–°æ“ä½œ
    parser.add_argument("--update-chapter", type=int, metavar="NUM", help="æ›´æ–°å•ç« ç´¢å¼•")
    parser.add_argument("--metadata", metavar="PATH", help="ç« èŠ‚æ–‡ä»¶è·¯å¾„ï¼ˆé…åˆ --update-chapterï¼‰")
    parser.add_argument("--metadata-json", metavar="JSON", help="å…ƒæ•°æ® JSON å­—ç¬¦ä¸²ï¼ˆé…åˆ --update-chapterï¼Œç”± metadata-extractor agent æä¾›ï¼‰")
    parser.add_argument("--metadata-file", metavar="FILE", help="å…ƒæ•°æ® JSON æ–‡ä»¶è·¯å¾„ï¼ˆé…åˆ --update-chapterï¼ŒWindows æ¨èä½¿ç”¨æ­¤å‚æ•°ï¼‰")

    # æ‰¹é‡æ“ä½œ
    parser.add_argument("--rebuild-index", action="store_true", help="æ‰¹é‡é‡å»ºæ‰€æœ‰ç´¢å¼•")

    # æŸ¥è¯¢æ“ä½œ
    parser.add_argument("--query-location", metavar="LOCATION", help="æŸ¥è¯¢åœ°ç‚¹ç›¸å…³ç« èŠ‚")
    parser.add_argument("--query-urgent-foreshadowing", action="store_true", help="æŸ¥è¯¢ç´§æ€¥ä¼ç¬”")
    parser.add_argument("--fuzzy-search", nargs='+', metavar="KEYWORD", help="æ¨¡ç³ŠæŸ¥è¯¢è§’è‰²ï¼ˆå¤šä¸ªå…³é”®è¯ï¼‰")

    # ç»Ÿè®¡ä¿¡æ¯
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")

    # é¡¹ç›®è·¯å¾„
    parser.add_argument("--project-root", metavar="PATH", help="é¡¹ç›®æ ¹ç›®å½•ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰")

    args = parser.parse_args()

    # åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
    index = StructuredIndex(project_root=args.project_root)

    # æ‰§è¡Œæ“ä½œ
    if args.update_chapter:
        # æ¨¡å¼1ï¼šä» JSON æ–‡ä»¶è¯»å–ï¼ˆWindows æ¨èï¼Œé¿å… CLI å¼•å·è½¬ä¹‰é—®é¢˜ï¼‰
        if args.metadata_file:
            try:
                metadata_file = Path(args.metadata_file)
                if not metadata_file.exists():
                    print(f"âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
                    return

                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ['title', 'location', 'characters', 'word_count', 'hash']
                missing_fields = [f for f in required_fields if f not in metadata]

                if missing_fields:
                    print(f"âŒ JSON ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
                    return

                # å…ˆåŒæ­¥å®ä½“ï¼ˆç”¨äºå°† metadata.characters/name è§£æä¸º entity_idï¼‰
                index.sync_entities_from_state()

                # æ›´æ–°ç« èŠ‚ç´¢å¼•
                index.index_chapter(args.update_chapter, metadata)

                # åŒæ­¥ä¼ç¬”ç´¢å¼•
                index.sync_foreshadowing_from_state()
                # bump_character_last_appearance_in_state å·²åˆ é™¤ï¼ˆv4.0ï¼‰
                index.sync_relationships_from_state()

            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æå¤±è´¥: {e}")
                return

        # æ¨¡å¼2ï¼šç›´æ¥æ¥æ”¶ JSON å­—ç¬¦ä¸²ï¼ˆLinux/macOSï¼Œæˆ–æµ‹è¯•æ—¶ä½¿ç”¨ï¼‰
        elif args.metadata_json:
            try:
                metadata = json.loads(args.metadata_json)

                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ['title', 'location', 'characters', 'word_count', 'hash']
                missing_fields = [f for f in required_fields if f not in metadata]

                if missing_fields:
                    print(f"âŒ JSON ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
                    return

                # å…ˆåŒæ­¥å®ä½“ï¼ˆç”¨äºå°† metadata.characters/name è§£æä¸º entity_idï¼‰
                index.sync_entities_from_state()

                # æ›´æ–°ç« èŠ‚ç´¢å¼•
                index.index_chapter(args.update_chapter, metadata)

                # åŒæ­¥ä¼ç¬”ç´¢å¼•
                index.sync_foreshadowing_from_state()
                # bump_character_last_appearance_in_state å·²åˆ é™¤ï¼ˆv4.0ï¼‰
                index.sync_relationships_from_state()

            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æå¤±è´¥: {e}")
                return

        # æ¨¡å¼3ï¼šä»ç« èŠ‚æ–‡ä»¶æå–å…ƒæ•°æ®ï¼ˆæ—§æ¨¡å¼ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        elif args.metadata:
            # è¯»å–ç« èŠ‚æ–‡ä»¶
            chapter_file = Path(args.metadata)
            if not chapter_file.exists():
                print(f"âŒ ç« èŠ‚æ–‡ä»¶ä¸å­˜åœ¨: {chapter_file}")
                return

            # æå–å…ƒæ•°æ®
            with open(chapter_file, 'r', encoding='utf-8') as f:
                content = f.read()

            metadata = index._extract_metadata_from_content(content, args.update_chapter)

            # å…ˆåŒæ­¥å®ä½“ï¼ˆç”¨äºå°† metadata.characters/name è§£æä¸º entity_idï¼‰
            index.sync_entities_from_state()

            # æ›´æ–°ç« èŠ‚ç´¢å¼•
            index.index_chapter(args.update_chapter, metadata)

            # åŒæ­¥ä¼ç¬”ç´¢å¼•
            index.sync_foreshadowing_from_state()
            # bump_character_last_appearance_in_state å·²åˆ é™¤ï¼ˆv4.0ï¼‰
            index.sync_relationships_from_state()

        else:
            print("âŒ ç¼ºå°‘å‚æ•°ï¼š--metadata-file (æ¨è) / --metadata-json / --metadata")
            return

    elif args.rebuild_index:
        index.rebuild_all_indexes()

    elif args.query_location:
        results = index.query_chapters_by_location(args.query_location)

        if not results:
            print(f"æœªæ‰¾åˆ°åœ°ç‚¹ç›¸å…³ç« èŠ‚: {args.query_location}")
        else:
            print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç« èŠ‚ï¼š")
            for chapter_num, title, characters in results:
                print(f"  Ch{chapter_num}: {title} - è§’è‰²: {characters}")

    elif args.query_urgent_foreshadowing:
        results = index.query_urgent_foreshadowing(threshold=60)

        if not results:
            print("âœ… æ— ç´§æ€¥ä¼ç¬”")
        else:
            print(f"âš ï¸ æ£€æµ‹åˆ° {len(results)} æ¡ç´§æ€¥ä¼ç¬”ï¼š")
            for item in results:
                print(f"  - {item['content'][:30]}...ï¼ˆç¬¬ {item['introduced_chapter']} ç« åŸ‹è®¾ï¼Œç´§æ€¥åº¦ {item['urgency']}/100ï¼‰")

    elif args.fuzzy_search:
        results = index.fuzzy_search_character(args.fuzzy_search)

        if not results:
            print(f"æœªæ‰¾åˆ°åŒ¹é…è§’è‰²: {' + '.join(args.fuzzy_search)}")
        else:
            print(f"æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…è§’è‰²ï¼š")
            for i, char in enumerate(results, 1):
                # v4.0: ä½¿ç”¨æ–°å­—æ®µå
                name = char.get('canonical_name', char.get('name', ''))
                desc = char.get('desc', char.get('description', ''))[:50]
                tier = char.get('tier', '')
                print(f"{i}. {name} [{tier}] - {desc}...")

    elif args.stats:
        stats = index.get_index_stats()

        print("ğŸ“Š ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"   ç« èŠ‚ç´¢å¼•: {stats['chapter_count']}")

        # v4.0: æ˜¾ç¤ºå®ä½“ç»Ÿè®¡
        entity_stats = stats.get('entity_stats', {})
        if entity_stats:
            entity_summary = ", ".join([f"{t}: {c}" for t, c in entity_stats.items()])
            print(f"   å®ä½“ç´¢å¼•: {entity_summary}")
        print(f"   åˆ«åç´¢å¼•: {stats.get('alias_count', 0)}")

        print(f"   ä¼ç¬”ç´¢å¼•: {stats['foreshadowing_active']} æ¡æ´»è·ƒ + {stats['foreshadowing_resolved']} æ¡å·²å›æ”¶")
        print(f"   å…³ç³»ç´¢å¼•: {stats['relationship_count']}")
        print(f"   æ•°æ®åº“å¤§å°: {stats['db_size_kb']} KB")

    else:
        parser.print_help()


if __name__ == "__main__":
    # Windows UTF-8 ç¼–ç ä¿®å¤ï¼ˆä»…åœ¨è„šæœ¬ç›´æ¥è¿è¡Œæ—¶ï¼‰
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

    main()
