#!/usr/bin/env python3
"""
å¯è§†åŒ–çŠ¶æ€æŠ¥å‘Šç³»ç»Ÿ (Status Reporter)

æ ¸å¿ƒç†å¿µï¼šé¢å¯¹ 1000 ä¸ªç« èŠ‚ï¼Œä½œè€…ä¼šè¿·å¤±ã€‚éœ€è¦"å®è§‚ä¿¯ç°"èƒ½åŠ›ã€‚

åŠŸèƒ½ï¼š
1. è§’è‰²æ´»è·ƒåº¦åˆ†æï¼šå“ªäº›è§’è‰²å¤ªä¹…æ²¡å‡ºåœºï¼ˆæ‰çº¿ç»Ÿè®¡ï¼‰
2. ä¼ç¬”æ·±åº¦åˆ†æï¼šå“ªäº›å‘æŒ–å¾—å¤ªä¹…äº†ï¼ˆè¶…è¿‡ 20 ä¸‡å­—æœªæ”¶ï¼‰+ ç´§æ€¥åº¦æ’åº
3. çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒï¼šå…¨ä¹¦é«˜æ½®ç‚¹çš„åˆ†å¸ƒé¢‘ç‡ï¼ˆçƒ­åŠ›å›¾ï¼‰
4. å­—æ•°åˆ†å¸ƒç»Ÿè®¡ï¼šå„å·ã€å„ç¯‡çš„å­—æ•°åˆ†å¸ƒ
5. äººé™…å…³ç³»å›¾è°±ï¼šå¥½æ„Ÿåº¦/ä»‡æ¨åº¦è¶‹åŠ¿
6. Strand Weave èŠ‚å¥åˆ†æï¼šQuest/Fire/Constellation ä¸‰çº¿å æ¯”ç»Ÿè®¡
7. ä¼ç¬”ç´§æ€¥åº¦æ’åºï¼šåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼ˆæ ¸å¿ƒ/æ”¯çº¿/è£…é¥°ï¼‰çš„ä¼˜å…ˆçº§è®¡ç®—

è¾“å‡ºæ ¼å¼ï¼š
  - Markdown æŠ¥å‘Šï¼ˆ.webnovel/health_report.mdï¼‰
  - åŒ…å« Mermaid å›¾è¡¨ï¼ˆè§’è‰²å…³ç³»å›¾ã€çˆ½ç‚¹çƒ­åŠ›å›¾ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  # ç”Ÿæˆå®Œæ•´å¥åº·æŠ¥å‘Š
  python status_reporter.py --output .webnovel/health_report.md

  # ä»…åˆ†æè§’è‰²æ´»è·ƒåº¦
  python status_reporter.py --focus characters

  # ä»…åˆ†æä¼ç¬”
  python status_reporter.py --focus foreshadowing

  # ä»…åˆ†æçˆ½ç‚¹èŠ‚å¥
  python status_reporter.py --focus pacing

  # åˆ†æ Strand Weave èŠ‚å¥
  python status_reporter.py --focus strand

æŠ¥å‘Šç¤ºä¾‹ï¼š
  # å…¨ä¹¦å¥åº·æŠ¥å‘Š

  ## ğŸ“Š åŸºæœ¬æ•°æ®

  - **æ€»ç« èŠ‚æ•°**: 450 ç« 
  - **æ€»å­—æ•°**: 1,985,432 å­—
  - **å¹³å‡ç« èŠ‚å­—æ•°**: 4,412 å­—
  - **åˆ›ä½œè¿›åº¦**: 99.3%ï¼ˆç›®æ ‡ 200ä¸‡å­—ï¼‰

  ## âš ï¸ è§’è‰²æ‰çº¿ï¼ˆ3äººï¼‰

  | è§’è‰² | æœ€åå‡ºåœº | ç¼ºå¸­ç« èŠ‚ | çŠ¶æ€ |
  |------|---------|---------|------|
  | æé›ª | ç¬¬ 350 ç«  | 100 ç«  | ğŸ”´ ä¸¥é‡æ‰çº¿ |
  | è¡€ç…é—¨ä¸» | ç¬¬ 300 ç«  | 150 ç«  | ğŸ”´ ä¸¥é‡æ‰çº¿ |
  | å¤©äº‘å®—å®—ä¸» | ç¬¬ 400 ç«  | 50 ç«  | ğŸŸ¡ è½»åº¦æ‰çº¿ |

  ## âš ï¸ ä¼ç¬”è¶…æ—¶ï¼ˆ2æ¡ï¼‰

  | ä¼ç¬”å†…å®¹ | åŸ‹è®¾ç« èŠ‚ | å·²è¿‡ç« èŠ‚ | çŠ¶æ€ |
  |---------|---------|---------|------|
  | "æ—å®¶å®åº“é“­æ–‡çš„ç§˜å¯†" | ç¬¬ 200 ç«  | 250 ç«  | ğŸ”´ ä¸¥é‡è¶…æ—¶ |
  | "ç¥ç§˜ç‰ä½©çš„æ¥å†" | ç¬¬ 270 ç«  | 180 ç«  | ğŸŸ¡ è½»åº¦è¶…æ—¶ |

  ## ğŸ“ˆ çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒ

  ```
  ç¬¬ 1-100 ç«    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ä¼˜ç§€ï¼ˆ1200å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 101-200ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1500å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 201-300ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1600å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 301-400ç«   â–ˆâ–ˆâ–ˆâ–ˆ åä½ï¼ˆ2200å­—/çˆ½ç‚¹ï¼‰âš ï¸
  ç¬¬ 401-450ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1550å­—/çˆ½ç‚¹ï¼‰
  ```

  ## ğŸ’‘ äººé™…å…³ç³»è¶‹åŠ¿

  ```mermaid
  graph LR
    ä¸»è§’ -->|å¥½æ„Ÿåº¦95| æé›ª
    ä¸»è§’ -->|å¥½æ„Ÿåº¦60| æ…•å®¹é›ª
    ä¸»è§’ -->|ä»‡æ¨åº¦100| è¡€ç…é—¨
  ```
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime
from collections import defaultdict
from project_locator import resolve_project_root
from chapter_paths import extract_chapter_num_from_filename

# å¯¼å…¥é…ç½®
try:
    from data_modules.config import get_config, DataModulesConfig
except ImportError:
    from scripts.data_modules.config import get_config, DataModulesConfig

def _is_resolved_foreshadowing_status(raw_status: Any) -> bool:
    """åˆ¤æ–­ä¼ç¬”æ˜¯å¦å·²å›æ”¶ï¼ˆå…¼å®¹å†å²å­—æ®µä¸åŒä¹‰è¯ï¼‰ã€‚"""
    if raw_status is None:
        return False

    status = str(raw_status).strip()
    if not status:
        return False

    status_lower = status.lower()
    if status in {"å·²å›æ”¶", "å·²å®Œæˆ", "å·²è§£å†³", "å®Œæˆ"}:
        return True
    if status_lower in {"resolved", "done", "complete"}:
        return True
    if "å·²å›æ”¶" in status:
        return True
    return False

# Windows ç¼–ç å…¼å®¹æ€§ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

class StatusReporter:
    """çŠ¶æ€æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.config = get_config(self.project_root)
        self.state_file = self.project_root / ".webnovel/state.json"
        self.chapters_dir = self.project_root / "æ­£æ–‡"

        self.state = None
        self.chapters_data = []

        # å¯é€‰ï¼šé›†æˆç»“æ„åŒ–ç´¢å¼•ï¼ˆå¦‚æœå¯ç”¨ï¼Œè§’è‰²ç»Ÿè®¡æ›´å‡†ï¼‰
        self.index = None
        try:
            from structured_index import StructuredIndex
            self.index = StructuredIndex(self.project_root)
        except Exception:
            self.index = None

    def _extract_stats_field(self, content: str, field_name: str) -> str:
        """
        ä»â€œæœ¬ç« ç»Ÿè®¡â€åŒºå—æå–å­—æ®µå€¼ï¼Œä¾‹å¦‚ï¼š
        - **ä¸»å¯¼Strand**: quest
        """
        pattern = rf"^\s*-\s*\*\*{re.escape(field_name)}\*\*\s*:\s*(.+?)\s*$"
        for line in content.splitlines():
            m = re.match(pattern, line)
            if m:
                return m.group(1).strip()
        return ""

    def load_state(self) -> bool:
        """åŠ è½½ state.json"""
        if not self.state_file.exists():
            print(f"âŒ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {self.state_file}")
            return False

        with open(self.state_file, 'r', encoding='utf-8') as f:
            self.state = json.load(f)

        return True

    def scan_chapters(self):
        """æ‰«ææ‰€æœ‰ç« èŠ‚æ–‡ä»¶"""
        if not self.chapters_dir.exists():
            print(f"âš ï¸  æ­£æ–‡ç›®å½•ä¸å­˜åœ¨: {self.chapters_dir}")
            return

        # æ”¯æŒä¸¤ç§ç›®å½•ç»“æ„ï¼š
        # 1) æ­£æ–‡/ç¬¬0001ç« .md
        # 2) æ­£æ–‡/ç¬¬1å·/ç¬¬001ç« -æ ‡é¢˜.md
        chapter_files = sorted(self.chapters_dir.rglob("ç¬¬*.md"))

        # è§’è‰²å€™é€‰ï¼ˆfallback ç”¨ï¼‰ï¼šä» state.json è·å–å·²çŸ¥è§’è‰²å (v5.0 entities_v3 æ ¼å¼)
        known_character_names: List[str] = []
        protagonist_name = ""
        if self.state:
            protagonist_name = self.state.get("protagonist_state", {}).get("name", "") or ""
            # v5.0: ä» entities_v3.è§’è‰² è·å–è§’è‰²å
            entities_v3 = self.state.get("entities_v3", {})
            characters_dict = entities_v3.get("è§’è‰²", {})
            known_character_names = [
                c.get("canonical_name", char_id)
                for char_id, c in characters_dict.items()
                if c.get("canonical_name")
            ]

        for chapter_file in chapter_files:
            chapter_num = extract_chapter_num_from_filename(chapter_file.name)
            if not chapter_num:
                continue

            # è¯»å–ç« èŠ‚å†…å®¹
            with open(chapter_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # ç»Ÿè®¡å­—æ•°ï¼ˆå»é™¤ Markdown æ ‡è®°ï¼‰
            text = re.sub(r'```[\s\S]*?```', '', content)  # å»é™¤ä»£ç å—
            text = re.sub(r'#+ .+', '', text)  # å»é™¤æ ‡é¢˜
            text = re.sub(r'---', '', text)  # å»é™¤åˆ†éš”çº¿
            word_count = len(text.strip())

            # ä¸»å¯¼ Strand / çˆ½ç‚¹ç±»å‹ï¼ˆä¼˜å…ˆä»â€œæœ¬ç« ç»Ÿè®¡â€è§£æï¼‰
            dominant_strand = (self._extract_stats_field(content, "ä¸»å¯¼Strand") or "").lower()
            cool_point_type = self._extract_stats_field(content, "çˆ½ç‚¹")

            # è§’è‰²æå–ï¼šä¼˜å…ˆä»ç»“æ„åŒ–ç´¢å¼•è¯»å–ï¼ˆè‹¥æœ‰ï¼‰ï¼Œå¦åˆ™ fallback ç”¨â€œå‡ºç°å³ç®—å‡ºåœºâ€
            characters: List[str] = []
            if self.index is not None:
                try:
                    cursor = self.index.conn.execute(
                        "SELECT characters FROM chapters WHERE chapter_num = ?",
                        (chapter_num,),
                    )
                    row = cursor.fetchone()
                    if row and row[0]:
                        try:
                            stored = json.loads(row[0])
                            if isinstance(stored, list):
                                # v4.0: chapters.characters å­˜ entity_id åˆ—è¡¨ï¼Œè¾“å‡ºæ—¶å°½é‡è¿˜åŸä¸º canonical_name
                                for x in stored:
                                    entity_id = str(x).strip()
                                    if not entity_id:
                                        continue
                                    name = entity_id
                                    try:
                                        ent = self.index.query_entity_by_id(entity_id)
                                        if ent and ent.get("canonical_name"):
                                            name = str(ent["canonical_name"]).strip() or entity_id
                                    except Exception:
                                        name = entity_id
                                    characters.append(name)
                        except json.JSONDecodeError:
                            characters = []
                except Exception:
                    characters = []

            if not characters and (protagonist_name or known_character_names):
                # é™åˆ¶å€™é€‰è§„æ¨¡ï¼Œé¿å…åœ¨è¶…å¤§è§’è‰²åº“ä¸‹è¿‡æ…¢
                candidates = []
                if protagonist_name:
                    candidates.append(protagonist_name)
                candidates.extend(known_character_names[:self.config.character_candidates_limit])

                seen = set()
                for name in candidates:
                    if not name or name in seen:
                        continue
                    if name in content:
                        characters.append(name)
                        seen.add(name)

            self.chapters_data.append({
                "chapter": chapter_num,
                "file": chapter_file,
                "word_count": word_count,
                "characters": characters,
                "dominant": dominant_strand,
                "cool_point": cool_point_type,
            })

    def analyze_characters(self) -> Dict:
        """åˆ†æè§’è‰²æ´»è·ƒåº¦ (v5.0 entities_v3 æ ¼å¼)"""
        if not self.state:
            return {}

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)
        # v5.0: ä» entities_v3.è§’è‰² è·å–è§’è‰²
        entities_v3 = self.state.get("entities_v3", {})
        characters_dict = entities_v3.get("è§’è‰²", {})

        # ç»Ÿè®¡æ¯ä¸ªè§’è‰²çš„æœ€åå‡ºåœºç« èŠ‚
        character_activity = {}

        for char_id, char in characters_dict.items():
            char_name = char.get("canonical_name", char_id)
            if not char_name:
                continue

            # æŸ¥æ‰¾æœ€åå‡ºåœºç« èŠ‚
            last_appearance = 0

            for ch_data in self.chapters_data:
                if char_name in ch_data.get("characters", []):
                    last_appearance = max(last_appearance, ch_data["chapter"])

            absence = current_chapter - last_appearance

            character_activity[char_name] = {
                "last_appearance": last_appearance,
                "absence": absence,
                "status": self._get_absence_status(absence)
            }

        return character_activity

    def _get_absence_status(self, absence: int) -> str:
        """åˆ¤æ–­æ‰çº¿çŠ¶æ€"""
        if absence == 0:
            return "âœ… æ´»è·ƒ"
        elif absence < self.config.character_absence_warning:
            return "ğŸŸ¢ æ­£å¸¸"
        elif absence < self.config.character_absence_critical:
            return "ğŸŸ¡ è½»åº¦æ‰çº¿"
        else:
            return "ğŸ”´ ä¸¥é‡æ‰çº¿"

    def analyze_foreshadowing(self) -> List[Dict]:
        """åˆ†æä¼ç¬”æ·±åº¦"""
        if not self.state:
            return []

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)
        plot_threads = self.state.get("plot_threads", {})
        foreshadowing = plot_threads.get("foreshadowing", [])

        overdue = []

        for item in foreshadowing:
            status = item.get("status")
            if _is_resolved_foreshadowing_status(status):
                continue

            # å‡è®¾æ¯ä¸ªä¼ç¬”è®°å½•äº†"added_chapter"ï¼ˆåŸ‹è®¾ç« èŠ‚ï¼‰
            # å¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨ added_at æ—¥æœŸä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
            # è¿™é‡Œç®€åŒ–ï¼šå‡è®¾ç¬¬ 1 ç« å¼€å§‹ï¼Œå¹³å‡æ¯å¤©å†™ 1 ç« 

            # ç®€åŒ–ï¼šå‡è®¾ä¼ç¬”æŒ‰æ·»åŠ é¡ºåºï¼Œç¬¬ N ä¸ªä¼ç¬”å¤§çº¦åœ¨ç¬¬ N*10 ç« åŸ‹ä¸‹
            # å®é™…é¡¹ç›®åº”è¯¥åœ¨ä¼ç¬”è®°å½•ä¸­åŠ å…¥ "åŸ‹è®¾ç« èŠ‚å·" å­—æ®µ

            # è¿™é‡Œä½¿ç”¨ content ä¸­çš„å…³é”®è¯åŒ¹é…ï¼ˆæåº¦ç®€åŒ–ï¼‰
            content = item.get("content", "")

            # å‡è®¾ä¼ç¬”å¹³å‡åŸ‹è®¾æ—¶é—´ = å½“å‰ç« èŠ‚çš„ä¸€åŠï¼ˆæåº¦ç²—ç³™ä¼°ç®—ï¼‰
            estimated_chapter = current_chapter // 2
            elapsed = current_chapter - estimated_chapter

            overdue.append({
                "content": content,
                "estimated_chapter": estimated_chapter,
                "elapsed": elapsed,
                "status": self._get_foreshadowing_status(elapsed)
            })

        return overdue

    def _get_foreshadowing_status(self, elapsed: int) -> str:
        """åˆ¤æ–­ä¼ç¬”è¶…æ—¶çŠ¶æ€"""
        if elapsed < self.config.foreshadowing_urgency_pending_medium:
            return "ğŸŸ¢ æ­£å¸¸"
        elif elapsed < self.config.foreshadowing_urgency_pending_high + 50:
            return "ğŸŸ¡ è½»åº¦è¶…æ—¶"
        else:
            return "ğŸ”´ ä¸¥é‡è¶…æ—¶"

    def analyze_foreshadowing_urgency(self) -> List[Dict]:
        """
        åˆ†æä¼ç¬”ç´§æ€¥åº¦ï¼ˆåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼‰

        ä¸‰å±‚çº§æƒé‡ï¼š
        - æ ¸å¿ƒ(Core): æƒé‡ 3.0 - å¿…é¡»å›æ”¶ï¼Œå¦åˆ™å‰§æƒ…å´©å¡Œ
        - æ”¯çº¿(Sub): æƒé‡ 2.0 - åº”è¯¥å›æ”¶ï¼Œå¦åˆ™æ˜¾å¾—ä½œè€…å¥å¿˜
        - è£…é¥°(Decor): æƒé‡ 1.0 - å¯å›æ”¶å¯ä¸å›æ”¶ï¼Œä»…å¢åŠ çœŸå®æ„Ÿ

        ç´§æ€¥åº¦è®¡ç®—å…¬å¼ï¼š
        urgency = (å·²è¿‡ç« èŠ‚ / ç›®æ ‡å›æ”¶ç« èŠ‚) Ã— å±‚çº§æƒé‡
        """
        if not self.state:
            return []

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)
        plot_threads = self.state.get("plot_threads", {})
        foreshadowing = plot_threads.get("foreshadowing", [])

        # å±‚çº§æƒé‡æ˜ å°„
        tier_weights = {
            "æ ¸å¿ƒ": self.config.foreshadowing_tier_weight_core,
            "core": self.config.foreshadowing_tier_weight_core,
            "æ”¯çº¿": self.config.foreshadowing_tier_weight_sub,
            "sub": self.config.foreshadowing_tier_weight_sub,
            "è£…é¥°": self.config.foreshadowing_tier_weight_decor,
            "decor": self.config.foreshadowing_tier_weight_decor
        }

        urgency_list = []

        for item in foreshadowing:
            if _is_resolved_foreshadowing_status(item.get("status")):
                continue

            content = item.get("content", "")
            tier = item.get("tier", "æ”¯çº¿")  # é»˜è®¤æ”¯çº¿
            planted_chapter = item.get("planted_chapter", 1)
            target_chapter = item.get("target_chapter", planted_chapter + 100)

            weight = tier_weights.get(tier.lower(), self.config.foreshadowing_tier_weight_sub)
            elapsed = current_chapter - planted_chapter
            remaining = target_chapter - current_chapter

            # ç´§æ€¥åº¦è®¡ç®—
            if target_chapter > planted_chapter:
                urgency = (elapsed / (target_chapter - planted_chapter)) * weight
            else:
                urgency = weight * 2  # å·²è¶…æœŸ

            urgency_list.append({
                "content": content,
                "tier": tier,
                "weight": weight,
                "planted_chapter": planted_chapter,
                "target_chapter": target_chapter,
                "elapsed": elapsed,
                "remaining": remaining,
                "urgency": round(urgency, 2),
                "status": self._get_urgency_status(urgency, remaining)
            })

        # æŒ‰ç´§æ€¥åº¦æ’åºï¼ˆé™åºï¼‰
        return sorted(urgency_list, key=lambda x: x["urgency"], reverse=True)

    def _get_urgency_status(self, urgency: float, remaining: int) -> str:
        """åˆ¤æ–­ç´§æ€¥åº¦çŠ¶æ€"""
        if remaining < 0:
            return "ğŸ”´ å·²è¶…æœŸ"
        elif urgency >= self.config.foreshadowing_tier_weight_sub:
            return "ğŸ”´ ç´§æ€¥"
        elif urgency >= 1.0:
            return "ğŸŸ¡ è­¦å‘Š"
        else:
            return "ğŸŸ¢ æ­£å¸¸"

    def analyze_strand_weave(self) -> Dict:
        """
        åˆ†æ Strand Weave èŠ‚å¥åˆ†å¸ƒ

        ä¸‰çº¿å®šä¹‰ï¼š
        - Questï¼ˆä¸»çº¿ï¼‰: æˆ˜æ–—ã€ä»»åŠ¡ã€å‡çº§ - ç›®æ ‡ 55-65%
        - Fireï¼ˆæ„Ÿæƒ…ï¼‰: æ„Ÿæƒ…çº¿ã€äººé™…äº’åŠ¨ - ç›®æ ‡ 20-30%
        - Constellationï¼ˆä¸–ç•Œè§‚ï¼‰: ä¸–ç•Œè§‚å±•å¼€ã€åŠ¿åŠ›èƒŒæ™¯ - ç›®æ ‡ 10-20%

        æ£€æŸ¥è§„åˆ™ï¼š
        - Quest çº¿è¿ç»­ä¸è¶…è¿‡ 5 ç« 
        - Fire çº¿ç¼ºå¤±ä¸è¶…è¿‡ 10 ç« 
        - Constellation çº¿ç¼ºå¤±ä¸è¶…è¿‡ 15 ç« 
        """
        if not self.state:
            return {}

        strand_tracker = self.state.get("strand_tracker", {})
        history = strand_tracker.get("history", [])

        if not history:
            return {
                "has_data": False,
                "message": "æš‚æ—  Strand Weave æ•°æ®"
            }

        # ç»Ÿè®¡å„çº¿å æ¯”
        quest_count = 0
        fire_count = 0
        constellation_count = 0
        total = len(history)

        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["quest", "ä¸»çº¿", "æˆ˜æ–—", "ä»»åŠ¡"]:
                quest_count += 1
            elif strand in ["fire", "æ„Ÿæƒ…", "æ„Ÿæƒ…çº¿", "äº’åŠ¨"]:
                fire_count += 1
            elif strand in ["constellation", "ä¸–ç•Œè§‚", "èƒŒæ™¯", "åŠ¿åŠ›"]:
                constellation_count += 1

        # è®¡ç®—å æ¯”
        quest_ratio = (quest_count / total * 100) if total > 0 else 0
        fire_ratio = (fire_count / total * 100) if total > 0 else 0
        constellation_ratio = (constellation_count / total * 100) if total > 0 else 0

        # æ£€æŸ¥è¿è§„
        violations = []

        # æ£€æŸ¥ Quest è¿ç»­è¶…è¿‡ 5 ç« 
        quest_streak = 0
        max_quest_streak = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["quest", "ä¸»çº¿", "æˆ˜æ–—", "ä»»åŠ¡"]:
                quest_streak += 1
                max_quest_streak = max(max_quest_streak, quest_streak)
            else:
                quest_streak = 0

        if max_quest_streak > self.config.strand_quest_max_consecutive:
            violations.append(f"Quest çº¿è¿ç»­ {max_quest_streak} ç« ï¼ˆè¶…è¿‡ {self.config.strand_quest_max_consecutive} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥ Fire ç¼ºå¤±è¶…è¿‡ 10 ç« 
        fire_gap = 0
        max_fire_gap = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["fire", "æ„Ÿæƒ…", "æ„Ÿæƒ…çº¿", "äº’åŠ¨"]:
                max_fire_gap = max(max_fire_gap, fire_gap)
                fire_gap = 0
            else:
                fire_gap += 1
        max_fire_gap = max(max_fire_gap, fire_gap)

        if max_fire_gap > self.config.strand_fire_max_gap:
            violations.append(f"Fire çº¿ç¼ºå¤± {max_fire_gap} ç« ï¼ˆè¶…è¿‡ {self.config.strand_fire_max_gap} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥ Constellation ç¼ºå¤±è¶…è¿‡ 15 ç« 
        const_gap = 0
        max_const_gap = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["constellation", "ä¸–ç•Œè§‚", "èƒŒæ™¯", "åŠ¿åŠ›"]:
                max_const_gap = max(max_const_gap, const_gap)
                const_gap = 0
            else:
                const_gap += 1
        max_const_gap = max(max_const_gap, const_gap)

        if max_const_gap > self.config.strand_constellation_max_gap:
            violations.append(f"Constellation çº¿ç¼ºå¤± {max_const_gap} ç« ï¼ˆè¶…è¿‡ {self.config.strand_constellation_max_gap} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥å æ¯”æ˜¯å¦åœ¨åˆç†èŒƒå›´
        cfg = self.config
        if quest_ratio < cfg.strand_quest_ratio_min:
            violations.append(f"Quest å æ¯” {quest_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}%ï¼‰")
        elif quest_ratio > cfg.strand_quest_ratio_max:
            violations.append(f"Quest å æ¯” {quest_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}%ï¼‰")

        if fire_ratio < cfg.strand_fire_ratio_min:
            violations.append(f"Fire å æ¯” {fire_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}%ï¼‰")
        elif fire_ratio > cfg.strand_fire_ratio_max:
            violations.append(f"Fire å æ¯” {fire_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}%ï¼‰")

        if constellation_ratio < cfg.strand_constellation_ratio_min:
            violations.append(f"Constellation å æ¯” {constellation_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}%ï¼‰")
        elif constellation_ratio > cfg.strand_constellation_ratio_max:
            violations.append(f"Constellation å æ¯” {constellation_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}%ï¼‰")

        return {
            "has_data": True,
            "total_chapters": total,
            "quest": {"count": quest_count, "ratio": quest_ratio},
            "fire": {"count": fire_count, "ratio": fire_ratio},
            "constellation": {"count": constellation_count, "ratio": constellation_ratio},
            "violations": violations,
            "max_quest_streak": max_quest_streak,
            "max_fire_gap": max_fire_gap,
            "max_const_gap": max_const_gap,
            "health": "âœ… å¥åº·" if not violations else f"âš ï¸ {len(violations)} ä¸ªé—®é¢˜"
        }

    def analyze_pacing(self) -> List[Dict]:
        """åˆ†æçˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒï¼ˆæ¯ N ç« ä¸ºä¸€æ®µï¼‰"""
        segment_size = self.config.pacing_segment_size
        segments = []

        for i in range(0, len(self.chapters_data), segment_size):
            segment_chapters = self.chapters_data[i:i+segment_size]

            if not segment_chapters:
                continue

            start_ch = segment_chapters[0]["chapter"]
            end_ch = segment_chapters[-1]["chapter"]
            total_words = sum(ch["word_count"] for ch in segment_chapters)

            # å‡è®¾çˆ½ç‚¹æ•°é‡ = ç« èŠ‚æ•°ï¼ˆç®€åŒ–ï¼šæ¯ç« è‡³å°‘ 1 ä¸ªçˆ½ç‚¹ï¼‰
            # å®é™…é¡¹ç›®åº”è¯¥åœ¨å®¡æŸ¥æŠ¥å‘Šä¸­è®°å½•çˆ½ç‚¹æ•°é‡
            assumed_cool_points = len(segment_chapters)

            words_per_point = total_words / assumed_cool_points if assumed_cool_points > 0 else 0

            segments.append({
                "start": start_ch,
                "end": end_ch,
                "total_words": total_words,
                "cool_points": assumed_cool_points,
                "words_per_point": words_per_point,
                "rating": self._get_pacing_rating(words_per_point)
            })

        return segments

    def _get_pacing_rating(self, words_per_point: float) -> str:
        """åˆ¤æ–­èŠ‚å¥è¯„çº§"""
        if words_per_point < self.config.pacing_words_per_point_excellent:
            return "ä¼˜ç§€"
        elif words_per_point < self.config.pacing_words_per_point_good:
            return "è‰¯å¥½"
        elif words_per_point < self.config.pacing_words_per_point_acceptable:
            return "åŠæ ¼"
        else:
            return "åä½âš ï¸"

    def generate_relationship_graph(self) -> str:
        """ç”Ÿæˆäººé™…å…³ç³» Mermaid å›¾"""
        if not self.state:
            return ""

        relationships = self.state.get("relationships", {})
        protagonist_name = self.state.get("protagonist_state", {}).get("name", "ä¸»è§’")

        lines = ["```mermaid", "graph LR"]

        # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        # æ ¼å¼1ï¼ˆæ–°ï¼‰: {"allies": [...], "enemies": [...]}
        # æ ¼å¼2ï¼ˆæ—§ï¼‰: {"è§’è‰²å": {"affection": X, "hatred": Y}}

        allies = relationships.get("allies", [])
        enemies = relationships.get("enemies", [])

        if allies or enemies:
            # æ–°æ ¼å¼
            for ally in allies:
                if isinstance(ally, dict):
                    name = ally.get("name", "æœªçŸ¥")
                    relation = ally.get("relation", "å‹å¥½")
                    lines.append(f"    {protagonist_name} -->|{relation}| {name}")

            for enemy in enemies:
                if isinstance(enemy, dict):
                    name = enemy.get("name", "æœªçŸ¥")
                    relation = enemy.get("relation", "æ•Œå¯¹")
                    lines.append(f"    {protagonist_name} -.->|{relation}| {name}")
        else:
            # æ—§æ ¼å¼å…¼å®¹
            for char_name, rel_data in relationships.items():
                if isinstance(rel_data, dict):
                    affection = rel_data.get("affection", 0)
                    hatred = rel_data.get("hatred", 0)

                    if affection > 0:
                        lines.append(f"    {protagonist_name} -->|å¥½æ„Ÿåº¦{affection}| {char_name}")

                    if hatred > 0:
                        lines.append(f"    {protagonist_name} -.->|ä»‡æ¨åº¦{hatred}| {char_name}")

        lines.append("```")

        return "\n".join(lines)

    def generate_report(self, focus: str = "all") -> str:
        """ç”Ÿæˆå¥åº·æŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰"""

        report_lines = [
            "# å…¨ä¹¦å¥åº·æŠ¥å‘Š",
            "",
            f"> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            ""
        ]

        # åŸºæœ¬æ•°æ®
        if focus in ["all", "basic"]:
            report_lines.extend(self._generate_basic_stats())

        # è§’è‰²æ´»è·ƒåº¦
        if focus in ["all", "characters"]:
            report_lines.extend(self._generate_character_section())

        # ä¼ç¬”æ·±åº¦
        if focus in ["all", "foreshadowing"]:
            report_lines.extend(self._generate_foreshadowing_section())

        # ä¼ç¬”ç´§æ€¥åº¦ï¼ˆæ–°å¢ï¼‰
        if focus in ["all", "foreshadowing", "urgency"]:
            report_lines.extend(self._generate_urgency_section())

        # çˆ½ç‚¹èŠ‚å¥
        if focus in ["all", "pacing"]:
            report_lines.extend(self._generate_pacing_section())

        # Strand Weave èŠ‚å¥ï¼ˆæ–°å¢ï¼‰
        if focus in ["all", "strand", "pacing"]:
            report_lines.extend(self._generate_strand_section())

        # äººé™…å…³ç³»
        if focus in ["all", "relationships"]:
            report_lines.extend(self._generate_relationship_section())

        return "\n".join(report_lines)

    def _generate_basic_stats(self) -> List[str]:
        """ç”ŸæˆåŸºæœ¬ç»Ÿè®¡"""
        if not self.state:
            return []

        progress = self.state.get("progress", {})
        current_chapter = progress.get("current_chapter", 0)
        total_words = progress.get("total_words", 0)
        target_words = self.state.get("project_info", {}).get("target_words", 2000000)

        avg_words = total_words / current_chapter if current_chapter > 0 else 0
        completion = (total_words / target_words * 100) if target_words > 0 else 0

        return [
            "## ğŸ“Š åŸºæœ¬æ•°æ®",
            "",
            f"- **æ€»ç« èŠ‚æ•°**: {current_chapter} ç« ",
            f"- **æ€»å­—æ•°**: {total_words:,} å­—",
            f"- **å¹³å‡ç« èŠ‚å­—æ•°**: {avg_words:,.0f} å­—",
            f"- **åˆ›ä½œè¿›åº¦**: {completion:.1f}%ï¼ˆç›®æ ‡ {target_words:,} å­—ï¼‰",
            "",
            "---",
            ""
        ]

    def _generate_character_section(self) -> List[str]:
        """ç”Ÿæˆè§’è‰²åˆ†æç« èŠ‚"""
        activity = self.analyze_characters()

        if not activity:
            return []

        # ç­›é€‰æ‰çº¿è§’è‰²
        dropped = {name: data for name, data in activity.items()
                  if "æ‰çº¿" in data["status"]}

        lines = [
            f"## âš ï¸ è§’è‰²æ‰çº¿ï¼ˆ{len(dropped)}äººï¼‰",
            ""
        ]

        if dropped:
            lines.extend([
                "| è§’è‰² | æœ€åå‡ºåœº | ç¼ºå¸­ç« èŠ‚ | çŠ¶æ€ |",
                "|------|---------|---------|------|"
            ])

            for char_name, data in sorted(dropped.items(),
                                         key=lambda x: x[1]["absence"],
                                         reverse=True):
                lines.append(
                    f"| {char_name} | ç¬¬ {data['last_appearance']} ç«  | "
                    f"{data['absence']} ç«  | {data['status']} |"
                )
        else:
            lines.append("âœ… æ‰€æœ‰è§’è‰²æ´»è·ƒåº¦æ­£å¸¸")

        lines.extend(["", "---", ""])

        return lines

    def _generate_foreshadowing_section(self) -> List[str]:
        """ç”Ÿæˆä¼ç¬”åˆ†æç« èŠ‚"""
        overdue = self.analyze_foreshadowing()

        # ç­›é€‰è¶…æ—¶ä¼ç¬”
        overdue_items = [item for item in overdue if "è¶…æ—¶" in item["status"]]

        lines = [
            f"## âš ï¸ ä¼ç¬”è¶…æ—¶ï¼ˆ{len(overdue_items)}æ¡ï¼‰",
            ""
        ]

        if overdue_items:
            lines.extend([
                "| ä¼ç¬”å†…å®¹ | ä¼°è®¡åŸ‹è®¾ | å·²è¿‡ç« èŠ‚ | çŠ¶æ€ |",
                "|---------|---------|---------|------|"
            ])

            for item in sorted(overdue_items, key=lambda x: x["elapsed"], reverse=True):
                lines.append(
                    f"| {item['content'][:30]}... | ç¬¬ {item['estimated_chapter']} ç«  | "
                    f"{item['elapsed']} ç«  | {item['status']} |"
                )
        else:
            lines.append("âœ… æ‰€æœ‰ä¼ç¬”è¿›åº¦æ­£å¸¸")

        lines.extend(["", "---", ""])

        return lines

    def _generate_urgency_section(self) -> List[str]:
        """ç”Ÿæˆä¼ç¬”ç´§æ€¥åº¦ç« èŠ‚ï¼ˆåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼‰"""
        urgency_list = self.analyze_foreshadowing_urgency()

        # ç­›é€‰ç´§æ€¥ä¼ç¬”
        urgent_items = [item for item in urgency_list if item["urgency"] >= 1.0]

        lines = [
            f"## ğŸš¨ ä¼ç¬”ç´§æ€¥åº¦æ’åºï¼ˆ{len(urgent_items)}æ¡éœ€å…³æ³¨ï¼‰",
            "",
            "> åŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼šæ ¸å¿ƒ(Ã—3) / æ”¯çº¿(Ã—2) / è£…é¥°(Ã—1)",
            "> ç´§æ€¥åº¦ = (å·²è¿‡ç« èŠ‚ / ç›®æ ‡å›æ”¶ç« èŠ‚) Ã— å±‚çº§æƒé‡",
            ""
        ]

        if urgency_list:
            lines.extend([
                "| ä¼ç¬”å†…å®¹ | å±‚çº§ | åŸ‹è®¾ | ç›®æ ‡ | ç´§æ€¥åº¦ | çŠ¶æ€ |",
                "|---------|------|------|------|--------|------|"
            ])

            for item in urgency_list[:10]:  # åªæ˜¾ç¤ºå‰10æ¡
                lines.append(
                    f"| {item['content'][:20]}... | {item['tier']} | "
                    f"ç¬¬{item['planted_chapter']}ç«  | ç¬¬{item['target_chapter']}ç«  | "
                    f"{item['urgency']:.2f} | {item['status']} |"
                )
        else:
            lines.append("âœ… æš‚æ— ä¼ç¬”æ•°æ®")

        lines.extend(["", "---", ""])

        return lines

    def _generate_strand_section(self) -> List[str]:
        """ç”Ÿæˆ Strand Weave èŠ‚å¥ç« èŠ‚"""
        strand_data = self.analyze_strand_weave()

        lines = [
            "## ğŸ­ Strand Weave èŠ‚å¥åˆ†æ",
            ""
        ]

        if not strand_data.get("has_data"):
            lines.append(f"âš ï¸ {strand_data.get('message', 'æš‚æ— æ•°æ®')}")
            lines.extend(["", "---", ""])
            return lines

        # å æ¯”ç»Ÿè®¡
        cfg = self.config
        lines.extend([
            "### ä¸‰çº¿å æ¯”",
            "",
            "| Strand | ç« èŠ‚æ•° | å æ¯” | ç›®æ ‡èŒƒå›´ | çŠ¶æ€ |",
            "|--------|--------|------|----------|------|"
        ])

        q = strand_data["quest"]
        q_status = "âœ…" if cfg.strand_quest_ratio_min <= q["ratio"] <= cfg.strand_quest_ratio_max else "âš ï¸"
        lines.append(f"| Questï¼ˆä¸»çº¿ï¼‰ | {q['count']} | {q['ratio']:.1f}% | {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}% | {q_status} |")

        f = strand_data["fire"]
        f_status = "âœ…" if cfg.strand_fire_ratio_min <= f["ratio"] <= cfg.strand_fire_ratio_max else "âš ï¸"
        lines.append(f"| Fireï¼ˆæ„Ÿæƒ…ï¼‰ | {f['count']} | {f['ratio']:.1f}% | {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}% | {f_status} |")

        c = strand_data["constellation"]
        c_status = "âœ…" if cfg.strand_constellation_ratio_min <= c["ratio"] <= cfg.strand_constellation_ratio_max else "âš ï¸"
        lines.append(f"| Constellationï¼ˆä¸–ç•Œè§‚ï¼‰ | {c['count']} | {c['ratio']:.1f}% | {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}% | {c_status} |")

        lines.append("")

        # è¿ç»­æ€§æ£€æŸ¥
        lines.extend([
            "### è¿ç»­æ€§æ£€æŸ¥",
            "",
            f"- Quest æœ€å¤§è¿ç»­: {strand_data['max_quest_streak']} ç« ï¼ˆé™åˆ¶ â‰¤5ï¼‰",
            f"- Fire æœ€å¤§ç¼ºå¤±: {strand_data['max_fire_gap']} ç« ï¼ˆé™åˆ¶ â‰¤10ï¼‰",
            f"- Constellation æœ€å¤§ç¼ºå¤±: {strand_data['max_const_gap']} ç« ï¼ˆé™åˆ¶ â‰¤15ï¼‰",
            ""
        ])

        # è¿è§„æ¸…å•
        if strand_data["violations"]:
            lines.extend([
                "### âš ï¸ è¿è§„æ¸…å•",
                ""
            ])
            for v in strand_data["violations"]:
                lines.append(f"- {v}")
        else:
            lines.append("### âœ… æ— è¿è§„")

        lines.extend(["", f"**ç»¼åˆå¥åº·åº¦**: {strand_data['health']}", "", "---", ""])

        return lines

    def _generate_pacing_section(self) -> List[str]:
        """ç”ŸæˆèŠ‚å¥åˆ†æç« èŠ‚"""
        segments = self.analyze_pacing()

        lines = [
            "## ğŸ“ˆ çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒ",
            "",
            "```"
        ]

        for seg in segments:
            bar_length = int(12 - (seg["words_per_point"] / 2000 * 12))
            bar_length = max(1, min(12, bar_length))

            bar = "â–ˆ" * bar_length

            lines.append(
                f"ç¬¬ {seg['start']}-{seg['end']}ç«    {bar} "
                f"{seg['rating']}ï¼ˆ{seg['words_per_point']:.0f}å­—/çˆ½ç‚¹ï¼‰"
            )

        lines.extend(["```", "", "---", ""])

        return lines

    def _generate_relationship_section(self) -> List[str]:
        """ç”Ÿæˆäººé™…å…³ç³»ç« èŠ‚"""
        graph = self.generate_relationship_graph()

        lines = [
            "## ğŸ’‘ äººé™…å…³ç³»è¶‹åŠ¿",
            "",
            graph,
            "",
            "---",
            ""
        ]

        return lines

def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="å¯è§†åŒ–çŠ¶æ€æŠ¥å‘Šç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # ç”Ÿæˆå®Œæ•´å¥åº·æŠ¥å‘Š
  python status_reporter.py --output .webnovel/health_report.md

  # ä»…åˆ†æè§’è‰²æ´»è·ƒåº¦
  python status_reporter.py --focus characters

  # ä»…åˆ†æä¼ç¬”
  python status_reporter.py --focus foreshadowing

  # ä»…åˆ†æçˆ½ç‚¹èŠ‚å¥
  python status_reporter.py --focus pacing
        """
    )

    parser.add_argument('--output', default='.webnovel/health_report.md',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--focus', choices=['all', 'basic', 'characters',
                                            'foreshadowing', 'urgency', 'pacing',
                                            'strand', 'relationships'],
                       default='all', help='åˆ†æç„¦ç‚¹ï¼ˆæ–°å¢ urgency, strandï¼‰')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•')

    args = parser.parse_args()

    # è§£æé¡¹ç›®æ ¹ç›®å½•ï¼ˆæ”¯æŒä»ä»“åº“æ ¹ç›®å½•è¿è¡Œï¼‰
    project_root = args.project_root
    if project_root == '.' and not (Path('.') / '.webnovel' / 'state.json').exists():
        try:
            project_root = str(resolve_project_root())
        except FileNotFoundError:
            project_root = args.project_root

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = StatusReporter(project_root)

    # åŠ è½½çŠ¶æ€
    if not reporter.load_state():
        sys.exit(1)

    print("ğŸ“– æ­£åœ¨æ‰«æç« èŠ‚æ–‡ä»¶...")
    reporter.scan_chapters()

    print(f"âœ… å·²æ‰«æ {len(reporter.chapters_data)} ä¸ªç« èŠ‚")

    print("\nğŸ“Š æ­£åœ¨åˆ†æ...")

    # ç”ŸæˆæŠ¥å‘Š
    report = reporter.generate_report(args.focus)

    # ä¿å­˜æŠ¥å‘Š
    output_file = Path(args.output)
    if args.output == '.webnovel/health_report.md' and project_root != '.':
        output_file = Path(project_root) / '.webnovel' / 'health_report.md'
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nâœ… å¥åº·æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    # é¢„è§ˆæŠ¥å‘Šï¼ˆå‰ 30 è¡Œï¼‰
    print("\n" + "="*60)
    print("ğŸ“„ æŠ¥å‘Šé¢„è§ˆï¼š\n")
    print("\n".join(report.split("\n")[:30]))
    print("\n...")
    print("="*60)

if __name__ == "__main__":
    main()
