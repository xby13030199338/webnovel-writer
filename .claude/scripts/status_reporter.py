#!/usr/bin/env python3
"""
å¯è§†åŒ–çŠ¶æ€æŠ¥å‘Šç³»ç»Ÿ (Status Reporter)

æ ¸å¿ƒç†å¿µï¼šé¢å¯¹ 1000 ä¸ªç« èŠ‚ï¼Œä½œè€…ä¼šè¿·å¤±ã€‚éœ€è¦"å®è§‚ä¿¯ç°"èƒ½åŠ›ã€‚

åŠŸèƒ½ï¼š
1. è§’è‰²æ´»è·ƒåº¦åˆ†æï¼šå“ªäº›è§’è‰²å¤ªä¹…æ²¡å‡ºåœºï¼ˆæ‰çº¿ç»Ÿè®¡ï¼‰
2. ä¼ç¬”æ·±åº¦åˆ†æï¼šå“ªäº›å‘æŒ–å¾—å¤ªä¹…äº†ï¼ˆè¶…è¿‡ 20 ä¸‡å­—æœªæ”¶ï¼‰+ ç´§æ€¥åº¦æ’åº
3. çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒï¼šå…¨ä¹¦é«˜æ½®ç‚¹çš„åˆ†å¸ƒé¢‘ç‡ï¼ˆçƒ­åŠ›å›¾ï¼‰
4. å­—æ•°åˆ†å¸ƒç»Ÿè®¡ï¼šå„å·ã€å„ç¯‡çš„å­—æ•°åˆ†å¸ƒ
5. äººé™…å…³ç³»å›¾è°±ï¼šå¥½æ„Ÿåº¦/ä»‡æ¨åº¦è¶‹åŠ¿
6. Strand Weave èŠ‚å¥åˆ†æï¼šQuest/Fire/Constellation ä¸‰çº¿å æ¯”ç»Ÿè®¡
7. ä¼ç¬”ç´§æ€¥åº¦æ’åºï¼šåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼ˆæ ¸å¿ƒ/æ”¯çº¿/è£…é¥°ï¼‰çš„ä¼˜å…ˆçº§è®¡ç®—

è¾“å‡ºæ ¼å¼ï¼š
  - Markdown æŠ¥å‘Šï¼ˆ.webnovel/health_report.mdï¼‰
  - åŒ…å« Mermaid å›¾è¡¨ï¼ˆè§’è‰²å…³ç³»å›¾ã€çˆ½ç‚¹çƒ­åŠ›å›¾ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  # ç”Ÿæˆå®Œæ•´å¥åº·æŠ¥å‘Š
  python status_reporter.py --output .webnovel/health_report.md

  # ä»…åˆ†æè§’è‰²æ´»è·ƒåº¦
  python status_reporter.py --focus characters

  # ä»…åˆ†æä¼ç¬”
  python status_reporter.py --focus foreshadowing

  # ä»…åˆ†æçˆ½ç‚¹èŠ‚å¥
  python status_reporter.py --focus pacing

  # åˆ†æ Strand Weave èŠ‚å¥
  python status_reporter.py --focus strand

æŠ¥å‘Šç¤ºä¾‹ï¼š
  # å…¨ä¹¦å¥åº·æŠ¥å‘Š

  ## ğŸ“Š åŸºæœ¬æ•°æ®

  - **æ€»ç« èŠ‚æ•°**: 450 ç« 
  - **æ€»å­—æ•°**: 1,985,432 å­—
  - **å¹³å‡ç« èŠ‚å­—æ•°**: 4,412 å­—
  - **åˆ›ä½œè¿›åº¦**: 99.3%ï¼ˆç›®æ ‡ 200ä¸‡å­—ï¼‰

  ## âš ï¸ è§’è‰²æ‰çº¿ï¼ˆ3äººï¼‰

  | è§’è‰² | æœ€åå‡ºåœº | ç¼ºå¸­ç« èŠ‚ | çŠ¶æ€ |
  |------|---------|---------|------|
  | æé›ª | ç¬¬ 350 ç«  | 100 ç«  | ğŸ”´ ä¸¥é‡æ‰çº¿ |
  | è¡€ç…é—¨ä¸» | ç¬¬ 300 ç«  | 150 ç«  | ğŸ”´ ä¸¥é‡æ‰çº¿ |
  | å¤©äº‘å®—å®—ä¸» | ç¬¬ 400 ç«  | 50 ç«  | ğŸŸ¡ è½»åº¦æ‰çº¿ |

  ## âš ï¸ ä¼ç¬”è¶…æ—¶ï¼ˆ2æ¡ï¼‰

  | ä¼ç¬”å†…å®¹ | åŸ‹è®¾ç« èŠ‚ | å·²è¿‡ç« èŠ‚ | çŠ¶æ€ |
  |---------|---------|---------|------|
  | "æ—å®¶å®åº“é“­æ–‡çš„ç§˜å¯†" | ç¬¬ 200 ç«  | 250 ç«  | ğŸ”´ ä¸¥é‡è¶…æ—¶ |
  | "ç¥ç§˜ç‰ä½©çš„æ¥å†" | ç¬¬ 270 ç«  | 180 ç«  | ğŸŸ¡ è½»åº¦è¶…æ—¶ |

  ## ğŸ“ˆ çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒ

  ```
  ç¬¬ 1-100 ç«    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ä¼˜ç§€ï¼ˆ1200å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 101-200ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1500å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 201-300ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1600å­—/çˆ½ç‚¹ï¼‰
  ç¬¬ 301-400ç«   â–ˆâ–ˆâ–ˆâ–ˆ åä½ï¼ˆ2200å­—/çˆ½ç‚¹ï¼‰âš ï¸
  ç¬¬ 401-450ç«   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ è‰¯å¥½ï¼ˆ1550å­—/çˆ½ç‚¹ï¼‰
  ```

  ## ğŸ’‘ äººé™…å…³ç³»è¶‹åŠ¿

  ```mermaid
  graph LR
    ä¸»è§’ -->|å¥½æ„Ÿåº¦95| æé›ª
    ä¸»è§’ -->|å¥½æ„Ÿåº¦60| æ…•å®¹é›ª
    ä¸»è§’ -->|ä»‡æ¨åº¦100| è¡€ç…é—¨
  ```
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime
from collections import defaultdict
from project_locator import resolve_project_root
from chapter_paths import extract_chapter_num_from_filename

# å¯¼å…¥é…ç½®
try:
    from data_modules.config import get_config, DataModulesConfig
    from data_modules.index_manager import IndexManager
    from data_modules.state_validator import (
        get_chapter_meta_entry,
        is_resolved_foreshadowing_status,
        normalize_foreshadowing_tier,
        normalize_state_runtime_sections,
        resolve_chapter_field,
        to_positive_int,
    )
except ImportError:
    from scripts.data_modules.config import get_config, DataModulesConfig
    from scripts.data_modules.index_manager import IndexManager
    from scripts.data_modules.state_validator import (
        get_chapter_meta_entry,
        is_resolved_foreshadowing_status,
        normalize_foreshadowing_tier,
        normalize_state_runtime_sections,
        resolve_chapter_field,
        to_positive_int,
    )

def _is_resolved_foreshadowing_status(raw_status: Any) -> bool:
    """åˆ¤æ–­ä¼ç¬”æ˜¯å¦å·²å›æ”¶ï¼ˆå…¼å®¹å†å²å­—æ®µä¸åŒä¹‰è¯ï¼‰ã€‚"""
    return is_resolved_foreshadowing_status(raw_status)

def _enable_windows_utf8_stdio() -> None:
    """åœ¨ Windows ä¸‹å¯ç”¨ UTF-8 è¾“å‡ºï¼›pytest ç¯å¢ƒè·³è¿‡ä»¥é¿å…æ•è·å†²çªã€‚"""
    if sys.platform != "win32":
        return
    if os.environ.get("PYTEST_CURRENT_TEST"):
        return

    try:
        import io

        stdout_buffer = getattr(sys.stdout, "buffer", None)
        stderr_buffer = getattr(sys.stderr, "buffer", None)
        if stdout_buffer is not None:
            sys.stdout = io.TextIOWrapper(stdout_buffer, encoding="utf-8")
        if stderr_buffer is not None:
            sys.stderr = io.TextIOWrapper(stderr_buffer, encoding="utf-8")
    except Exception:
        pass


class StatusReporter:
    """çŠ¶æ€æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.config = get_config(self.project_root)
        self.state_file = self.project_root / ".webnovel/state.json"
        self.chapters_dir = self.project_root / "æ­£æ–‡"

        self.state = None
        self.chapters_data = []
        self._reading_power_cache: Dict[int, Optional[Dict[str, Any]]] = {}

        # v5.1 å¼•å…¥: ä½¿ç”¨ IndexManager è¯»å–å®ä½“
        self._index_manager = IndexManager(self.config)

    def _extract_stats_field(self, content: str, field_name: str) -> str:
        """
        ä»â€œæœ¬ç« ç»Ÿè®¡â€åŒºå—æå–å­—æ®µå€¼ï¼Œä¾‹å¦‚ï¼š
        - **ä¸»å¯¼Strand**: quest
        """
        pattern = rf"^\s*-\s*\*\*{re.escape(field_name)}\*\*\s*:\s*(.+?)\s*$"
        for line in content.splitlines():
            m = re.match(pattern, line)
            if m:
                return m.group(1).strip()
        return ""

    def load_state(self) -> bool:
        """åŠ è½½ state.json"""
        if not self.state_file.exists():
            print(f"âŒ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {self.state_file}")
            return False

        with open(self.state_file, 'r', encoding='utf-8') as f:
            self.state = json.load(f)

        if isinstance(self.state, dict):
            self.state = normalize_state_runtime_sections(self.state)

        return True

    def _to_positive_int(self, value: Any) -> Optional[int]:
        """å°†è¾“å…¥è§£æä¸ºæ­£æ•´æ•°ï¼›è§£æå¤±è´¥è¿”å› Noneã€‚"""
        return to_positive_int(value)

    def _normalize_foreshadowing_tier(self, raw_tier: Any) -> Tuple[str, float]:
        """æ ‡å‡†åŒ–ä¼ç¬”å±‚çº§å¹¶è¿”å›å¯¹åº”æƒé‡ã€‚"""
        tier = normalize_foreshadowing_tier(raw_tier)

        if tier == "æ ¸å¿ƒ":
            return "æ ¸å¿ƒ", self.config.foreshadowing_tier_weight_core
        if tier == "è£…é¥°":
            return "è£…é¥°", self.config.foreshadowing_tier_weight_decor
        return "æ”¯çº¿", self.config.foreshadowing_tier_weight_sub

    def _resolve_chapter_field(self, item: Dict[str, Any], keys: List[str]) -> Optional[int]:
        """æŒ‰å€™é€‰é”®é¡ºåºè¯»å–ç« èŠ‚å·ã€‚"""
        return resolve_chapter_field(item, keys)

    def _collect_foreshadowing_records(self) -> List[Dict[str, Any]]:
        """æ”¶é›†æœªå›æ”¶ä¼ç¬”ï¼Œå¹¶åŸºäºçœŸå®å­—æ®µæ„å»ºåˆ†æè®°å½•ã€‚"""
        if not self.state:
            return []

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)
        plot_threads = self.state.get("plot_threads", {}) if isinstance(self.state.get("plot_threads"), dict) else {}
        foreshadowing = plot_threads.get("foreshadowing", [])
        if not isinstance(foreshadowing, list):
            return []

        records: List[Dict[str, Any]] = []
        for item in foreshadowing:
            if not isinstance(item, dict):
                continue
            if _is_resolved_foreshadowing_status(item.get("status")):
                continue

            content = str(item.get("content") or "").strip() or "[æœªå‘½åä¼ç¬”]"
            tier, weight = self._normalize_foreshadowing_tier(item.get("tier"))

            planted_chapter = self._resolve_chapter_field(
                item,
                [
                    "planted_chapter",
                    "added_chapter",
                    "source_chapter",
                    "start_chapter",
                    "chapter",
                ],
            )
            target_chapter = self._resolve_chapter_field(
                item,
                [
                    "target_chapter",
                    "due_chapter",
                    "deadline_chapter",
                    "resolve_by_chapter",
                    "target",
                ],
            )

            elapsed = None
            if planted_chapter is not None:
                elapsed = max(0, current_chapter - planted_chapter)

            remaining = None
            if target_chapter is not None:
                remaining = target_chapter - current_chapter

            if remaining is not None and remaining < 0:
                overtime_status = "ğŸ”´ å·²è¶…æœŸ"
            elif elapsed is None:
                overtime_status = "âšª æ•°æ®ä¸è¶³"
            else:
                overtime_status = self._get_foreshadowing_status(elapsed)

            urgency: Optional[float] = None
            if (
                planted_chapter is not None
                and target_chapter is not None
                and target_chapter > planted_chapter
                and elapsed is not None
            ):
                urgency = round((elapsed / (target_chapter - planted_chapter)) * weight, 2)
            elif (
                planted_chapter is not None
                and target_chapter is not None
                and target_chapter <= planted_chapter
                and elapsed is not None
            ):
                urgency = round(weight * 2.0, 2)

            if remaining is not None and remaining < 0:
                urgency_status = "ğŸ”´ å·²è¶…æœŸ"
            elif urgency is None:
                urgency_status = "âšª æ•°æ®ä¸è¶³"
            else:
                urgency_status = self._get_urgency_status(urgency, remaining if remaining is not None else 0)

            records.append(
                {
                    "content": content,
                    "tier": tier,
                    "weight": weight,
                    "planted_chapter": planted_chapter,
                    "target_chapter": target_chapter,
                    "elapsed": elapsed,
                    "remaining": remaining,
                    "status": overtime_status,
                    "urgency": urgency,
                    "urgency_status": urgency_status,
                }
            )

        return records

    def _get_chapter_meta(self, chapter: int) -> Dict[str, Any]:
        """è¯»å–æŒ‡å®šç« èŠ‚çš„ chapter_metaï¼ˆæ”¯æŒ 0001/1 ä¸¤ç§é”®ï¼‰ã€‚"""
        if not self.state:
            return {}
        return get_chapter_meta_entry(self.state, chapter)

    def _parse_pattern_count(self, raw_value: Any) -> Optional[int]:
        """è§£æçˆ½ç‚¹æ¨¡å¼æ•°é‡ï¼Œè§£æå¤±è´¥è¿”å› Noneã€‚"""
        if raw_value is None:
            return None

        if isinstance(raw_value, list):
            patterns = [str(x).strip() for x in raw_value if str(x).strip()]
            return len(set(patterns))

        if isinstance(raw_value, str):
            text = raw_value.strip()
            if not text:
                return None
            parts = [p.strip() for p in re.split(r"[ã€,ï¼Œ/|+ï¼›;]+", text) if p.strip()]
            if parts:
                return len(set(parts))
            return 1

        return None

    def _get_chapter_reading_power_cached(self, chapter: int) -> Optional[Dict[str, Any]]:
        """è¯»å–å¹¶ç¼“å­˜ chapter_reading_powerã€‚"""
        if chapter in self._reading_power_cache:
            return self._reading_power_cache[chapter]

        try:
            record = self._index_manager.get_chapter_reading_power(chapter)
        except Exception:
            record = None

        self._reading_power_cache[chapter] = record
        return record

    def _get_chapter_cool_points(self, chapter: int, chapter_data: Dict[str, Any]) -> Tuple[Optional[int], str]:
        """è·å–å•ç« çˆ½ç‚¹æ•°é‡ï¼ˆçœŸå®å…ƒæ•°æ®ä¼˜å…ˆï¼‰ã€‚"""
        reading_power = self._get_chapter_reading_power_cached(chapter)
        if isinstance(reading_power, dict):
            count = self._parse_pattern_count(reading_power.get("coolpoint_patterns"))
            if count is not None:
                return count, "chapter_reading_power"

        chapter_meta = self._get_chapter_meta(chapter)
        for key in ("coolpoint_patterns", "coolpoint_pattern", "cool_point_patterns", "cool_point_pattern", "patterns", "pattern"):
            count = self._parse_pattern_count(chapter_meta.get(key))
            if count is not None:
                return count, "chapter_meta"

        count = self._parse_pattern_count(chapter_data.get("cool_point"))
        if count is not None:
            return count, "chapter_stats"

        return None, "none"

    def scan_chapters(self):
        """æ‰«ææ‰€æœ‰ç« èŠ‚æ–‡ä»¶"""
        if not self.chapters_dir.exists():
            print(f"âš ï¸  æ­£æ–‡ç›®å½•ä¸å­˜åœ¨: {self.chapters_dir}")
            return

        # æ”¯æŒä¸¤ç§ç›®å½•ç»“æ„ï¼š
        # 1) æ­£æ–‡/ç¬¬0001ç« .md
        # 2) æ­£æ–‡/ç¬¬1å·/ç¬¬001ç« -æ ‡é¢˜.md
        chapter_files = sorted(self.chapters_dir.rglob("ç¬¬*.md"))

        # v5.1 å¼•å…¥: ä» SQLite è·å–å·²çŸ¥è§’è‰²å
        known_character_names: List[str] = []
        protagonist_name = ""
        if self.state:
            protagonist_name = self.state.get("protagonist_state", {}).get("name", "") or ""

        # ä» SQLite è·å–æ‰€æœ‰è§’è‰²çš„ canonical_name
        try:
            characters_from_db = self._index_manager.get_entities_by_type("è§’è‰²")
            known_character_names = [
                c.get("canonical_name", c.get("id", ""))
                for c in characters_from_db
                if c.get("canonical_name")
            ]
        except Exception:
            known_character_names = []

        for chapter_file in chapter_files:
            chapter_num = extract_chapter_num_from_filename(chapter_file.name)
            if not chapter_num:
                continue

            # è¯»å–ç« èŠ‚å†…å®¹
            with open(chapter_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # ç»Ÿè®¡å­—æ•°ï¼ˆå»é™¤ Markdown æ ‡è®°ï¼‰
            text = re.sub(r'```[\s\S]*?```', '', content)  # å»é™¤ä»£ç å—
            text = re.sub(r'#+ .+', '', text)  # å»é™¤æ ‡é¢˜
            text = re.sub(r'---', '', text)  # å»é™¤åˆ†éš”çº¿
            word_count = len(text.strip())

            # ä¸»å¯¼ Strand / çˆ½ç‚¹ç±»å‹ï¼ˆä¼˜å…ˆä»"æœ¬ç« ç»Ÿè®¡"è§£æï¼‰
            dominant_strand = (self._extract_stats_field(content, "ä¸»å¯¼Strand") or "").lower()
            cool_point_type = self._extract_stats_field(content, "çˆ½ç‚¹")

            # v5.1 å¼•å…¥: è§’è‰²æå–ä» SQLite chapters è¡¨è¯»å–
            characters: List[str] = []
            try:
                chapter_info = self._index_manager.get_chapter(chapter_num)
                if chapter_info and chapter_info.get("characters"):
                    stored = chapter_info["characters"]
                    if isinstance(stored, str):
                        stored = json.loads(stored)
                    if isinstance(stored, list):
                        for entity_id in stored:
                            entity_id = str(entity_id).strip()
                            if not entity_id:
                                continue
                            # å°è¯•è·å– canonical_name
                            entity = self._index_manager.get_entity(entity_id)
                            name = entity.get("canonical_name", entity_id) if entity else entity_id
                            characters.append(name)
            except Exception:
                characters = []

            if not characters and (protagonist_name or known_character_names):
                # é™åˆ¶å€™é€‰è§„æ¨¡ï¼Œé¿å…åœ¨è¶…å¤§è§’è‰²åº“ä¸‹è¿‡æ…¢
                candidates = []
                if protagonist_name:
                    candidates.append(protagonist_name)
                candidates.extend(known_character_names[:self.config.character_candidates_limit])

                seen = set()
                for name in candidates:
                    if not name or name in seen:
                        continue
                    if name in content:
                        characters.append(name)
                        seen.add(name)

            self.chapters_data.append({
                "chapter": chapter_num,
                "file": chapter_file,
                "word_count": word_count,
                "characters": characters,
                "dominant": dominant_strand,
                "cool_point": cool_point_type,
            })

    def analyze_characters(self) -> Dict:
        """åˆ†æè§’è‰²æ´»è·ƒåº¦ï¼ˆv5.1 å¼•å…¥ï¼Œv5.4 æ²¿ç”¨ï¼‰"""
        if not self.state:
            return {}

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)

        # v5.1 å¼•å…¥: ä» SQLite è·å–æ‰€æœ‰è§’è‰²
        try:
            characters_list = self._index_manager.get_entities_by_type("è§’è‰²")
        except Exception:
            characters_list = []

        # ç»Ÿè®¡æ¯ä¸ªè§’è‰²çš„æœ€åå‡ºåœºç« èŠ‚
        character_activity = {}

        for char in characters_list:
            char_name = char.get("canonical_name", char.get("id", ""))
            if not char_name:
                continue

            # æŸ¥æ‰¾æœ€åå‡ºåœºç« èŠ‚
            last_appearance = char.get("last_appearance", 0) or 0

            # ä¹Ÿä» chapters_data ä¸­æ£€æŸ¥
            for ch_data in self.chapters_data:
                if char_name in ch_data.get("characters", []):
                    last_appearance = max(last_appearance, ch_data["chapter"])

            absence = current_chapter - last_appearance

            character_activity[char_name] = {
                "last_appearance": last_appearance,
                "absence": absence,
                "status": self._get_absence_status(absence)
            }

        return character_activity

    def _get_absence_status(self, absence: int) -> str:
        """åˆ¤æ–­æ‰çº¿çŠ¶æ€"""
        if absence == 0:
            return "âœ… æ´»è·ƒ"
        elif absence < self.config.character_absence_warning:
            return "ğŸŸ¢ æ­£å¸¸"
        elif absence < self.config.character_absence_critical:
            return "ğŸŸ¡ è½»åº¦æ‰çº¿"
        else:
            return "ğŸ”´ ä¸¥é‡æ‰çº¿"

    def analyze_foreshadowing(self) -> List[Dict]:
        """åˆ†æä¼ç¬”æ·±åº¦"""
        records = self._collect_foreshadowing_records()
        return [
            {
                "content": item["content"],
                "planted_chapter": item["planted_chapter"],
                "estimated_chapter": item["planted_chapter"],
                "target_chapter": item["target_chapter"],
                "elapsed": item["elapsed"],
                "status": item["status"],
            }
            for item in records
        ]

    def _get_foreshadowing_status(self, elapsed: int) -> str:
        """åˆ¤æ–­ä¼ç¬”è¶…æ—¶çŠ¶æ€"""
        if elapsed < self.config.foreshadowing_urgency_pending_medium:
            return "ğŸŸ¢ æ­£å¸¸"
        elif elapsed < self.config.foreshadowing_urgency_pending_high + 50:
            return "ğŸŸ¡ è½»åº¦è¶…æ—¶"
        else:
            return "ğŸ”´ ä¸¥é‡è¶…æ—¶"

    def analyze_foreshadowing_urgency(self) -> List[Dict]:
        """
        åˆ†æä¼ç¬”ç´§æ€¥åº¦ï¼ˆåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼‰

        ä¸‰å±‚çº§æƒé‡ï¼š
        - æ ¸å¿ƒ(Core): æƒé‡ 3.0 - å¿…é¡»å›æ”¶ï¼Œå¦åˆ™å‰§æƒ…å´©å¡Œ
        - æ”¯çº¿(Sub): æƒé‡ 2.0 - åº”è¯¥å›æ”¶ï¼Œå¦åˆ™æ˜¾å¾—ä½œè€…å¥å¿˜
        - è£…é¥°(Decor): æƒé‡ 1.0 - å¯å›æ”¶å¯ä¸å›æ”¶ï¼Œä»…å¢åŠ çœŸå®æ„Ÿ

        ç´§æ€¥åº¦è®¡ç®—å…¬å¼ï¼š
        urgency = (å·²è¿‡ç« èŠ‚ / ç›®æ ‡å›æ”¶ç« èŠ‚) Ã— å±‚çº§æƒé‡
        """
        records = self._collect_foreshadowing_records()
        urgency_list = [
            {
                "content": item["content"],
                "tier": item["tier"],
                "weight": item["weight"],
                "planted_chapter": item["planted_chapter"],
                "target_chapter": item["target_chapter"],
                "elapsed": item["elapsed"],
                "remaining": item["remaining"],
                "urgency": item["urgency"],
                "status": item["urgency_status"],
            }
            for item in records
        ]

        # å…ˆæŒ‰â€œæ˜¯å¦å¯è®¡ç®—â€ï¼Œå†æŒ‰ç´§æ€¥åº¦é™åº
        return sorted(
            urgency_list,
            key=lambda x: (x["urgency"] is None, -(x["urgency"] if x["urgency"] is not None else -1)),
        )

    def _get_urgency_status(self, urgency: float, remaining: int) -> str:
        """åˆ¤æ–­ç´§æ€¥åº¦çŠ¶æ€"""
        if remaining < 0:
            return "ğŸ”´ å·²è¶…æœŸ"
        elif urgency >= self.config.foreshadowing_tier_weight_sub:
            return "ğŸ”´ ç´§æ€¥"
        elif urgency >= 1.0:
            return "ğŸŸ¡ è­¦å‘Š"
        else:
            return "ğŸŸ¢ æ­£å¸¸"

    def analyze_strand_weave(self) -> Dict:
        """
        åˆ†æ Strand Weave èŠ‚å¥åˆ†å¸ƒ

        ä¸‰çº¿å®šä¹‰ï¼š
        - Questï¼ˆä¸»çº¿ï¼‰: æˆ˜æ–—ã€ä»»åŠ¡ã€å‡çº§ - ç›®æ ‡ 55-65%
        - Fireï¼ˆæ„Ÿæƒ…ï¼‰: æ„Ÿæƒ…çº¿ã€äººé™…äº’åŠ¨ - ç›®æ ‡ 20-30%
        - Constellationï¼ˆä¸–ç•Œè§‚ï¼‰: ä¸–ç•Œè§‚å±•å¼€ã€åŠ¿åŠ›èƒŒæ™¯ - ç›®æ ‡ 10-20%

        æ£€æŸ¥è§„åˆ™ï¼š
        - Quest çº¿è¿ç»­ä¸è¶…è¿‡ 5 ç« 
        - Fire çº¿ç¼ºå¤±ä¸è¶…è¿‡ 10 ç« 
        - Constellation çº¿ç¼ºå¤±ä¸è¶…è¿‡ 15 ç« 
        """
        if not self.state:
            return {}

        strand_tracker = self.state.get("strand_tracker", {})
        history = strand_tracker.get("history", [])

        if not history:
            return {
                "has_data": False,
                "message": "æš‚æ—  Strand Weave æ•°æ®"
            }

        # ç»Ÿè®¡å„çº¿å æ¯”
        quest_count = 0
        fire_count = 0
        constellation_count = 0
        total = len(history)

        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["quest", "ä¸»çº¿", "æˆ˜æ–—", "ä»»åŠ¡"]:
                quest_count += 1
            elif strand in ["fire", "æ„Ÿæƒ…", "æ„Ÿæƒ…çº¿", "äº’åŠ¨"]:
                fire_count += 1
            elif strand in ["constellation", "ä¸–ç•Œè§‚", "èƒŒæ™¯", "åŠ¿åŠ›"]:
                constellation_count += 1

        # è®¡ç®—å æ¯”
        quest_ratio = (quest_count / total * 100) if total > 0 else 0
        fire_ratio = (fire_count / total * 100) if total > 0 else 0
        constellation_ratio = (constellation_count / total * 100) if total > 0 else 0

        # æ£€æŸ¥è¿è§„
        violations = []

        # æ£€æŸ¥ Quest è¿ç»­è¶…è¿‡ 5 ç« 
        quest_streak = 0
        max_quest_streak = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["quest", "ä¸»çº¿", "æˆ˜æ–—", "ä»»åŠ¡"]:
                quest_streak += 1
                max_quest_streak = max(max_quest_streak, quest_streak)
            else:
                quest_streak = 0

        if max_quest_streak > self.config.strand_quest_max_consecutive:
            violations.append(f"Quest çº¿è¿ç»­ {max_quest_streak} ç« ï¼ˆè¶…è¿‡ {self.config.strand_quest_max_consecutive} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥ Fire ç¼ºå¤±è¶…è¿‡ 10 ç« 
        fire_gap = 0
        max_fire_gap = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["fire", "æ„Ÿæƒ…", "æ„Ÿæƒ…çº¿", "äº’åŠ¨"]:
                max_fire_gap = max(max_fire_gap, fire_gap)
                fire_gap = 0
            else:
                fire_gap += 1
        max_fire_gap = max(max_fire_gap, fire_gap)

        if max_fire_gap > self.config.strand_fire_max_gap:
            violations.append(f"Fire çº¿ç¼ºå¤± {max_fire_gap} ç« ï¼ˆè¶…è¿‡ {self.config.strand_fire_max_gap} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥ Constellation ç¼ºå¤±è¶…è¿‡ 15 ç« 
        const_gap = 0
        max_const_gap = 0
        for entry in history:
            strand = (entry.get("strand") or entry.get("dominant") or "").lower()
            if strand in ["constellation", "ä¸–ç•Œè§‚", "èƒŒæ™¯", "åŠ¿åŠ›"]:
                max_const_gap = max(max_const_gap, const_gap)
                const_gap = 0
            else:
                const_gap += 1
        max_const_gap = max(max_const_gap, const_gap)

        if max_const_gap > self.config.strand_constellation_max_gap:
            violations.append(f"Constellation çº¿ç¼ºå¤± {max_const_gap} ç« ï¼ˆè¶…è¿‡ {self.config.strand_constellation_max_gap} ç« é™åˆ¶ï¼‰")

        # æ£€æŸ¥å æ¯”æ˜¯å¦åœ¨åˆç†èŒƒå›´
        cfg = self.config
        if quest_ratio < cfg.strand_quest_ratio_min:
            violations.append(f"Quest å æ¯” {quest_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}%ï¼‰")
        elif quest_ratio > cfg.strand_quest_ratio_max:
            violations.append(f"Quest å æ¯” {quest_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}%ï¼‰")

        if fire_ratio < cfg.strand_fire_ratio_min:
            violations.append(f"Fire å æ¯” {fire_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}%ï¼‰")
        elif fire_ratio > cfg.strand_fire_ratio_max:
            violations.append(f"Fire å æ¯” {fire_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}%ï¼‰")

        if constellation_ratio < cfg.strand_constellation_ratio_min:
            violations.append(f"Constellation å æ¯” {constellation_ratio:.1f}% åä½ï¼ˆç›®æ ‡ {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}%ï¼‰")
        elif constellation_ratio > cfg.strand_constellation_ratio_max:
            violations.append(f"Constellation å æ¯” {constellation_ratio:.1f}% åé«˜ï¼ˆç›®æ ‡ {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}%ï¼‰")

        return {
            "has_data": True,
            "total_chapters": total,
            "quest": {"count": quest_count, "ratio": quest_ratio},
            "fire": {"count": fire_count, "ratio": fire_ratio},
            "constellation": {"count": constellation_count, "ratio": constellation_ratio},
            "violations": violations,
            "max_quest_streak": max_quest_streak,
            "max_fire_gap": max_fire_gap,
            "max_const_gap": max_const_gap,
            "health": "âœ… å¥åº·" if not violations else f"âš ï¸ {len(violations)} ä¸ªé—®é¢˜"
        }

    def analyze_pacing(self) -> List[Dict]:
        """åˆ†æçˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒï¼ˆæ¯ N ç« ä¸ºä¸€æ®µï¼‰"""
        segment_size = self.config.pacing_segment_size
        segments = []

        for i in range(0, len(self.chapters_data), segment_size):
            segment_chapters = self.chapters_data[i:i+segment_size]

            if not segment_chapters:
                continue

            start_ch = segment_chapters[0]["chapter"]
            end_ch = segment_chapters[-1]["chapter"]
            total_words = sum(ch["word_count"] for ch in segment_chapters)

            cool_points = 0
            chapters_with_data = 0
            source_counter: Dict[str, int] = {}

            for chapter_data in segment_chapters:
                chapter = chapter_data["chapter"]
                count, source = self._get_chapter_cool_points(chapter, chapter_data)
                source_counter[source] = source_counter.get(source, 0) + 1
                if count is None:
                    continue
                chapters_with_data += 1
                cool_points += count

            words_per_point = None
            if cool_points > 0:
                words_per_point = total_words / cool_points

            rating = self._get_pacing_rating(words_per_point)
            missing_chapters = len(segment_chapters) - chapters_with_data
            dominant_source = "none"
            if source_counter:
                dominant_source = max(source_counter.items(), key=lambda x: x[1])[0]

            segments.append({
                "start": start_ch,
                "end": end_ch,
                "total_words": total_words,
                "cool_points": cool_points,
                "words_per_point": words_per_point,
                "rating": rating,
                "missing_chapters": missing_chapters,
                "data_coverage": (chapters_with_data / len(segment_chapters)) if segment_chapters else 0.0,
                "dominant_source": dominant_source,
            })

        return segments

    def _get_pacing_rating(self, words_per_point: Optional[float]) -> str:
        """åˆ¤æ–­èŠ‚å¥è¯„çº§"""
        if words_per_point is None:
            return "æ•°æ®ä¸è¶³"
        if words_per_point < self.config.pacing_words_per_point_excellent:
            return "ä¼˜ç§€"
        elif words_per_point < self.config.pacing_words_per_point_good:
            return "è‰¯å¥½"
        elif words_per_point < self.config.pacing_words_per_point_acceptable:
            return "åŠæ ¼"
        else:
            return "åä½âš ï¸"

    def generate_relationship_graph(self) -> str:
        """ç”Ÿæˆäººé™…å…³ç³» Mermaid å›¾"""
        if not self.state:
            return ""

        relationships = self.state.get("relationships", {})
        protagonist_name = self.state.get("protagonist_state", {}).get("name", "ä¸»è§’")

        lines = ["```mermaid", "graph LR"]

        # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        # æ ¼å¼1ï¼ˆæ–°ï¼‰: {"allies": [...], "enemies": [...]}
        # æ ¼å¼2ï¼ˆæ—§ï¼‰: {"è§’è‰²å": {"affection": X, "hatred": Y}}

        allies = relationships.get("allies", [])
        enemies = relationships.get("enemies", [])

        if allies or enemies:
            # æ–°æ ¼å¼
            for ally in allies:
                if isinstance(ally, dict):
                    name = ally.get("name", "æœªçŸ¥")
                    relation = ally.get("relation", "å‹å¥½")
                    lines.append(f"    {protagonist_name} -->|{relation}| {name}")

            for enemy in enemies:
                if isinstance(enemy, dict):
                    name = enemy.get("name", "æœªçŸ¥")
                    relation = enemy.get("relation", "æ•Œå¯¹")
                    lines.append(f"    {protagonist_name} -.->|{relation}| {name}")
        else:
            # æ—§æ ¼å¼å…¼å®¹
            for char_name, rel_data in relationships.items():
                if isinstance(rel_data, dict):
                    affection = rel_data.get("affection", 0)
                    hatred = rel_data.get("hatred", 0)

                    if affection > 0:
                        lines.append(f"    {protagonist_name} -->|å¥½æ„Ÿåº¦{affection}| {char_name}")

                    if hatred > 0:
                        lines.append(f"    {protagonist_name} -.->|ä»‡æ¨åº¦{hatred}| {char_name}")

        lines.append("```")

        return "\n".join(lines)

    def generate_report(self, focus: str = "all") -> str:
        """ç”Ÿæˆå¥åº·æŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰"""

        report_lines = [
            "# å…¨ä¹¦å¥åº·æŠ¥å‘Š",
            "",
            f"> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            ""
        ]

        # åŸºæœ¬æ•°æ®
        if focus in ["all", "basic"]:
            report_lines.extend(self._generate_basic_stats())

        # è§’è‰²æ´»è·ƒåº¦
        if focus in ["all", "characters"]:
            report_lines.extend(self._generate_character_section())

        # ä¼ç¬”æ·±åº¦
        if focus in ["all", "foreshadowing"]:
            report_lines.extend(self._generate_foreshadowing_section())

        # ä¼ç¬”ç´§æ€¥åº¦ï¼ˆæ–°å¢ï¼‰
        if focus in ["all", "foreshadowing", "urgency"]:
            report_lines.extend(self._generate_urgency_section())

        # çˆ½ç‚¹èŠ‚å¥
        if focus in ["all", "pacing"]:
            report_lines.extend(self._generate_pacing_section())

        # Strand Weave èŠ‚å¥ï¼ˆæ–°å¢ï¼‰
        if focus in ["all", "strand", "pacing"]:
            report_lines.extend(self._generate_strand_section())

        # äººé™…å…³ç³»
        if focus in ["all", "relationships"]:
            report_lines.extend(self._generate_relationship_section())

        return "\n".join(report_lines)

    def _generate_basic_stats(self) -> List[str]:
        """ç”ŸæˆåŸºæœ¬ç»Ÿè®¡"""
        if not self.state:
            return []

        progress = self.state.get("progress", {})
        current_chapter = progress.get("current_chapter", 0)
        total_words = progress.get("total_words", 0)
        target_words = self.state.get("project_info", {}).get("target_words", 2000000)

        avg_words = total_words / current_chapter if current_chapter > 0 else 0
        completion = (total_words / target_words * 100) if target_words > 0 else 0

        return [
            "## ğŸ“Š åŸºæœ¬æ•°æ®",
            "",
            f"- **æ€»ç« èŠ‚æ•°**: {current_chapter} ç« ",
            f"- **æ€»å­—æ•°**: {total_words:,} å­—",
            f"- **å¹³å‡ç« èŠ‚å­—æ•°**: {avg_words:,.0f} å­—",
            f"- **åˆ›ä½œè¿›åº¦**: {completion:.1f}%ï¼ˆç›®æ ‡ {target_words:,} å­—ï¼‰",
            "",
            "---",
            ""
        ]

    def _generate_character_section(self) -> List[str]:
        """ç”Ÿæˆè§’è‰²åˆ†æç« èŠ‚"""
        activity = self.analyze_characters()

        if not activity:
            return []

        # ç­›é€‰æ‰çº¿è§’è‰²
        dropped = {name: data for name, data in activity.items()
                  if "æ‰çº¿" in data["status"]}

        lines = [
            f"## âš ï¸ è§’è‰²æ‰çº¿ï¼ˆ{len(dropped)}äººï¼‰",
            ""
        ]

        if dropped:
            lines.extend([
                "| è§’è‰² | æœ€åå‡ºåœº | ç¼ºå¸­ç« èŠ‚ | çŠ¶æ€ |",
                "|------|---------|---------|------|"
            ])

            for char_name, data in sorted(dropped.items(),
                                         key=lambda x: x[1]["absence"],
                                         reverse=True):
                lines.append(
                    f"| {char_name} | ç¬¬ {data['last_appearance']} ç«  | "
                    f"{data['absence']} ç«  | {data['status']} |"
                )
        else:
            lines.append("âœ… æ‰€æœ‰è§’è‰²æ´»è·ƒåº¦æ­£å¸¸")

        lines.extend(["", "---", ""])

        return lines

    def _generate_foreshadowing_section(self) -> List[str]:
        """ç”Ÿæˆä¼ç¬”åˆ†æç« èŠ‚"""
        overdue = self.analyze_foreshadowing()

        # ç­›é€‰è¶…æ—¶ä¼ç¬”
        overdue_items = [
            item for item in overdue if "è¶…æ—¶" in item["status"] or "è¶…æœŸ" in item["status"]
        ]
        unknown_items = [item for item in overdue if item["status"] == "âšª æ•°æ®ä¸è¶³"]

        lines = [
            f"## âš ï¸ ä¼ç¬”è¶…æ—¶ï¼ˆ{len(overdue_items)}æ¡ï¼‰",
            ""
        ]

        if overdue_items:
            lines.extend([
                "| ä¼ç¬”å†…å®¹ | åŸ‹è®¾ç« èŠ‚ | å·²è¿‡ç« èŠ‚ | çŠ¶æ€ |",
                "|---------|---------|---------|------|"
            ])

            for item in sorted(overdue_items, key=lambda x: (x["elapsed"] if x["elapsed"] is not None else -1), reverse=True):
                planted = item["planted_chapter"] if item["planted_chapter"] is not None else "æœªçŸ¥"
                elapsed = item["elapsed"] if item["elapsed"] is not None else "æœªçŸ¥"
                lines.append(
                    f"| {item['content'][:30]}... | ç¬¬ {planted} ç«  | "
                    f"{elapsed} ç«  | {item['status']} |"
                )
        else:
            lines.append("âœ… æ‰€æœ‰ä¼ç¬”è¿›åº¦æ­£å¸¸")

        if unknown_items:
            lines.append("")
            lines.append(f"âšª å¦æœ‰ {len(unknown_items)} æ¡ä¼ç¬”ç¼ºå°‘ç« èŠ‚ä¿¡æ¯ï¼Œæ— æ³•åˆ¤æ–­æ˜¯å¦è¶…æ—¶")

        lines.extend(["", "---", ""])

        return lines

    def _generate_urgency_section(self) -> List[str]:
        """ç”Ÿæˆä¼ç¬”ç´§æ€¥åº¦ç« èŠ‚ï¼ˆåŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼‰"""
        urgency_list = self.analyze_foreshadowing_urgency()

        # ç­›é€‰ç´§æ€¥ä¼ç¬”
        urgent_items = [
            item
            for item in urgency_list
            if (item["urgency"] is not None and item["urgency"] >= 1.0) or item["status"] == "ğŸ”´ å·²è¶…æœŸ"
        ]

        lines = [
            f"## ğŸš¨ ä¼ç¬”ç´§æ€¥åº¦æ’åºï¼ˆ{len(urgent_items)}æ¡éœ€å…³æ³¨ï¼‰",
            "",
            "> åŸºäºä¸‰å±‚çº§ç³»ç»Ÿï¼šæ ¸å¿ƒ(Ã—3) / æ”¯çº¿(Ã—2) / è£…é¥°(Ã—1)",
            "> ç´§æ€¥åº¦ = (å·²è¿‡ç« èŠ‚ / (ç›®æ ‡ç« èŠ‚-åŸ‹è®¾ç« èŠ‚)) Ã— å±‚çº§æƒé‡",
            ""
        ]

        unknown_items = [item for item in urgency_list if item["urgency"] is None]
        if unknown_items:
            lines.append(f"> {len(unknown_items)} æ¡ä¼ç¬”ç¼ºå°‘åŸ‹è®¾/ç›®æ ‡ç« èŠ‚ï¼Œç´§æ€¥åº¦è®°ä¸º N/A")
            lines.append("")

        if urgency_list:
            lines.extend([
                "| ä¼ç¬”å†…å®¹ | å±‚çº§ | åŸ‹è®¾ | ç›®æ ‡ | ç´§æ€¥åº¦ | çŠ¶æ€ |",
                "|---------|------|------|------|--------|------|"
            ])

            for item in urgency_list[:10]:  # åªæ˜¾ç¤ºå‰10æ¡
                planted = f"ç¬¬{item['planted_chapter']}ç« " if item["planted_chapter"] is not None else "æœªçŸ¥"
                target = f"ç¬¬{item['target_chapter']}ç« " if item["target_chapter"] is not None else "æœªçŸ¥"
                urgency_text = f"{item['urgency']:.2f}" if item["urgency"] is not None else "N/A"
                lines.append(
                    f"| {item['content'][:20]}... | {item['tier']} | "
                    f"{planted} | {target} | "
                    f"{urgency_text} | {item['status']} |"
                )
        else:
            lines.append("âœ… æš‚æ— ä¼ç¬”æ•°æ®")

        lines.extend(["", "---", ""])

        return lines

    def _generate_strand_section(self) -> List[str]:
        """ç”Ÿæˆ Strand Weave èŠ‚å¥ç« èŠ‚"""
        strand_data = self.analyze_strand_weave()

        lines = [
            "## ğŸ­ Strand Weave èŠ‚å¥åˆ†æ",
            ""
        ]

        if not strand_data.get("has_data"):
            lines.append(f"âš ï¸ {strand_data.get('message', 'æš‚æ— æ•°æ®')}")
            lines.extend(["", "---", ""])
            return lines

        # å æ¯”ç»Ÿè®¡
        cfg = self.config
        lines.extend([
            "### ä¸‰çº¿å æ¯”",
            "",
            "| Strand | ç« èŠ‚æ•° | å æ¯” | ç›®æ ‡èŒƒå›´ | çŠ¶æ€ |",
            "|--------|--------|------|----------|------|"
        ])

        q = strand_data["quest"]
        q_status = "âœ…" if cfg.strand_quest_ratio_min <= q["ratio"] <= cfg.strand_quest_ratio_max else "âš ï¸"
        lines.append(f"| Questï¼ˆä¸»çº¿ï¼‰ | {q['count']} | {q['ratio']:.1f}% | {cfg.strand_quest_ratio_min}-{cfg.strand_quest_ratio_max}% | {q_status} |")

        f = strand_data["fire"]
        f_status = "âœ…" if cfg.strand_fire_ratio_min <= f["ratio"] <= cfg.strand_fire_ratio_max else "âš ï¸"
        lines.append(f"| Fireï¼ˆæ„Ÿæƒ…ï¼‰ | {f['count']} | {f['ratio']:.1f}% | {cfg.strand_fire_ratio_min}-{cfg.strand_fire_ratio_max}% | {f_status} |")

        c = strand_data["constellation"]
        c_status = "âœ…" if cfg.strand_constellation_ratio_min <= c["ratio"] <= cfg.strand_constellation_ratio_max else "âš ï¸"
        lines.append(f"| Constellationï¼ˆä¸–ç•Œè§‚ï¼‰ | {c['count']} | {c['ratio']:.1f}% | {cfg.strand_constellation_ratio_min}-{cfg.strand_constellation_ratio_max}% | {c_status} |")

        lines.append("")

        # è¿ç»­æ€§æ£€æŸ¥
        lines.extend([
            "### è¿ç»­æ€§æ£€æŸ¥",
            "",
            f"- Quest æœ€å¤§è¿ç»­: {strand_data['max_quest_streak']} ç« ï¼ˆé™åˆ¶ â‰¤5ï¼‰",
            f"- Fire æœ€å¤§ç¼ºå¤±: {strand_data['max_fire_gap']} ç« ï¼ˆé™åˆ¶ â‰¤10ï¼‰",
            f"- Constellation æœ€å¤§ç¼ºå¤±: {strand_data['max_const_gap']} ç« ï¼ˆé™åˆ¶ â‰¤15ï¼‰",
            ""
        ])

        # è¿è§„æ¸…å•
        if strand_data["violations"]:
            lines.extend([
                "### âš ï¸ è¿è§„æ¸…å•",
                ""
            ])
            for v in strand_data["violations"]:
                lines.append(f"- {v}")
        else:
            lines.append("### âœ… æ— è¿è§„")

        lines.extend(["", f"**ç»¼åˆå¥åº·åº¦**: {strand_data['health']}", "", "---", ""])

        return lines

    def _generate_pacing_section(self) -> List[str]:
        """ç”ŸæˆèŠ‚å¥åˆ†æç« èŠ‚"""
        segments = self.analyze_pacing()

        lines = [
            "## ğŸ“ˆ çˆ½ç‚¹èŠ‚å¥åˆ†å¸ƒ",
            "",
            "```"
        ]

        for seg in segments:
            words_per_point = seg["words_per_point"]
            if words_per_point is None:
                lines.append(
                    f"ç¬¬ {seg['start']}-{seg['end']}ç«    â–‘ æ•°æ®ä¸è¶³"
                    f"ï¼ˆç¼ºå°‘çˆ½ç‚¹æ•°æ® {seg['missing_chapters']} ç« ï¼‰"
                )
                continue

            bar_length = int(12 - (words_per_point / 2000 * 12))
            bar_length = max(1, min(12, bar_length))
            bar = "â–ˆ" * bar_length

            suffix = ""
            if seg["missing_chapters"] > 0:
                suffix = f"ï¼Œç¼ºå°‘çˆ½ç‚¹æ•°æ® {seg['missing_chapters']} ç« "

            lines.append(
                f"ç¬¬ {seg['start']}-{seg['end']}ç«    {bar} {seg['rating']}"
                f"ï¼ˆ{words_per_point:.0f}å­—/çˆ½ç‚¹ï¼Œè®°å½• {seg['cool_points']} ä¸ªçˆ½ç‚¹{suffix}ï¼‰"
            )

        lines.extend(["```", "", "---", ""])

        return lines

    def _generate_relationship_section(self) -> List[str]:
        """ç”Ÿæˆäººé™…å…³ç³»ç« èŠ‚"""
        graph = self.generate_relationship_graph()

        lines = [
            "## ğŸ’‘ äººé™…å…³ç³»è¶‹åŠ¿",
            "",
            graph,
            "",
            "---",
            ""
        ]

        return lines

def main():
    import argparse

    _enable_windows_utf8_stdio()

    parser = argparse.ArgumentParser(
        description="å¯è§†åŒ–çŠ¶æ€æŠ¥å‘Šç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # ç”Ÿæˆå®Œæ•´å¥åº·æŠ¥å‘Š
  python status_reporter.py --output .webnovel/health_report.md

  # ä»…åˆ†æè§’è‰²æ´»è·ƒåº¦
  python status_reporter.py --focus characters

  # ä»…åˆ†æä¼ç¬”
  python status_reporter.py --focus foreshadowing

  # ä»…åˆ†æçˆ½ç‚¹èŠ‚å¥
  python status_reporter.py --focus pacing
        """
    )

    parser.add_argument('--output', default='.webnovel/health_report.md',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--focus', choices=['all', 'basic', 'characters',
                                            'foreshadowing', 'urgency', 'pacing',
                                            'strand', 'relationships'],
                       default='all', help='åˆ†æç„¦ç‚¹ï¼ˆæ–°å¢ urgency, strandï¼‰')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•')

    args = parser.parse_args()

    # è§£æé¡¹ç›®æ ¹ç›®å½•ï¼ˆæ”¯æŒä»ä»“åº“æ ¹ç›®å½•è¿è¡Œï¼‰
    project_root = args.project_root
    if project_root == '.' and not (Path('.') / '.webnovel' / 'state.json').exists():
        try:
            project_root = str(resolve_project_root())
        except FileNotFoundError:
            project_root = args.project_root

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = StatusReporter(project_root)

    # åŠ è½½çŠ¶æ€
    if not reporter.load_state():
        sys.exit(1)

    print("ğŸ“– æ­£åœ¨æ‰«æç« èŠ‚æ–‡ä»¶...")
    reporter.scan_chapters()

    print(f"âœ… å·²æ‰«æ {len(reporter.chapters_data)} ä¸ªç« èŠ‚")

    print("\nğŸ“Š æ­£åœ¨åˆ†æ...")

    # ç”ŸæˆæŠ¥å‘Š
    report = reporter.generate_report(args.focus)

    # ä¿å­˜æŠ¥å‘Š
    output_file = Path(args.output)
    if args.output == '.webnovel/health_report.md' and project_root != '.':
        output_file = Path(project_root) / '.webnovel' / 'health_report.md'
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nâœ… å¥åº·æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    # é¢„è§ˆæŠ¥å‘Šï¼ˆå‰ 30 è¡Œï¼‰
    print("\n" + "="*60)
    print("ğŸ“„ æŠ¥å‘Šé¢„è§ˆï¼š\n")
    print("\n".join(report.split("\n")[:30]))
    print("\n...")
    print("="*60)

if __name__ == "__main__":
    main()
